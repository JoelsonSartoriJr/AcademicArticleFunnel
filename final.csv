T√≠tulo,Link,Snippet,Autores,Data de Publica√ß√£o,Fonte,Similaridade com T√≠tulo,Similaridade com Resumo,Similaridade M√©dia
Focal attention for long-range interactions in vision transformers,https://proceedings.neurips.cc/paper/2021/hash/fc1a36821b02abbd2503fd949bfc9131-Abstract.html,", we present focal attention, a new attention mechanism that  focal attention into a multi-scale  Transformer architecture, we  that is widely applicable to all attention-based neural network","J Yang, C Li, P Zhang, X Dai, B Xiao",2021,Advances in Neural ‚Ä¶,0.802406066195008,0.8256337723776119,0.81401991928631
Dual aggregation transformer for image super-resolution,http://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.html,"self-attention module, we propose the adaptive interaction  in deepening the layer of the  network for better performance.  introducing the architecture of dual aggregation Transformer (","Z Chen, Y Zhang, J Gu, L Kong",2023,Proceedings of the ‚Ä¶,0.7972323231018712,0.8298305611282106,0.8135314421150409
Self-attention transformer-based architecture for remaining useful life estimation of complex machines,https://www.sciencedirect.com/science/article/pii/S1877050922023195,‚Ä¢ We propose a self-attention based transformer architecture  ‚Ä¢ We investigate the abstract  feature extraction layer module to  any prior domain knowledge into the attention mechanism.,"A Wahid, M Yahya, JG Breslin, MA Intizar",2023,Procedia Computer Science,0.8023937718911103,0.8228490462040385,0.8126214090475744
An abstractive text summarization technique using transformer model with self-attention mechanism,https://link.springer.com/article/10.1007/s00521-023-08687-7,"transformer architecture with an attention mechanism and a  Feed-forward layer and the  crucial Self-attention layer, which  network and a knowledge-based hierarchical attention module","S Kumar, A Solanki",2023,Neural Computing and Applications,0.7987531065693221,0.8253796219834173,0.8120663642763697
Point transformer v2: Grouped vector attention and partition-based pooling,https://proceedings.neurips.cc/paper_files/paper/2022/hash/d78ece6613953f46501b958b7bb4582f-Abstract-Conference.html,"Transformer [1], and propose several novel architecture designs for the attention and pooling  module,  With grouped vector attention restricting the capacity of the attention mechanism,","X Wu, Y Lao, L Jiang, X Liu",2022,Advances in Neural ‚Ä¶,0.8057814369742546,0.8122880768774163,0.8090347569258355
A weakly-supervised transformer-based hybrid network with multi-attention for pavement crack detection,https://www.sciencedirect.com/science/article/pii/S0950061823038527,", a novel architecture integrating Gated Axial Transformer into  attention mechanism  decomposed the self-attention module  MLP layer to process the feature map from Transformer","Z Wang, Z Leng, Z Zhang",2024,Construction and Building Materials,0.8082352155689672,0.8095894180536958,0.8089123168113315
Attention-based interpretability with concept transformers,https://openreview.net/forum?id=kAa9eDS0RdO,"performance gains of deep neural network models in a host of  architecture, plausibility is  achieved by construction by supervising the attention heads of the cross-attention mechanism","M Rigotti, C Miksovic, I Giurgiu, T Gschwind",2021,International ‚Ä¶,0.8056541193961623,0.8108860277118924,0.8082700735540274
Surface vision transformers: Attention-based modelling applied to cortical analysis,https://proceedings.mlr.press/v172/dahan22a.html,"architecture is made of L transformer blocks, each composed of a multi-head self-attention  layer  Corticalflow: A diffeomorphic mesh transformer network for cortical surface reconstruction","S Dahan, A Fawaz, LZJ Williams",2022,‚Ä¶ on Medical Imaging ‚Ä¶,0.7997538153500605,0.8158829702923703,0.8078183928212155
Pay attention to the activations: A modular attention mechanism for fine-grained image recognition,https://ieeexplore.ieee.org/abstract/document/8762109/,"number of attention heads per module. This is implicitly done in the transformer architecture  [ By adding attention layers with AW = 1 after each layer, we obtain increasingly better results","P Rodriguez, D Velazquez, G Cucurull",2019,IEEE Transactions ‚Ä¶,0.7999773642256821,0.8141897621188249,0.8070835631722535
TGF: Multiscale transformer graph attention network for multi-sensor image fusion,https://www.sciencedirect.com/science/article/pii/S0957417423022911,"The graph attention mechanism provides additional  IR and VI fusion methods and graph  attention-based low-level vision  network architecture that consists of conv layers, transformer","HT Mustafa, P Shamsolmoali, IH Lee",2024,Expert Systems with Applications,0.790090520678936,0.8239849397770993,0.8070377302280176
A multi-head self-attention transformer-based model for traffic situation prediction in terminal areas,https://ieeexplore.ieee.org/abstract/document/10044658/,Self-attention is a variation of the attention mechanism that  on Transformer's architecture  by adopting other network structures to  The data processing module in the prediction model,"Z Yu, X Shi, Z Zhang",2023,IEEE Access,0.7941694087293314,0.8179383237914358,0.8060538662603836
Vicinity vision transformer,https://ieeexplore.ieee.org/abstract/document/10149455/,into each layer throughout the whole model via convolutional  self-attention (MSA) module  to reduce the feature dimension  the overall architecture of Vicinity Vision Transformer (VVT),"W Sun, Z Qin, H Deng, J Wang, Y Zhang",2023,‚Ä¶ on Pattern Analysis ‚Ä¶,0.7911853713706096,0.820862446040737,0.8060239087056733
A hybrid multi-scale attention convolution and aging transformer network for Alzheimer's disease diagnosis,https://ieeexplore.ieee.org/abstract/document/10109788/,Attention mechanism has attracted a lot of interest to enhance  Architecture of our proposed  aging transformer subnetwork  of the attention module and aging transformer for disease,"X Gao, H Cai, M Liu",2023,IEEE Journal of Biomedical and Health ‚Ä¶,0.8051531890469859,0.8057770475141636,0.8054651182805748
Swiftformer: Efficient additive attention for transformer-based real-time mobile vision applications,http://openaccess.thecvf.com/content/ICCV2023/html/Shaker_SwiftFormer_Efficient_Additive_Attention_for_Transformer-based_Real-time_Mobile_Vision_Applications_ICCV_2023_paper.html,"a novel efficient additive attention mechanism that effectively  Inspired by the transformer  architecture, we employ a linear  baseline model, which only includes the self-attention based","A Shaker, M Maaz, H Rasheed",2023,Proceedings of the ‚Ä¶,0.79326534317948,0.8157826300991481,0.8045239866393141
Image super-resolution method based on the interactive fusion of transformer and CNN features,https://link.springer.com/article/10.1007/s00371-023-03138-9,"into the attention module to improve the Transformer, utilizing  to the attention mechanism  and feed-forward network (FFN),  The new transformer architecture combines self-attention","J Wang, Y Zou, O Alfarraj, PK Sharma, W Said",2024,The Visual ‚Ä¶,0.7868099297520718,0.8214301091043719,0.8041200194282219
Paraformer: Parallel attention transformer for efficient feature matching,https://ojs.aaai.org/index.php/AAAI/article/view/25275,"of quadratic complexity of attention mechanism. So we focus on  In this paper, we propose  a novel attention-based network  attention architecture that not only integrates self-attention","X Lu, Y Yan, B Kang, S Du",2023,Proceedings of the AAAI Conference on ‚Ä¶,0.7903378937948602,0.8176727344095078,0.804005314102184
Transformer-based visual object tracking via fine‚Äìcoarse concatenated attention and cross concatenated MLP,https://www.sciencedirect.com/science/article/pii/S0031320323006623,within one attention layer of the original self-attention learning  in the transformer to achieve  nonlocal attention-based  of multi-head self-attention (MSA) and feed-forward network (,"L Gao, L Chen, P Liu, Y Jiang, Y Li, J Ning",2024,Pattern Recognition,0.7944923674042267,0.8132932917254488,0.8038928295648378
Adaptive semantic-enhanced transformer for image captioning,https://ieeexplore.ieee.org/abstract/document/9810877/,"gated mechanism (AGM) module to adjust the attention  has gradually replaced the CNN‚ÄìRNN  architecture and  the multihead attention mechanism, our AS-Transformer can adaptively","J Zhang, Z Fang, H Sun, Z Wang",2022,‚Ä¶ on Neural Networks and ‚Ä¶,0.7933734062791314,0.8133253638318707,0.8033493850555011
Vision transformer with deformable attention,https://openaccess.thecvf.com/content/CVPR2022/html/Xia_Vision_Transformer_With_Deformable_Attention_CVPR_2022_paper.html?ref=https://githubhelp.com,"propose a novel deformable self-attention module, where the  revisit the attention mechanism  in recent Vision Transformers.  of the network architecture, our model, Deformable Attention","Z Xia, X Pan, S Song, LE Li",2022,Proceedings of the IEEE ‚Ä¶,0.7873563337954014,0.8192594369091921,0.8033078853522968
A survey on vision transformer,https://ieeexplore.ieee.org/abstract/document/9716741/,proposed transformer based on attention mechanism for  due to the cross-attention module  in the transformer decoder. To  model named TransPose based on Transformer architecture,"K Han, Y Wang, H Chen, X Chen, J Guo",2022,IEEE transactions on ‚Ä¶,0.79340972028186,0.8131187073718202,0.8032642138268401
Boundary-aware transformers for skin lesion segmentation,https://link.springer.com/chapter/10.1007/978-3-030-87193-2_20,"employing a powerful global attention mechanism, but one of  -wise attention gate (BAG) in  transformer architecture to  layer in the encoder consists of a multi-head self-attention module","J Wang, L Wei, L Wang, Q Zhou, L Zhu",2021,Medical Image Computing ‚Ä¶,0.8009745710096753,0.8041108756139239,0.8025427233117997
Attention retractable frequency fusion transformer for image super resolution,https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/html/Zhu_Attention_Retractable_Frequency_Fusion_Transformer_for_Image_Super_Resolution_CVPRW_2023_paper.html,"], and attention mechanism, eg, residual channel attention  The architecture of our ARFFT  is illustrated in Fig. 1. It is  Transformer [16] was developed using the multiaxis attention based","Q Zhu, P Li, Q Li",2023,‚Ä¶ of the IEEE/CVF Conference on ‚Ä¶,0.7930201818448369,0.8113299975525594,0.8021750896986981
Extracting long‚Äêterm spatiotemporal characteristics of traffic flow using attention‚Äêbased convolutional transformer,https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/itr2.12468,to the self-attention layer within the encoder transformer  that incorporates modifications to  the attention mechanism to better  the overall architecture of the spatiotemporal transformers.,"AR Sattarzadeh, PN Pathirana",2023,IET Intelligent ‚Ä¶,0.7898121453901934,0.8138030098984774,0.8018075776443354
Castling-vit: Compressing self-attention via switching towards linear-angular attention at vision transformer inference,http://openaccess.thecvf.com/content/CVPR2023/html/You_Castling-ViT_Compressing_Self-Attention_via_Switching_Towards_Linear-Angular_Attention_at_Vision_CVPR_2023_paper.html,"In this way, our attention module can be formulated as:  backbones with transformer blocks,  whose architecture could  a new linear-angular attention mechanism: we decompose angular","H You, Y Xiong, X Dai, B Wu, P Zhang",2023,Proceedings of the ‚Ä¶,0.7826361740907797,0.8209351851373518,0.8017856796140657
Tree transformer: Integrating tree structures into self-attention,https://arxiv.org/abs/1909.06639,"Attention‚Äù module, which is simply implemented by  same network architecture, but with  different sets of network  of attention heads from each layer of the original Transformer","YS Wang, HY Lee, YN Chen",2019,arXiv preprint arXiv:1909.06639,0.7934192746865455,0.809861737223067,0.8016405059548062
Entangled transformer for image captioning,http://openaccess.thecvf.com/content_ICCV_2019/html/Li_Entangled_Transformer_for_Image_Captioning_ICCV_2019_paper.html,"attention module can be readily applied to the Transformer  As shown in Figure 2, the  overall architecture follows the  To mimic the attention mechanism of the human vision system","G Li, L Zhu, P Liu, Y Yang",2019,Proceedings of the IEEE/CVF ‚Ä¶,0.7956996675207293,0.8062445179241752,0.8009720927224522
Multi-dimension Transformer with Attention-based Filtering for Medical Image Segmentation,https://arxiv.org/abs/2405.12328,a convolutional layer within the Transformer to enhance its  to introduce locality into the  Transformer architecture. And an  factor that modulates the attention mechanism‚Äôs sensitivity.,"W Wang, X Xiao, M Liu, Q Tian, X Huang, Q Lan",2024,arXiv preprint arXiv ‚Ä¶,0.788940017763575,0.8129259833419293,0.8009330005527522
Couplformer: Rethinking vision transformer with coupling attention map,https://arxiv.org/abs/2112.05425,"memory economy attention mechanism named Couplformer,  Nowadays, Transformer and  attention-based models have  our architecture, we replace the original multi-head attention","H Lan, X Wang, X Wei",2021,arXiv preprint arXiv:2112.05425,0.8071785489104968,0.7942999926113039,0.8007392707609003
A semi-supervised approach for the integration of multi-omics data based on transformer multi-head self-attention mechanism and graph convolutional networks,https://link.springer.com/article/10.1186/s12864-024-09985-7,"Transformer architecture comprises an input layer,  number of attention heads in the multi-head  attention mechanism.  In this approach, we employed the Transformer encoding module","J Wang, N Liao, X Du, Q Chen, B Wei",2024,BMC genomics,0.784066173276385,0.8172438261915195,0.8006549997339523
BViT: Broad attention-based vision transformer,https://ieeexplore.ieee.org/abstract/document/10113704/,attention mechanism that can efficiently extract and utilize the knowledge in each transformer  layer ] searched high-performed transformer-based models through one-shot architecture,"N Li, Y Chen, W Li, Z Ding, D Zhao",2023,‚Ä¶ on Neural Networks and ‚Ä¶,0.7753639334312187,0.8256461390128296,0.8005050362220241
Multi-head self-attention via vision transformer for zero-shot learning,https://arxiv.org/abs/2108.00045,"In this work, we propose an attention-based model in the  an attention mechanism adapted  from Vision Transformer to  as attention mechanism is included in these models architecture.","F Alamri, A Dutta",2021,arXiv preprint arXiv:2108.00045,0.7715195726143854,0.8292603717305327,0.800389972172459
A transformer-based gan for anomaly detection,https://link.springer.com/chapter/10.1007/978-3-031-15931-2_29,"a novel Transformer-based architecture for anomaly  In the self-attention module, different  heads can pay attention to different pixels and areas in the image via the attention mechanism","C Yang, S Lan, W Huang, W Wang, G Liu",2022,‚Ä¶ Neural Networks,0.7964391242208673,0.8042814590106699,0.8003602916157686
On the usefulness of self-attention for automatic speech recognition with transformers,https://ieeexplore.ieee.org/abstract/document/9383521/,"For attention-based RNN models, the attention mechanism  train a baseline model with a  12-layer self-attention encoder.  designing novel network architecture based on our findings.","S Zhang, E Loweimi, P Bell",2021,2021 IEEE Spoken ‚Ä¶,0.7789448191416184,0.8217669720925488,0.8003558956170835
An effective video transformer with synchronized spatiotemporal and spatial self-attention for action recognition,https://ieeexplore.ieee.org/abstract/document/9834306/,"spatial attention by another spatial self-attention module in  It expands the model architecture  by adapting six axes,  layer) that is added on top of the temporal selfattention module.","S Alfasly, CK Chui, Q Jiang, J Lu",2022,‚Ä¶ on Neural Networks and ‚Ä¶,0.7853612036107542,0.8145108083414285,0.7999360059760914
Transformer meets convolution: A bilateral awareness network for semantic segmentation of very fine resolution urban scene images,https://www.mdpi.com/2072-4292/13/16/3065,"linear attention mechanism, a feature aggregation module is  , an entirely novel architecture  named Transformer [45] has  layer with BN and ReLU is deployed to obtain the attention","L Wang, R Li, D Wang, C Duan, T Wang, X Meng",2021,Remote Sensing,0.7933932692274956,0.8058511423799319,0.7996222058037138
Localvit: Bringing locality to vision transformers,https://arxiv.org/abs/2104.05707,the sequence from the self-attention module must be rearranged  The new transformer  architecture combines a self-attention  within aa sequence owing to their attention mechanism [42,"Y Li, K Zhang, J Cao, R Timofte, L Van Gool",2021,arXiv preprint arXiv ‚Ä¶,0.789995678599235,0.8089919648930362,0.7994938217461356
Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting,https://proceedings.neurips.cc/paper/2019/hash/6775a0635c302542da2c32aa19d86be0-Abstract.html,new architecture which leverages attention mechanism to  The well-known self-attention  based Transformer [1] has recently  a 3-layer canonical Transformer with standard self-attention.,"S Li, X Jin, Y Xuan, X Zhou, W Chen",2019,Advances in neural ‚Ä¶,0.7940950616854541,0.8048797597164254,0.7994874107009398
Easy attention: A simple self-attention mechanism for transformer-based time-series reconstruction and prediction,https://www.researchsquare.com/article/rs-3545247/latest,", we propose a novel attention mechanism called easy attention which we demonstrate in   sparse multi-head easy attention as the easy attention module on the proposed architecture","R Vinuesa, M Sanchis-Agudo, Y Wang, L Guastoni",2023,NA,0.7804384498757329,0.8178511357596427,0.7991447928176878
Architecting an enterprise financial management model: leveraging multi-head attention mechanism-transformer for user information transformation,https://peerj.com/articles/cs-1928/,"refined Transformer network, the multi-head attention mechanism ( This mechanism endows  the network with heightened semantic  Each module includes a 1-D convolution layer with","W Yu, H Hamam",2024,PeerJ Computer Science,0.8044983026791397,0.7936770435844135,0.7990876731317766
Attention transformer mechanism and fusion-based deep learning architecture for MRI brain tumor classification system,https://www.sciencedirect.com/science/article/pii/S1746809423005529,model that integrates the Transformer Module (TM) with the  utilizes a normalized dot product  attention mechanism [48]. Input x i in  A fusion layer with a bidirectional fusion architecture,"S Tabatabaei, K Rezaee, M Zhu",2023,Biomedical Signal Processing and ‚Ä¶,0.785305030033919,0.8122675225028098,0.7987862762683644
U-shaped transformer with frequency-band aware attention for speech enhancement,https://ieeexplore.ieee.org/abstract/document/10100864/,"to the conventional attention mechanism, the self-attention  attention based UTransformer  with the frequency-band aware attentions. Each block in the overall architecture of the network","Y Li, Y Sun, W Wang, SM Naqvi",2023,IEEE/ACM Transactions on ‚Ä¶,0.7922149545638595,0.8045013752103629,0.7983581648871112
Rethinking U‚Äênet from an attention perspective with transformers for osteosarcoma MRI image segmentation,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/7973404,"osteosarcoma image segmentation architecture, UATransNet , multilevel guided attention  mechanism, and multiscale jump  model with a multilevel guided self-aware attention module (","T Ouyang, S Yang, F Gou, Z Dai",2022,Computational ‚Ä¶,0.7965622250792332,0.799662591866622,0.7981124084729276
Plg-vit: Vision transformer with parallel local and global self-attention,https://www.mdpi.com/1424-8220/23/7/3447,"This attention mechanism allows the modeling of  Instead, we replaced self-attention with  a pyramid-pooling module along  Model architecture of our PLG-SA block. The PLG-ViT block","N Ebert, D Stricker, O Wasenm√ºller",2023,Sensors,0.7789380438669272,0.8172702931126645,0.7981041684897958
Occlusion-aware spatial attention transformer for occluded object recognition,https://www.sciencedirect.com/science/article/pii/S0167865522001581,Visual Transformer (ViT) [5] uses the attention mechanism on  We adopt ViT as our backbone  architecture to analyze  the speed effects of adding OMP module in Table 5. The inference,"J Heo, Y Wang, J Park",2022,Pattern Recognition Letters,0.7741094040721174,0.82163971357522,0.7978745588236686
A time patch dynamic attention transformer for enhanced well production forecasting in complex oilfield operations,https://www.sciencedirect.com/science/article/pii/S036054422402961X,"fusion causal temporal attention mechanism, effectively overcoming  into an improved  Transformer architecture, retaining its  enables the model to adaptively allocate attention based on","T Huang, H Qian, Z Huang, NH Xu, X Huang, D Yin",2024,Energy,0.7894310920931323,0.8062375095542699,0.7978343008237011
Contrans: Improving transformer with convolutional attention for medical image segmentation,https://link.springer.com/chapter/10.1007/978-3-031-16443-9_29,"module including depthwise convolution, channel attention,  , and leverage the attention  mechanism to reduce feature redundancy  In this paper, we propose a novel architecture termed","A Lin, J Xu, J Li, G Lu",2022,‚Ä¶ Conference on Medical Image Computing and ‚Ä¶,0.7938975607094393,0.8014082656653705,0.7976529131874048
Transformer tracking with cyclic shifting window attention,http://openaccess.thecvf.com/content/CVPR2022/html/Song_Transformer_Tracking_With_Cyclic_Shifting_Window_Attention_CVPR_2022_paper.html,We propose a novel transformer architecture with multi-scale  we consider the transformer  as a feature matching module to  transformer naively and do touch the attention mechanism,"Z Song, J Yu, YPP Chen",2022,Proceedings of the IEEE ‚Ä¶,0.7877932431210747,0.8073499799090946,0.7975716115150846
Recent advances in vision transformer: A survey and outlook of recent work,https://arxiv.org/abs/2203.01536,"This transformer is solely based on attention mechanism,  a reattention module, which  regenerated the attention map  volumetric transformer and proposed a unique architecture UNETR",K Islam,2022,arXiv preprint arXiv:2203.01536,0.788258768053631,0.8066713917822528,0.7974650799179419
Crossformer++: A versatile vision transformer hinging on cross-scale attention,https://ieeexplore.ieee.org/abstract/document/10366193/,"of the powerful attention mechanism. Early vision  layer after the linear transformation layer  of the self-attention module. It  Anyway, most works that focus on transformer architecture","W Wang, W Chen, Q Qiu, L Chen, B Wu",2023,‚Ä¶ on Pattern Analysis ‚Ä¶,0.7896141582942078,0.8046121548001467,0.7971131565471772
Visualizing and understanding patch interactions in vision transformer,https://ieeexplore.ieee.org/abstract/document/10132428/,"We propose a window-free modified attention mechanism to  a simple yet transformer  architecture by incorporating the  Therefore, the window-free multihead attention module computes","J Ma, Y Bai, B Zhong, W Zhang",2023,‚Ä¶ on Neural Networks ‚Ä¶,0.7842436233686433,0.8097123370382769,0.7969779802034601
A free lunch from vit: Adaptive attention multi-scale fusion transformer for fine-grained visual recognition,https://ieeexplore.ieee.org/abstract/document/9747591/,"vision due to its attention mechanism. Nonetheless, with the  transform layer, the Selective  Attention Collection Module ( warded to a network to produce our layer attention ùëÄùêø ‚àà ‚ÑùùëÅ","Y Zhang, J Cao, L Zhang, X Liu, Z Wang",2022,ICASSP 2022-2022 ‚Ä¶,0.7718169858240506,0.8221097374200985,0.7969633616220746
Facial Expression Recognition Based on Vision Transformer with Hybrid Local Attention,https://www.mdpi.com/2076-3417/14/15/6471,"without changing the architecture of the network model itself.  In this paper, we propose a  local hybrid attention mechanism  Transformer with the proposed hybrid local attention module","Y Tian, J Zhu, H Yao, D Chen",2024,Applied Sciences,0.7834207886799621,0.8102945465293696,0.7968576676046659
Couplformer: Rethinking vision transformer with coupling attention,https://openaccess.thecvf.com/content/WACV2023/html/Lan_Couplformer_Rethinking_Vision_Transformer_With_Coupling_Attention_WACV_2023_paper.html,Recent efforts have shown that Transformer and attention-based models have become   model‚Äôs overall architecture to reach a better result. We believe our coupled attention mechanism,"H Lan, X Wang, H Shen, P Liang",2023,Proceedings of the ‚Ä¶,0.793874692943486,0.799683203824691,0.7967789483840886
A study on transformer-based object detection,https://ieeexplore.ieee.org/abstract/document/9498550/,"of them are based on the attention mechanism. In this work,  layer has a multi-head attention  module, masked multi-head  Since the transformer has a permutation invariant architecture","H Vaidwan, N Seth, AS Parihar",2021,‚Ä¶ conference on intelligent ‚Ä¶,0.7962440700960609,0.7972899255495687,0.7967669978228148
Learning multiple attention transformer super-resolution method for grape disease recognition,https://www.sciencedirect.com/science/article/pii/S0957417423032190,"enhanced feature attention mechanism module CSAB are  layer, two concatenate layers  and an upper sampling layer ( of transformer structure construction, the shuffle architecture","H Jin, X Chu, J Qi, J Feng, W Mu",2024,Expert Systems with Applications,0.7875328527208307,0.8059489965351221,0.7967409246279764
Reducing carbon emissions in the architectural design process via transformer with cross-attention mechanism,https://www.frontiersin.org/articles/10.3389/fevo.2023.1249308/full,using an efficient neural network with transformer grouping. The  a CA-Transformer model  with a cross-attention mechanism to aid  on the Transformer module. We selected Time Series,"HD Li, X Yang, HL Zhu",2023,Frontiers in Ecology and Evolution,0.8018276049316376,0.7911559042527363,0.796491754592187
Easy attention: A simple self-attention mechanism for transformers,https://arxiv.org/abs/2308.12874,"systems, we propose a novel attention mechanism called easy attention. Due to the fact that   sparse multi-head easy attention as the easy attention module on the proposed architecture,","M Sanchis-Agudo, Y Wang, K Duraisamy",2023,arXiv preprint arXiv ‚Ä¶,0.7832263884649522,0.8092101830181264,0.7962182857415393
Parallel Attention-Based Transformer for Channel Estimation in RIS-Aided 6G Wireless Communications,https://ieeexplore.ieee.org/abstract/document/10591410/,"Transformer, ie, the attention mechanism, which is a neural network module derived from  human attention  the first convolutional layer in step 16, the attention mechanism from step 18 to","J Guo, G Liu, Q Wu, P Fan",2024,IEEE Transactions on Vehicular ‚Ä¶,0.7843093517434603,0.8079126294497833,0.7961109905966217
Attention over self-attention: Intention-aware re-ranking with dynamic transformer encoders for recommendation,https://ieeexplore.ieee.org/abstract/document/9906456/,A fundamental assumption of the transformer architecture is  merit of our dynamic self-attention  module. By assembling the  then the co-attention mechanism assigns higher matching,"Z Lin, S Zang, R Wang, Z Sun",2022,‚Ä¶ on Knowledge and ‚Ä¶,0.7803252554070338,0.8112831398199973,0.7958041976135155
A tensorized transformer for language modeling,https://proceedings.neurips.cc/paper/2019/hash/dc960c46c38bd16e953d97cdeefdbc68-Abstract.html,"Transformer [35] is based solely on the attention mechanism,  AttenTD(¬∑) is the function of  Single-block attention based on  architecture, and replace the standard multi-head attention","X Ma, P Zhang, S Zhang, N Duan",2019,Advances in neural ‚Ä¶,0.791970562923968,0.7992504524523818,0.7956105076881749
Rethinking attention mechanism in time series classification,https://www.sciencedirect.com/science/article/pii/S0020025523000968,"of the Transformer for TSC, namely flexible multi-head linear  the existing Transformer-based  models, our architecture has  CNN-based or attention-based neural networks. However,","B Zhao, H Xing, X Wang, F Song, Z Xiao",2023,Information Sciences,0.7893320614375923,0.8010295245022089,0.7951807929699006
Convolutional transformer: An enhanced attention mechanism architecture for remaining useful life estimation of bearings,https://ieeexplore.ieee.org/abstract/document/9792382/,"(MSC) module with Swish activation for Transformer architecture to  previous layer, the MHA  module concatenates the attention  With MHA module, the network can extract long distance","Y Ding, M Jia",2022,IEEE Transactions on Instrumentation and ‚Ä¶,0.7942471765898549,0.7958541758149985,0.7950506762024268
Efficient attention: Attention with linear complexities,http://openaccess.thecvf.com/content/WACV2021/html/Shen_Efficient_Attention_Attention_With_Linear_Complexities_WACV_2021_paper.html,efficient attention mechanism equivalent to dot-product attention but  The Transformer  architecture is highly successful on  ) module [10] uses global average pooling and a linear layer,"Z Shen, M Zhang, H Zhao, S Yi",2021,Proceedings of the IEEE ‚Ä¶,0.7869469065360009,0.8030956015754769,0.7950212540557389
Trtr: Visual tracking with transformer,https://arxiv.org/abs/2105.03817,"based on Transformer architecture and its attention mechanism to  model, we use 8 heads  for multi-head attention module (M = 8), and set the channel dimension of FFN hidden layer","M Zhao, K Okada, M Inaba",2021,arXiv preprint arXiv:2105.03817,0.7864387804763091,0.8032121246939739,0.7948254525851415
Algorithm-hardware co-design of attention mechanism on FPGA devices,https://dl.acm.org/doi/abs/10.1145/3477002,model architecture behind the attention mechanism. To  can compress Transformer (an  attention mechanism based model)  The Transformer is the first self-attention based model. GPT,"X Zhang, Y Wu, P Zhou, X Tang, J Hu",2021,ACM Transactions on Embedded ‚Ä¶,0.7879431911925372,0.8015906851554282,0.7947669381739827
MATNet: A combining multi-attention and transformer network for hyperspectral image classification,https://ieeexplore.ieee.org/abstract/document/10064266/,"brandnew architecture uses the self-attention mechanism to  The spatial attention mechanism  module considers the  stacks the transformer layer, we use the cross-layer connection to","B Zhang, Y Chen, Y Rong, S Xiong",2023,IEEE Transactions on ‚Ä¶,0.7769671127358805,0.8124001362618916,0.794683624498886
Evaluation of transformer model and self-attention mechanism in the Yangtze River basin runoff prediction,https://www.sciencedirect.com/science/article/pii/S2214581823001258,"The Transformer (TSF) is a newly proposed neural network  Likely, the Attention Mechanism  (AM) is a solution to arrange the  or GRU model, an SA module, and a fully connected layer.","X Wei, G Wang, B Schmalz, DFT Hagan",2023,Journal of Hydrology ‚Ä¶,0.7822304950753929,0.8067864221735936,0.7945084586244933
Point transformer,https://ieeexplore.ieee.org/abstract/document/9552005/,We aim to make use of the attention mechanism to capture the  present attention and introduce  the Transformer architecture  The network is permutation invariant due to a new module,"N Engel, V Belagiannis, K Dietmayer",2021,IEEE access,0.7957229193581696,0.792976226076949,0.7943495727175593
Miti-detr: Object detection based on transformers with mitigatory self-attention convergence,https://arxiv.org/abs/2112.13310,"to network depth, we propose a transformer architecture with  composite module of multi-head  self-attention network and  problem by attention mechanism and transformer network itself.","W Ma, T Zhang, G Wang",2021,arXiv preprint arXiv:2112.13310,0.7757111040567692,0.8129849810698125,0.794348042563291
A transformer-based method of multienergy load forecasting in integrated energy system,https://ieeexplore.ieee.org/abstract/document/9756020/,") The attention mechanism is adopted in the proposed model  FORECASTING ARCHITECTURE  In this paper, we proposed  In the multi-head attention module of the encoding layer and","C Wang, Y Wang, Z Ding, T Zheng",2022,IEEE Transactions on ‚Ä¶,0.7924724173343556,0.795953649108761,0.7942130332215582
Slide-transformer: Hierarchical vision transformer with local self-attention,http://openaccess.thecvf.com/content/CVPR2023/html/Pan_Slide-Transformer_Hierarchical_Vision_Transformer_With_Local_Self-Attention_CVPR_2023_paper.html,"human design, which sets the least restrictions on the model architecture design.  attention  mechanism and address its efficiency overhead by proposing a novel Slide Attention module","X Pan, T Ye, Z Xia, S Song",2023,Proceedings of the IEEE ‚Ä¶,0.7872267448634859,0.8011504960011394,0.7941886204323126
Multimodal channel-wise attention transformer inspired by multisensory integration mechanisms of the brain,https://www.sciencedirect.com/science/article/pii/S0031320322003181,"with the top-down attention mechanism in the brain, we  MCAT architecture, which consists  of N layers; each layer  and layer normalization concluded in the multi-head attention module,","Q Shi, J Fan, Z Wang, Z Zhang",2022,Pattern Recognition,0.7906584931523998,0.7976691449507676,0.7941638190515836
Synthesizer: Rethinking self-attention for transformer models,https://proceedings.mlr.press/v139/tay21a.html,"-based content retrieval as an attention mechanism. On the other end  Synthetic Attention,  our proposed self-attention module. Our  For simplicity, we describe the per head and per layer","Y Tay, D Bahri, D Metzler, DC Juan",2021,International ‚Ä¶,0.7769801797978018,0.8112598589812279,0.7941200193895148
Transformer networks for trajectory forecasting,https://ieeexplore.ieee.org/abstract/document/9412190/,"only-attention-based memory mechanisms of Transformers.  , weighting them according  to an attention mechanism.  Compared to these techniques, our transformer architecture","F Giuliari, I Hasan, M Cristani",2021,2020 25th international ‚Ä¶,0.793847036822616,0.7943691781465998,0.7941081074846079
Evolving attention with residual convolutions,https://proceedings.mlr.press/v139/wang21ab.html,The attention maps are indispensable for a transformer model to  ‚Ä¢ We propose a novel  evolving attention mechanism aug module that generalizes attention maps in the current layer,"Y Wang, Y Yang, J Bai, M Zhang, J Bai",2021,International ‚Ä¶,0.7858246451646765,0.8023373844656918,0.7940810148151842
Ps-transformer: Learning sparse photometric stereo network using self-attention mechanism,https://arxiv.org/abs/2211.11386,PMA (Pooling by Multihead Attention) module [17] which applies multi-head attention on a   the architecture. This illustrates that how the attention mechanism from the transformer models,S Ikehata,2022,arXiv preprint arXiv:2211.11386,0.7912273028264576,0.7968136352799802,0.7940204690532189
Transformer model incorporating local graph semantic attention for image caption,https://link.springer.com/article/10.1007/s00371-023-03180-7,"‚Äìdecoder architecture for image caption, and with the introduction of the attention mechanism,   enters the multi-head self-attention module in the encoder to get the image feature space","K Qian, Y Pan, H Xu, L Tian",2023,The Visual Computer,0.7855235799864081,0.8024281568789462,0.7939758684326772
Neighborhood attention transformer,http://openaccess.thecvf.com/content/CVPR2023/html/Hassani_Neighborhood_Attention_Transformer_CVPR_2023_paper.html,"and scalable sliding window attention mechanism for vision. NA is  more vision transformers,  and attentionbased models in  An illustration of the overall network architecture is presented","A Hassani, S Walton, J Li, S Li",2023,Proceedings of the IEEE ‚Ä¶,0.7927399835398976,0.7949258142976954,0.7938328989187965
AttentionMGT-DTA: A multi-modal drug-target affinity prediction using graph transformer and attention mechanism,https://www.sciencedirect.com/science/article/pii/S089360802300641X,"Thus, a cross-attention module was leveraged in our method  Secondly, the architecture of  graph transformer model  define the detailed update process of the l th layer: (6) Q i j k , l = Q k","H Wu, J Liu, T Jiang, Q Zou, S Qi, Z Cui, P Tiwari",2024,Neural Networks,0.7899454606892056,0.7970950537720881,0.7935202572306468
A survey on visual transformer,https://arxiv.org/abs/2012.12556,[9] first proposed transformer based on attention mechanism for  is similar to the self-attention  layer in the encoder module  model named TransPose based on Transformer architecture,"K Han, Y Wang, H Chen, X Chen, J Guo, Z Liu",2020,arXiv preprint arXiv ‚Ä¶,0.7856563815893781,0.8013735360966547,0.7935149588430164
Deepvit: Towards deeper vision transformer,https://arxiv.org/abs/2103.11886,"architecture, we would like to highlight that the self-attention  replace the self-attention module  in ViT with Reattention and  and propose a novel Re-attention mechanism to solve it with","D Zhou, B Kang, X Jin, L Yang, X Lian, Z Jiang",2021,arXiv preprint arXiv ‚Ä¶,0.764734299293633,0.8222890537969304,0.7935116765452817
Multi-scale hierarchical vision transformer with cascaded attention decoding for medical image segmentation,https://proceedings.mlr.press/v227/rahman24a.html,"an attention-based decoder, namely Cascaded Attention  as follows: ‚Ä¢ New Transformer  Architecture: We propose a  vision transformer using a spatial reduction attention mechanism.","MM Rahman, R Marculescu",2024,Medical Imaging with Deep ‚Ä¶,0.7777273140478049,0.8092577138640513,0.7934925139559281
Psvit: Better vision transformer via token pooling and attention sharing,https://arxiv.org/abs/2108.03428,The flexible attention mechanism of the transformer in the whole pipeline intrigued the   independent multi-head attention module in designing the overall transformer architecture.,"B Chen, P Li, B Li, C Li, L Bai, C Lin, M Sun",2021,arXiv preprint arXiv ‚Ä¶,0.7745353046675332,0.8122092476864711,0.7933722761770021
Local multi-head channel self-attention for facial expression recognition,https://www.mdpi.com/2078-2489/13/9/419,"multi-Head Channel self-attention, a novel self-attention module  alone spatial self-attention  architecture in which the transformer‚Äô to improve the attention mechanism of the Transformer.","R Pecoraro, V Basile, V Bono",2022,Information,0.7722827833568322,0.81446036696028,0.7933715751585562
Transformer interpretability beyond attention visualization,http://openaccess.thecvf.com/content/CVPR2021/html/Chefer_Transformer_Interpretability_Beyond_Attention_Visualization_CVPR_2021_paper.html,lack of conservation in the attention mechanism due to matrix  The self-attention module  operates on a small sub-space dh  the architecture and propagation of information in the network,"H Chefer, S Gur, L Wolf",2021,‚Ä¶ of the IEEE/CVF conference on ‚Ä¶,0.7828786921705123,0.8037801147278496,0.7933294034491809
Per-former: rethinking person re-identification using transformer augmented with self-attention and contextual mapping,https://link.springer.com/article/10.1007/s00371-022-02577-0,"transformer architecture with a lightweight self-attention module,  The spatial transformer  networks module samples an  of SCM module in each layer of the baseline architecture","N Pervaiz, MM Fraz, M Shahzad",2023,The Visual Computer,0.7890459350593713,0.7972448878211054,0.7931454114402383
A novel time‚Äìfrequency Transformer based on self‚Äìattention mechanism and its application in fault diagnosis of rolling bearings,https://www.sciencedirect.com/science/article/pii/S0888327021009468,"latest Transformer architecture based on attention mechanism has  only embed attention  mechanism as an auxiliary module into  a two-layer feed-forward network, whose hidden layer is","Y Ding, M Jia, Q Miao, Y Cao",2022,Mechanical Systems and Signal Processing,0.788374201581979,0.7978651663134477,0.7931196839477134
Hyperspectral image classification with multi-attention transformer and adaptive superpixel segmentation-based active learning,https://ieeexplore.ieee.org/abstract/document/10167502/,", the self-attention module of Transformer is applied to model  The detailed architecture of  multi-attention Transformer (MAT The value is computed via a linear layer WV ‚àà RC√óC, and V","C Zhao, B Qin, S Feng, W Zhu, W Sun",2023,IEEE Transactions on ‚Ä¶,0.7716270740554201,0.8145827525183049,0.7931049132868625
Dynamic multi-headed self-attention and multiscale enhancement vision transformer for object detection,https://link.springer.com/article/10.1007/s11042-024-18234-8,"redesigned module, even in a single layer, the network can  Table 1 Layer wise architecture  of DGANet-ViT. Each stage  -headed self-attention mechanism, which enabled the model to","S Fang, X Lu, Y Huang, G Sun, X Liu",2024,Multimedia Tools and Applications,0.7719485845313174,0.8138894015650071,0.7929189930481623
Sparse MLP for image recognition: Is self-attention really necessary?,https://ojs.aaai.org/index.php/AAAI/article/view/20133,whether the core self-attention module in Transformer is the key  (a) illustrates the overall  architecture of our designed network.  this fusion module with concatenation and a FC layer:,"C Tang, Y Zhao, G Wang, C Luo, W Xie",2022,Proceedings of the AAAI ‚Ä¶,0.7731191217829153,0.812650866879538,0.7928849943312266
A novel transformer network with a CNN-enhanced cross-attention mechanism for hyperspectral image classification,https://www.mdpi.com/2072-4292/16/7/1180,"from the previous module. Firstly, we apply a 2D convolutional layer with kernel sizes of ( 3   (1) Batch Size: Due to our observation that the performance of the transformer architecture","X Wang, L Sun, C Lu, B Li",2024,Remote Sensing,0.7811624572632683,0.8043504351207563,0.7927564461920122
Multi-view self-attention based transformer for speaker recognition,https://ieeexplore.ieee.org/abstract/document/9746639/,"These works utilize the attention mechanism as a selection of  We study five variants of the  Transformer architecture for iden with a 6-layer encoder, a 3-layer decoder, 512 attention size,","R Wang, J Ao, L Zhou, S Liu, Z Wei, T Ko",2022,ICASSP 2022-2022 ‚Ä¶,0.7767052402104736,0.8087223489375531,0.7927137945740134
Double attention transformer for hyperspectral image classification,https://ieeexplore.ieee.org/abstract/document/10052741/,"is devised for cross-layer feature fusion. Experimental results  Fig.1 shows the architecture  of the proposed framework, which  networks including only one type of self-attention module,","P Tang, M Zhang, Z Liu, R Song",2023,IEEE Geoscience and ‚Ä¶,0.7788753723238903,0.8058563050463691,0.7923658386851297
A lightweight transformer network for hyperspectral image classification,https://ieeexplore.ieee.org/abstract/document/10189879/,attention module that feeds attention heads with different splits of the full features to reduce  computational redundancy. A super token attention mechanism [ a hybrid architecture for HSI,"X Zhang, Y Su, L Gao, L Bruzzone",2023,IEEE Transactions on ‚Ä¶,0.7847582721274184,0.7996514223243352,0.7922048472258768
Vision transformer attention with multi-reservoir echo state network for anomaly recognition,https://www.sciencedirect.com/science/article/pii/S0306457323000262,architecture into them. The vision transformer uses the transformer encoder module to   As a result of the deep features extracted with the attention mechanism from the consecutive,"W Ullah, T Hussain, SW Baik",2023,Information Processing & Management,0.7807845811218537,0.8034943368969667,0.7921394590094102
Twins transformer: Cross-attention based two-branch transformer network for rotating bearing fault diagnosis,https://www.sciencedirect.com/science/article/pii/S0263224123012514,"The Transformer architecture is already working well in various  relies on the attention  mechanism to build the model. Therefore,  The first sub-layer is the two-branches Twins Attention","J Li, Y Bao, WX Liu, PX Ji, LK Wang, Z Wang",2023,Measurement,0.8002304691108744,0.784020899450492,0.7921256842806832
Vitbis: Vision transformer for biomedical image segmentation,https://link.springer.com/chapter/10.1007/978-3-030-90874-4_4,a novel network incorporating attention mechanism in transformer architecture along with  multi scale module  The structure of Transformer layer used in this work is illustrated in Fig. 1:,A Sagar,2021,MICCAI Workshop on Distributed and Collaborative ‚Ä¶,0.7706479355753101,0.8135803624579091,0.7921141490166096
Sanvis: Visual analytics for understanding self-attention networks,https://ieeexplore.ieee.org/abstract/document/8933677/,"inspired by humans‚Äô attention mechanism, have seen  -of-the-art self-attention model  called Transformer, we demon self-attention module originally proposed in Transformer [26].","C Park, I Na, Y Jo, S Shin, J Yoo",2019,2019 IEEE ‚Ä¶,0.7699608288647126,0.8140331824072327,0.7919970056359726
Transformer-based multivariate time series anomaly detection using inter-variable attention mechanism,https://www.sciencedirect.com/science/article/pii/S0950705124001424,bring forth an anomaly interpretation module to shed light on  employing the Transformer  [21] architecture. Although  √ó d model is the hidden representation of the l th layer. Lastly,"H Kang, P Kang",2024,Knowledge-Based Systems,0.7819211637377793,0.8019327680467142,0.7919269658922468
Low-rank and locality constrained self-attention for sequence modeling,https://ieeexplore.ieee.org/abstract/document/8894858/,", we parameterize the selfattention module with two constraints the learned attention matrix  with the Transformer architecture.  layer structure, we further design a Transformerlike model","Q Guo, X Qiu, X Xue, Z Zhang",2019,IEEE/ACM Transactions on ‚Ä¶,0.782151955912871,0.8011981930738022,0.7916750744933366
Medical transformer: Gated axial-attention for medical image segmentation,https://link.springer.com/chapter/10.1007/978-3-030-87193-2_4,"an additional control mechanism in the self-attention module.  -sensitive axial attention  mechanism where we introduce four  architecture MedT performs better than Gated axial attention,","JMJ Valanarasu, P Oza, I Hacihaliloglu",2021,Medical image computing ‚Ä¶,0.787013631620663,0.7961442647759467,0.7915789481983049
Fault detection of complicated processes based on an enhanced transformer network with graph attention mechanism,https://www.sciencedirect.com/science/article/pii/S0957582024003641,"This architecture is distinguished by its multiple layers, each  layer is equipped with a  multi-head self-attention mechanism includes a multi-head attention mechanism module for","Y Cao, X Tang, X Deng, P Wang",2024,Process Safety and Environmental ‚Ä¶,0.7898982237239882,0.7929327027052808,0.7914154632146345
Crossvit: Cross-attention multi-scale vision transformer for image classification,http://openaccess.thecvf.com/content/ICCV2021/html/Chen_CrossViT_Cross-Attention_Multi-Scale_Vision_Transformer_for_Image_Classification_ICCV_2021_paper.html,"cross-attention module, in which each transformer branch  of our proposed transformer  architecture for learning multi- a cross-attention module of a given xl with layer normalization","CFR Chen, Q Fan, R Panda",2021,Proceedings of the IEEE/CVF ‚Ä¶,0.7737577508429025,0.8086840210606859,0.7912208859517942
Face-based age estimation using improved Swin Transformer with attention-based convolution,https://www.frontiersin.org/articles/10.3389/fnins.2023.1136934/full,"We also reviewed the attention mechanism and Transformer,  The architecture of  attention-based convolution is shown in  layer X was used as the input of the attention mechanism.","C Shi, S Zhao, K Zhang, Y Wang, L Liang",2023,Frontiers in Neuroscience,0.7784723720797366,0.8039655744608264,0.7912189732702815
Fine-grained citation count prediction via a transformer-based model with among-attention mechanism,https://www.sciencedirect.com/science/article/pii/S0306457321002776,"architecture of the transformer.  After that, the Scaled Dot-Product Attention module calculated  the inner  blocks of the encoder layer of the transformers. Actually, it can also be used","S Huang, Y Huang, Y Bu, W Lu, J Qian",2022,Information Processing & ‚Ä¶,0.7776360375095839,0.8047693156301431,0.7912026765698634
Decoding selective auditory attention with EEG using a transformer model,https://www.sciencedirect.com/science/article/pii/S1046202322000986,"-decoder architecture model for auditory attention detection  that introducing an attention  mechanism will help improve  attention- mechanism, including a temporal self-attention module","Z Xu, Y Bai, R Zhao, H Hu, G Ni, D Ming",2022,Methods,0.7850700646737234,0.7973175295869934,0.7911937971303584
Improved transformer for high-resolution gans,https://proceedings.neurips.cc/paper/2021/hash/98dce83da57b0395e163467c9dae521b-Abstract.html,a cross-attention module performing attention between the  attention mechanism. We follow  the decoder form of Nested  architecture of these stages as multi-axis Nested Transformer,"L Zhao, Z Zhang, T Chen",2021,Advances in Neural ‚Ä¶,0.7839486196451227,0.7983911261921643,0.7911698729186436
Learning contextual transformer network for image inpainting,https://dl.acm.org/doi/abs/10.1145/3474085.3475426,"a multi-scale multi-head attention module to better model the affinity  ‚Ä¢ We propose a novel  transformer architecture network for  a multi-headed attention mechanism on the same scale,","Y Deng, S Hui, S Zhou, D Meng, J Wang",2021,Proceedings of the 29th ACM ‚Ä¶,0.7873482585648914,0.7948574955588934,0.7911028770618924
Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers,http://openaccess.thecvf.com/content/ICCV2021/html/Chefer_Generic_Attention-Model_Explainability_for_Interpreting_Bi-Modal_and_Encoder-Decoder_Transformers_ICCV_2021_paper.html,"Recall the attention mechanism presented in [40]:  at each layer, we can consider an  aggregated self-attention matrix Rqq as  a self-attention based architecture, and the second model","H Chefer, S Gur, L Wolf",2021,Proceedings of the IEEE/CVF ‚Ä¶,0.7704429239019932,0.811467187773009,0.7909550558375011
Deep learning-based identification of maize leaf diseases is improved by an attention mechanism: Self-attention,https://www.frontiersin.org/articles/10.3389/fpls.2022.864486/full,"In this study, we found that transformer and self-attention  The standard model architecture.  Stage 1 extracts information  module of the whole network, and the essential part of it is","X Qian, C Zhang, L Chen, K Li",2022,Frontiers in Plant Science,0.7814392170687137,0.7998126023487254,0.7906259097087196
Variational attention-based interpretable transformer network for rotary machine fault diagnosis,https://ieeexplore.ieee.org/abstract/document/9887963/,"attention mechanism is widely applied to interpreting model  Our proposed model architecture  is comprised of a feature  in the multihead self-attention layer, and we will describe it in","Y Li, Z Zhou, C Sun, X Chen",2022,‚Ä¶ on neural networks and ‚Ä¶,0.7769341504834708,0.8043131616510176,0.7906236560672442
DI-Unet: Dimensional interaction self-attention for medical image segmentation,https://www.sciencedirect.com/science/article/pii/S1746809422004062,"basic network architecture based on Transformer structure  processed by the attention  mechanism in different windows. It  network, and the Cross-Window(CsWin) Self-Attention module","Y Wu, G Wang, Z Wang, H Wang, Y Li",2022,Biomedical Signal Processing and ‚Ä¶,0.7753600821069315,0.8057682779147967,0.790564180010864
Pale transformer: A general vision transformer backbone with pale-shaped attention,https://ojs.aaai.org/index.php/AAAI/article/view/20176,"Consequently, their receptive fields in a single attention layer  2021d) proposed a cascade  Transformer architecture to  , the proposed PS-Attention module for capturing contextual","S Wu, T Wu, H Tan, G Guo",2022,Proceedings of the AAAI Conference on ‚Ä¶,0.7974865739304614,0.7836027287052163,0.7905446513178389
"ELSA: Hardware-software co-design for efficient, lightweight self-attention mechanism in neural networks",https://ieeexplore.ieee.org/abstract/document/9499860/,"of the attention mechanism is the self-attention mechanism,  layer in Transformer-style models  with the self-attention [48], [ to the attention computation module. The candidate selection","TJ Ham, Y Lee, SH Seo, S Kim, H Choi",2021,‚Ä¶ Architecture (ISCA),0.7815299139837357,0.7994936273233308,0.7905117706535333
An attention-based multiscale transformer network for remote sensing image change detection,https://www.sciencedirect.com/science/article/pii/S092427162300182X,Siamese network based on the CNN-transformer architecture  and attention mechanism with  the transformer structure for  multi-layer perception (MLP) to obtain the channel attention M c,"W Liu, Y Lin, W Liu, Y Yu, J Li",2023,ISPRS Journal of Photogrammetry and ‚Ä¶,0.7804999219613984,0.7997417383735418,0.79012083016747
Lightweight Vision Transformer with Spatial and Channel Enhanced Self-Attention,https://openaccess.thecvf.com/content/ICCV2023W/RCV/html/Zheng_Lightweight_Vision_Transformer_with_Spatial_and_Channel_Enhanced_Self-Attention_ICCVW_2023_paper.html,"principles of lightweight transformer architecture design [8, 16] We use the SE module  in [4] as a channel attention operation our network is Spatial and Channel enhanced Self-Attention,","J Zheng, L Yang, Y Li, K Yang",2023,Proceedings of the ‚Ä¶,0.7772935592104802,0.8028842162029269,0.7900888877067036
Vision-language transformer and query generation for referring segmentation,http://openaccess.thecvf.com/content/ICCV2021/html/Ding_Vision-Language_Transformer_and_Query_Generation_for_Referring_Segmentation_ICCV_2021_paper.html,"However, most of them only utilize the attention mechanism  attention based architecture,  which helps us to easily model  an attention map from the second layer of the transformer","H Ding, C Liu, S Wang, X Jiang",2021,Proceedings of the IEEE ‚Ä¶,0.7813556510863668,0.7986392742339956,0.7899974626601812
STGAFormer: Spatial‚Äìtemporal Gated Attention Transformer based Graph Neural Network for traffic flow forecasting,https://www.sciencedirect.com/science/article/pii/S156625352400006X,the encoder architecture based on the transformer model to  By employing the multi-head  attention mechanism to capture  This paper proposes a distance spatial self-attention module to,"Z Geng, J Xu, R Wu, C Zhao, J Wang, Y Li, C Zhang",2024,Information Fusion,0.7780147362373564,0.8019751775474164,0.7899949568923864
Multi-gate attention network for image captioning,https://ieeexplore.ieee.org/abstract/document/9382255/,"-layernorm transformer to simplify the transformer architecture  network, [1] first integrates  the spatial attention mechanism  a SG module to consider the intra-object attention distribution","W Jiang, X Li, H Hu, Q Lu, B Liu",2021,IEEE Access,0.7832653395555585,0.7965014310617293,0.789883385308644
Towards robust diagnosis of COVID-19 using vision self-attention transformer,https://www.nature.com/articles/s41598-022-13039-x,"CNN architecture 11 . To enhance the local related features, self-attention module performs   are significantly important relevance to machine translation using attention mechanism.","F Mehboob, A Rauf, R Jiang, AKJ Saudagar",2022,Scientific Reports,0.7645738820206607,0.8148466350425306,0.7897102585315956
R-transformer network based on position and self-attention mechanism for aspect-level sentiment classification,https://ieeexplore.ieee.org/abstract/document/8822480/,"Inspired by the human visual attention mechanism, the attention mechanism based on   PSRTN overall architecture. The PSRTN consists of three parts: The attention mechanism module","Z Zhou, Q Wang",2019,IEEE Access,0.7815885565308229,0.7978086419119785,0.7896985992214007
On exploring attention-based explanation for transformer models in text classification,https://ieeexplore.ieee.org/abstract/document/9671639/,"behind this architecture is the attention mechanism, ie, the  across the attention heads  at each layer. In reality, the  Attention-based methods try to understand the network logic","S Liu, F Le, S Chakraborty",2021,2021 IEEE International ‚Ä¶,0.7778093098515217,0.8012907266837206,0.7895500182676212
Attention calibration for transformer-based sequential recommendation,https://dl.acm.org/doi/abs/10.1145/3583780.3614785,highest attention weight learned by the self-attention module  tations of the attention  mechanism: Locker [12] contends that the  to offer a succinct overview of the transformer,"P Zhou, Q Ye, Y Xie, J Gao, S Wang, JB Kim",2023,Proceedings of the ‚Ä¶,0.7729371688180793,0.8058354700634766,0.789386319440778
Aspect-context level information extraction via transformer based interactive attention mechanism for sentiment classification,https://ieeexplore.ieee.org/abstract/document/10132475/,the network architecture containing the attention mechanism is  pre-trained interactiveattention-based  modeling method for  -layer Aspect-Context Interactive Attention (MultiACIA) model,"S Nayab, MK Hanif, R Talib, MU Sarwar",2023,IEEE Access,0.7847334691308119,0.7939778449586657,0.7893556570447389
Energy transformer,https://proceedings.neurips.cc/paper_files/paper/2023/hash/57a9b97477b67936298489e3c1417b0a-Abstract-Conference.html,"a novel architecture, called the Energy Transformer (or ET for  of the energy attention  mechanism and the corresponding  matrix in the Hopfield Network module (HN) of our model.","B Hoover, Y Liang, B Pham, R Panda",2024,Advances in ‚Ä¶,0.7894998765277927,0.7890876332916685,0.7892937549097306
A Convolutional Neural Network Based on Attention Mechanism for Designing Vibration Similarity Models of Converter Transformers,https://www.mdpi.com/2075-1702/12/1/11,"layer, convolutional layer, pooling layer, fully connected layer The attention module can  be added between different  convolutional neural network vibration prediction model for ¬±","H Wang, L Zhang, Y Sun, L Zou",2023,Machines,0.776938216469084,0.8014049375998212,0.7891715770344526
MCWS-transformers: towards an efficient modeling of protein sequences via multi context-window based scaled self-attention,https://ieeexplore.ieee.org/abstract/document/9772392/,"The use of the transformer architecture is well-established for plain  transformer module [23]:  (i) Window-based self-attention ‚Äî  Model A classifier (ie, a multi-layer perceptron network) is","A Ranjan, MS Fahad",2022,IEEE/ACM ‚Ä¶,0.7783083883125377,0.7999061468292159,0.7891072675708768
Transformer-based personalized attention mechanism for medical images with clinical records,https://www.sciencedirect.com/science/article/pii/S2153353922007854,"attention-based MIL, there is no mechanism to change the  We introduce a variant of the  Transformer architecture that  had a hidden layer with 256 units and an output layer with 3 units","Y Takagi, N Hashimoto, H Masuda, H Miyoshi",2023,Journal of Pathology ‚Ä¶,0.7816683037200132,0.7965007818949723,0.7890845428074927
Transformer based on channel-spatial attention for accurate classification of scenes in remote sensing image,https://www.nature.com/articles/s41598-022-19831-z,"First, transformer is a new encoder-decoder architecture that  Third, the self-attention  mechanism layer in transformer will  attention mechanism called the bottleneck attention module (","J Guo, N Jia, J Bai",2022,Scientific Reports,0.7782766246461148,0.799320794898841,0.7887987097724779
Glit: Neural architecture search for global and local image transformer,http://openaccess.thecvf.com/content/ICCV2021/html/Chen_GLiT_Neural_Architecture_Search_for_Global_and_Local_Image_Transformer_ICCV_2021_paper.html,"Specifically, we introduce a locality module that models the  All the above methods manually  design attention mechanism  We utilize 1D convolution layer instead of 2D convolution layer","B Chen, P Li, C Li, B Li, L Bai, C Lin",2021,Proceedings of the ‚Ä¶,0.7759740232784499,0.8013154799364274,0.7886447516074386
Video transformer network,http://openaccess.thecvf.com/content/ICCV2021W/CVEU/html/Neimark_Video_Transformer_Network_ICCVW_2021_paper.html,Followed by a temporal attention-based encoder (Longformer in this  NLN demonstrated  that the core attention mechanism in Transformers can  1 demonstrates our architecture layout.,"D Neimark, O Bar, M Zohar",2021,Proceedings of the ‚Ä¶,0.7907434393906622,0.7863492877041485,0.7885463635474053
HCA-former: Hybrid Convolution Attention Transformer for 3D Medical Image Segmentation,https://www.sciencedirect.com/science/article/pii/S1746809423012673,"of CNN into the architecture of the Transformer. It confines  transformer layers are introduced  in each module, where the  a new dual-headed attention mechanism inserted into the DFB.","F Yang, F Wang, P Dong, B Wang",2024,Biomedical Signal Processing and ‚Ä¶,0.7777542894746305,0.7992951194696656,0.7885247044721481
Dual-former: Hybrid self-attention transformer for efficient image restoration,https://www.sciencedirect.com/science/article/pii/S1051200424001106,"of convolutions in an overall architecture. With convolution- For the Hybrid Transformer  Block in the latent layer, we  , we also design a local feature extraction module in parallel with","S Chen, T Ye, Y Liu, E Chen",2024,Digital Signal Processing,0.776145944604065,0.8006886592351838,0.7884173019196244
Quantifying attention flow in transformers,https://arxiv.org/abs/2005.00928,"Given the attention module with residual connection, we  , we average the attention at each  layer over all heads.  in any task or architecture that uses self-attention. We should note that","S Abnar, W Zuidema",2020,arXiv preprint arXiv:2005.00928,0.7719564540017894,0.8048137736388468,0.7883851138203181
An arrhythmia classification model based on vision transformer with deformable attention,https://www.mdpi.com/2072-666X/14/6/1155,", the transformer architecture can capture temporal features through an attention mechanism  and  First, we assess the effectiveness of the deformable attention module. In our CNN-DVIT","Y Dong, M Zhang, L Qiu, L Wang, Y Yu",2023,Micromachines,0.7691233979593373,0.8076140109232115,0.7883687044412744
A novel hybrid framework based on temporal convolution network and transformer for network traffic prediction,https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288935,"The Transformer architecture outperformed previous models  Block Attention Module (CBAM)  attention mechanism [20] to  , a layer of Transformer with a full self-attention mechanism","Z Zhang, S Gong, Z Liu, D Chen",2023,Plos one,0.7859390031135298,0.7906845841029868,0.7883117936082583
Lightweight vision transformer with cross feature attention,https://arxiv.org/abs/2207.07268,"strategies to find the optimal architecture under restrictions like  in transformer lies in the  self-attention layer. In the original  of attention module, called cross feature attention (XFA). Fol","Y Zhao, H Tang, Y Jiang, Q Wu",2022,arXiv preprint arXiv:2207.07268,0.7779392966539268,0.7984261089000706,0.7881827027769988
Introducing attention mechanism for eeg signals: Emotion recognition with vision transformers,https://ieeexplore.ieee.org/abstract/document/9629837/,"Representations from Transformers (BERT) [14] architecture,  Then a SoftMax layer followed  by an ArgMax layer is applied  multi-headed attention-based mechanism, the model is able","A Arjun, AS Rajpoot",2021,2021 43rd annual ‚Ä¶,0.7744283177077421,0.8016099561318235,0.7880191369197829
Two-stream transformer network for sensor-based human activity recognition,https://www.sciencedirect.com/science/article/pii/S0925231222011924,"propose a self-attention based Two-stream Transformer Network ( In aggregation layer, we  use the attention mechanism to  the contribution of two-stream architecture. From Table 5, we","S Xiao, S Wang, Z Huang, Y Wang, H Jiang",2022,Neurocomputing,0.7871947024747261,0.7884772248193883,0.7878359636470572
Axial Attention Transformer Networks: A New Frontier in Breast Cancer Detection,https://arxiv.org/abs/2409.12347,"an axial attention mechanism with gated units. (4) By using the axial attention module with   The U-Net architecture has been a standard in medical image segmentation, yet it falls short","W He, R Bao, Y Cang, J Wei, Y Zhang, J Hu",2024,arXiv preprint arXiv ‚Ä¶,0.7869692596463345,0.7886815543955459,0.7878254070209402
CrossFuse: A novel cross attention mechanism based infrared and visible image fusion approach,https://www.sciencedirect.com/science/article/pii/S1566253523004633,"To overcome the limitations of current transformer-based  By injecting the CAM into the  transformer architecture, the  novel attention-based loss function is proposed to train our network.","H Li, XJ Wu",2024,Information Fusion,0.7731884241751086,0.8023874152512375,0.787787919713173
Swin transformer assisted prior attention network for medical image segmentation,https://dl.acm.org/doi/abs/10.1145/3532213.3532287,"to apply pure Transformer-based U-shaped architecture to  Swin Transformer module  is consisted of LayerNorm layer,  details by applying window-based attention mechanism.","Z Liao, K Xu, N Fan",2022,Proceedings of the 8th International Conference on ‚Ä¶,0.7839387635571573,0.7910614385872747,0.787500101072216
Hand-transformer: Non-autoregressive structured modeling for 3d hand pose estimation,https://link.springer.com/chapter/10.1007/978-3-030-58595-2_2,propose to leverage the Transformer architecture with a novel  -decoder attention mechanism  used in the Transformer to  masked self-attention module of the traditional Transformer,"L Huang, J Tan, J Liu, J Yuan",2020,"‚Ä¶ Conference, Glasgow, UK, August 23‚Äì28 ‚Ä¶",0.7759347131127262,0.7990151520761832,0.7874749325944548
Cross attention is all you need: relational remote sensing change detection with transformer,https://www.tandfonline.com/doi/abs/10.1080/15481603.2024.2380126,The proposed architecture is able to excavate the long-range  cross attention model is  passed to a simple three-layer FFN  RCDT module that involves the cross attention mechanism.,"K Lu, X Huang, R Xia, P Zhang",2024,GIScience & Remote ‚Ä¶,0.7816395581417646,0.7932827255374841,0.7874611418396243
Transattunet: Multi-level attention-guided u-net with transformer for medical image segmentation,https://ieeexplore.ieee.org/abstract/document/10244199/,"segmentation architecture. Inspired by Transformer, the self-aware attention (SAA) module  with  The multi-head attention mechanism processes each attention head separately and","B Chen, Y Liu, Z Zhang, G Lu",2023,IEEE Transactions on ‚Ä¶,0.7837428066931462,0.7911714621507786,0.7874571344219624
Efficient temporal flow Transformer accompanied with multi-head probsparse self-attention mechanism for remaining useful life prognostics,https://www.sciencedirect.com/science/article/pii/S095183202200326X,"As a new architecture, the Transformer completely relies on  The encoder module mainly  undertakes the function of mining  Comparisons of different attention mechanism in various RUL","Y Chang, F Li, J Chen, Y Liu, Z Li",2022,Reliability Engineering & System Safety,0.777041315229113,0.7976467316959537,0.7873440234625333
Decomformer: Decompose Self-Attention of Transformer for Efficient Image Restoration,https://ieeexplore.ieee.org/abstract/document/10464292/,"A transformer architecture achieves outstanding  attention mechanism, D-MSA,  with previous self-attention  the attention module of the first encoder layer in the network","E Lee, Y Hwang",2024,IEEE Access,0.7813601579841641,0.793216024001492,0.7872880909928281
EMTCAL: Efficient multiscale transformer and cross-level attention learning for remote sensing scene classification,https://ieeexplore.ieee.org/abstract/document/9844016/,"First, we use a multi-layer feature extraction module (MFEM) to  the scaled dotproduct attention  mechanism, its formulation is,  transformer architecture (ie, ViT [44]) and several improved","X Tang, M Li, J Ma, X Zhang, F Liu",2022,IEEE Transactions on ‚Ä¶,0.7685301860193821,0.8058618706463339,0.787196028332858
Facial action unit detection based on transformer and attention mechanism,https://link.springer.com/chapter/10.1007/978-3-030-87358-5_37,"network based on Transformer and Attention Mechanism named  predefined attention map,  we refer to the skipping layer structure  module on the fixed attention mechanism is effective.","W Song, S Shi, G An",2021,International Conference on Image and Graphics,0.7798237298957327,0.7942403325995796,0.7870320312476562
Transformer based memory network for sentiment analysis of web comments,https://ieeexplore.ieee.org/abstract/document/8918438/,"module. We use a global self-attention mechanism and a local attention mechanism (memory   of the sequence transduction model, we need to use a novel architecture, the self-attention","M Jiang, J Wu, X Shi, M Zhang",2019,IEEE Access,0.7818579605385554,0.79195456839363,0.7869062644660927
MTAtrack: Multilevel transformer attention for visual tracking,https://www.sciencedirect.com/science/article/pii/S0030399223005522,"networks based on the Transformer attention mechanism  The overall architecture of the  MTAtrack network mainly  model, we connect every layer output of the self-attention module,","D An, F Zhang, Y Zhao, B Luo, C Yang, B Chen",2023,Optics & Laser ‚Ä¶,0.7779632030489532,0.7957176008897,0.7868404019693266
Neural speech synthesis with transformer network,https://ojs.aaai.org/index.php/AAAI/article/view/4642,"and adapt the multi-head attention mechanism to replace the  introduce the architecture of  our Transformer TTS model, and  Attention-based models for speech recognition. In Advances","N Li, S Liu, Y Liu, S Zhao, M Liu",2019,‚Ä¶ of the AAAI conference on artificial ‚Ä¶,0.7837866462360779,0.7898546459847481,0.786820646110413
Design of a modified transformer architecture based on relative position coding,https://link.springer.com/article/10.1007/s44196-023-00345-z,"transformer module, the calculation formula of self-attention is  position embedding layer.  The performance of the modified  This study uses transformer-based attention mechanism, so","W Zheng, G Gong, J Tian, S Lu, R Wang, Z Yin",2023,International Journal of ‚Ä¶,0.7766913911190989,0.7966027498145334,0.7866470704668161
ACTNet: A dual-attention adapter with a CNN-transformer network for the semantic segmentation of remote sensing imagery,https://www.mdpi.com/2072-4292/15/9/2363,"Transformer, the ResAttn module is designed as an adapter in this paper. Its dual attention  mechanism  and presented in the Vision Transformer architecture, which relies on its attention","Z Zhang, F Liu, C Liu, Q Tian, H Qu",2023,Remote Sensing,0.7684443759554003,0.8048058150748203,0.7866250955151103
Transformer tracking with multi-scale dual-attention,https://link.springer.com/article/10.1007/s40747-023-01043-1,"Attention mechanism in Transformer can fully explore the  In this paper, a novel multi-scale  dual-attention-based tracking  In this work, a Siamese network architecture is designed.","J Wang, C Lai, W Zhang, Y Wang, C Meng",2023,Complex & Intelligent Systems,0.7693845555701659,0.8038204230504453,0.7866024893103056
FAMOUS: Flexible Accelerator for the Attention Mechanism of Transformer on UltraScale+ FPGAs,https://arxiv.org/abs/2409.14023,"was designed for the multi-head attention (MHA) layer of a transformer neural network (TNN)   In this paper, the architecture supports only the attention module, but it will be expanded to","E Kabir, MA Kabir, ARJ Downey, JD Bakos",2024,arXiv preprint arXiv ‚Ä¶,0.7751925457120281,0.7978483399289347,0.7865204428204814
A hybrid network of cnn and transformer for lightweight image super-resolution,https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/html/Fang_A_Hybrid_Network_of_CNN_and_Transformer_for_Lightweight_Image_CVPRW_2022_paper.html,"Attention-based networks. Inspired by human visual system which can focus on significant  regions automatically, attention mechanism  Transformer layer (STL) adopts the architecture of","J Fang, H Lin, X Chen, K Zeng",2022,Proceedings of the IEEE ‚Ä¶,0.777743933411977,0.7952688873920217,0.7865064104019994
Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers,https://proceedings.neurips.cc/paper/2020/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html,distilling the self-attention module of the last Transformer layer of  of the student is required  to have the same architecture as its  The attention mechanism [3] has been a highly successful,"W Wang, F Wei, L Dong, H Bao",2020,Advances in Neural ‚Ä¶,0.7722455935858993,0.8003343714204827,0.786289982503191
Efficient content-based sparse attention with routing transformers,https://direct.mit.edu/tacl/article-abstract/doi/10.1162/tacl_a_00353/97776,"with a sparse routing module based on online k-means while  we train a 22 layer Routing  Transformer model with 8 heads  Overall, our work contributes an efficient attention mechanism","A Roy, M Saffar, A Vaswani, D Grangier",2021,Transactions of the ‚Ä¶,0.7790053998368802,0.7934719277570979,0.786238663796989
Hyperspectral Image Classification Using Attention-only Spatial-Spectral Network Based on Transformer,https://ieeexplore.ieee.org/abstract/document/10587243/,"new network architecture called the transformer architecture,  success of the attention  mechanism, this paper proposes a  feature extraction module (ie, the spectral attention module).","W Liao, F Wang, H Zhao",2024,IEEE Access,0.7782981772598266,0.794122125134738,0.7862101511972823
Cross-attention transformer for video interpolation,https://openaccess.thecvf.com/content/ACCV2022W/TCV/html/Kim_Cross-Attention_Transformer_for_Video_Interpolation_ACCVW_2022_paper.html,"vision transformer module and spatial attention module, still  various modules in the transformer  architecture, and derives  cross-similarity transformer and spatial attention mechanism.","HH Kim, S Yu, S Yuan",2022,Proceedings of the Asian ‚Ä¶,0.7710783435131734,0.801268459409642,0.7861734014614077
Monotonic multihead attention,https://arxiv.org/abs/1909.12406,"attention mechanism, monotonic multihead attention, which enables the Transformer model   An important feature of the Transformer is the use of a separate multihead attention module","X Ma, J Pino, J Cross, L Puzon, J Gu",2019,arXiv preprint arXiv:1909.12406,0.7787533961913298,0.793547752067475,0.7861505741294024
Robust wave-feature adaptive heartbeat classification based on self-attention mechanism using a transformer model,https://iopscience.iop.org/article/10.1088/1361-6579/ac3e88/meta,"the feature attention mechanism (FAM) and location attention  model based on the proposed  transformer model architecture,  encoder module of the transformer to perform self-attention","S Hu, W Cai, T Gao, J Zhou",2021,Physiological ‚Ä¶,0.7764965589241054,0.79579705597253,0.7861468074483178
Spectral‚Äìspatial morphological attention transformer for hyperspectral image classification,https://ieeexplore.ieee.org/abstract/document/10036472/,(in conjunction with the attention mechanism) to improve the  a transformer encoder module  and utilizing adjacent bands.  transformer architecture search subject to find out the optimal,"SK Roy, A Deria, C Shah, JM Haut",2023,IEEE Transactions on ‚Ä¶,0.7785977208994228,0.7935855519736212,0.786091636436522
PL-Transformer: a POS-aware and layer ensemble transformer for text classification,https://link.springer.com/article/10.1007/s00521-022-07872-4,"a masked multi-head attention module, a normalization layer,  a The architecture of using  transformer for text classification.  our hook function with the attention mechanism in Sect. 4.6).","Y Shi, X Zhang, N Yu",2023,Neural Computing and Applications,0.786598924979725,0.7855232768815861,0.7860611009306555
Long-short transformer: Efficient transformers for language and vision,https://proceedings.neurips.cc/paper/2021/hash/9425be43ba92c2b4454ca7bf602efad8-Abstract.html,"suffixes are our long-short term attention based on the official ViL  does not depend on the  particular architecture, and it can be  We design a novel global attention mechanism with linear","C Zhu, W Ping, C Xiao, M Shoeybi",2021,Advances in neural ‚Ä¶,0.7760090096287293,0.7961050761000159,0.7860570428643726
Centroid transformers: Learning to abstract with attention,https://arxiv.org/abs/2102.08606,"and use it to motivate the design of our new module.  the design of a new transformer  architecture, and our goal is not  to draw connection between attention mechanism and learning to","L Wu, X Liu, Q Liu",2021,arXiv preprint arXiv:2102.08606,0.7823879947314344,0.7894679295610108,0.7859279621462225
Beyond self-attention: Deformable large kernel attention for medical image segmentation,https://openaccess.thecvf.com/content/WACV2024/html/Azad_Beyond_Self-Attention_Deformable_Large_Kernel_Attention_for_Medical_Image_Segmentation_WACV_2024_paper.html,"Additionally, our proposed attention mechanism benefits  Transformer architecture, the  D-LKA Net. Evaluations of our  transformer-based pipeline featuring a double attention module","R Azad, L Niggemeier, M H√ºttemann",2024,Proceedings of the ‚Ä¶,0.7767728194634782,0.795070045123524,0.7859214322935011
Image captioning through image transformer,http://openaccess.thecvf.com/content/ACCV2020/html/He_Image_Captioning_through_Image_Transformer_ACCV_2020_paper.html,"use a recurrent neural network with attention mechanism in the decoding  architecture for  the transformer layer adapted to the image captioning task, with a modified attention module","S He, W Liao, HR Tavakoli, M Yang",2020,Proceedings of the ‚Ä¶,0.781019295121381,0.7904911424928024,0.7857552188070918
Skeleton-based action recognition via spatial and temporal transformer networks,https://www.sciencedirect.com/science/article/pii/S1077314221000631,", we introduce a Temporal Self-Attention (TSA) module to study the  Transformer (ST-TR)  network, an architecture which uses  , a layer of standard convolution with our transformer","C Plizzari, M Cannici, M Matteucci",2021,Computer Vision and Image ‚Ä¶,0.7793663242358656,0.7921115743360576,0.7857389492859617
Transformer with Hybrid Attention Mechanism for Stereo Endoscopic Video Super Resolution,https://www.mdpi.com/2073-8994/15/10/1947,"Specifically, the Swin transformer architecture is utilized in  hybrid attention block that combines  the parallel attention module  feed-forward layer in the transformer model spatially aligns","T Zhang, J Yang",2023,Symmetry,0.7815998686625627,0.7892783638819671,0.7854391162722649
Remaining useful life prediction via a deep adaptive transformer framework enhanced by graph attention network,https://www.sciencedirect.com/science/article/pii/S0142112323002232,"the attention mechanism to calculate the attention coefficients  Therefore, we propose a DAT  module for RUL estimation to  choice of neural network architecture and model parameters","P Liang, Y Li, B Wang, X Yuan, L Zhang",2023,International Journal of Fatigue,0.7723916355944763,0.7983489211386985,0.7853702783665875
When shift operation meets vision transformer: An extremely simple alternative to attention mechanism,https://ojs.aaai.org/index.php/AAAI/article/view/20142,"We propose to replace the attention layer with a simple shift  backbones are based on the  architecture of Swin Transformer already the simplest spatial modelling module, we argue that","G Wang, Y Zhao, C Tang, C Luo, W Zeng",2022,Proceedings of the AAAI ‚Ä¶,0.7797983441804517,0.7908959271287913,0.7853471356546216
Attention mechanism in intelligent fault diagnosis of machinery: A review of technique and application,https://www.sciencedirect.com/science/article/pii/S0263224122008077,"Transformer was first applied to NLP and achieved results  -based, Convolution-based  and Self-Attention-based. We will  But the full connected layer has insufficient ability to extract","H Lv, J Chen, T Pan, T Zhang, Y Feng, S Liu",2022,Measurement,0.7767340791484791,0.7938148223324115,0.7852744507404453
Cross aggregation transformer for image restoration,https://proceedings.neurips.cc/paper_files/paper/2022/hash/a37fea8e67f907311826bc1ba2654d97-Abstract-Conference.html,"Recently, Transformer architecture has been introduced into  Module to complement the  self-attention mechanism, which  44], we propose a new window attention mechanism as","Z Chen, Y Zhang, J Gu, L Kong",2022,Advances in Neural ‚Ä¶,0.7752055600781257,0.7952798502028269,0.7852427051404762
Dependency graph enhanced dual-transformer structure for aspect-based sentiment classification,https://aclanthology.org/2020.acl-main.588/,"The network architecture of our proposed DGEDT is shown  maxpooling and apply an  attention module to align contextual  Here, we utilize an attention mechanism to identify relevant","H Tang, D Ji, C Li, Q Zhou",2020,‚Ä¶ of the 58th annual meeting of the ‚Ä¶,0.7853236663525099,0.7850948392375712,0.7852092527950405
Contextual transformer networks for visual recognition,https://ieeexplore.ieee.org/abstract/document/9747984/,"a novel Transformer-style module, ie, Contextual Transformer ( way to enhance  Transformer-style architecture by exploiting the  2 through attention mechanism [36]. In particular,","Y Li, T Yao, Y Pan, T Mei",2022,IEEE Transactions on Pattern ‚Ä¶,0.778723979876313,0.7914676834760718,0.7850958316761925
Multimodal transformer for accelerated MR imaging,https://ieeexplore.ieee.org/abstract/document/9796552/,"multi-head attention mechanism, named cross attention module propose a novel transformer  architecture, named MTrans, to  task, we add a sub-pixel convolutional layer [66] to Tailtar to","CM Feng, Y Yan, G Chen, Y Xu, Y Hu",2022,IEEE Transactions on ‚Ä¶,0.778107560991235,0.792053552891338,0.7850805569412865
RPformer: A robust parallel transformer for visual tracking in complex scenes,https://ieeexplore.ieee.org/abstract/document/9764834/,"Transformer architecture with the attention mechanism to replace the correlation-based network  module propose two fresh Transformer variant structures based on attention mechanism,","F Gu, J Lu, C Cai",2022,IEEE Transactions on Instrumentation and ‚Ä¶,0.7883190307430081,0.7816567660820901,0.7849878984125491
Wild terrestrial animal re-identification based on an improved locally aware transformer with a cross-attention mechanism,https://www.mdpi.com/2076-2615/12/24/3503,"a transformer network structure with a cross-attention block ( We replace the self-attention  module of the LA transformer with  model consists of three parts, namely, the embedding layer [","Z Zheng, Y Zhao, A Li, Q Yu",2022,Animals,0.7841161801187168,0.7857894050671332,0.7849527925929249
Se (3)-transformers: 3d roto-translation equivariant attention networks,https://proceedings.neurips.cc/paper/2020/hash/15231a7ce4ba789d13b722cc5c955834-Abstract.html,"(3)-Transformer, a variant of the self-attention module for 3D  We have presented an  attention-based neural architecture  a mathematically motivated attention mechanism which can","F Fuchs, D Worrall, V Fischer",2020,Advances in neural ‚Ä¶,0.7821240574450892,0.7875443701185963,0.7848342137818427
Deep learning attention mechanism in medical image analysis: Basics and beyonds,https://www.sciltp.com/journals/ijndi/article/view/173,"The attention mechanism is usually used as a module of deep  of channel attention, hybrid  attention, and transformer in medical  [105] proposed a hybrid transformer architecture termed","X Li, M Li, P Yan, G Li, Y Jiang, H Luo",2023,‚Ä¶ Journal of Network ‚Ä¶,0.7749287480917824,0.7944155896591474,0.7846721688754649
Transformer in transformer,https://proceedings.neurips.cc/paper/2021/hash/854d9fca60b4bd07f9bb215d59ef5561-Abstract.html,"features via the attention mechanism. Basically, the visual  a new architecture, namely,  Transformer iN Transformer (TNT).  In the self-attention module, the inputs X ‚àà Rn√ód are linearly","K Han, A Xiao, E Wu, J Guo, C Xu",2021,Advances in neural ‚Ä¶,0.7836152061028572,0.7856158009431813,0.7846155035230192
Local-to-global self-attention in vision transformers,https://arxiv.org/abs/2107.04735,"1-3), we expand the self-attention module into a multi-path structure,  the detailed architecture  of the proposed LG-Transformer. As  multi-path attention mechanism and demonstrate the","J Li, Y Yan, S Liao, X Yang, L Shao",2021,arXiv preprint arXiv:2107.04735,0.7732654866976498,0.7957225744208706,0.7844940305592603
Transformers in time series: A survey,https://arxiv.org/abs/2202.07125,"module, a residual connection module followed by a layer  on both module level and  architecture level of Transformer in  multi-head attention with a multi-branch attention mechanism,","Q Wen, T Zhou, C Zhang, W Chen, Z Ma, J Yan",2022,arXiv preprint arXiv ‚Ä¶,0.7895552199421652,0.779198338797606,0.7843767793698856
HT-Net: hierarchical context-attention transformer network for medical ct image segmentation,https://link.springer.com/article/10.1007/s10489-021-03010-0,", avoiding the poor training effect of transformer-based architecture in the dataset of medical   attention mechanism of transformers, we build a HCA module following the PAA module","M Ma, H Xia, Y Tan, H Li, S Song",2022,Applied Intelligence,0.7770117162913617,0.7917153088098755,0.7843635125506185
Learning texture transformer network for image super-resolution,http://openaccess.thecvf.com/content_CVPR_2020/html/Yang_Learning_Texture_Transformer_Network_for_Image_Super-Resolution_CVPR_2020_paper.html,of the first to introduce the transformer architecture into image generation tasks attention  module to transfer the HR texture features V from the Ref image. Traditional attention mechanism,"F Yang, H Yang, J Fu, H Lu",2020,Proceedings of the IEEE ‚Ä¶,0.7731511317022723,0.7953785079853343,0.7842648198438034
Adder attention for vision transformer,https://proceedings.neurips.cc/paper/2021/hash/a57e8915461b83adefb011530b711704-Abstract.html,"network (AdderNet). We first theoretically analyze the  Transformer‚Äî which implement the  multi-head attention module  each layer, since LN is widely used in the transformer architecture","H Shu, J Wang, H Chen, L Li",2021,Advances in Neural ‚Ä¶,0.7767871426172496,0.7914977458495415,0.7841424442333955
An attention mechanism based convolutional LSTM network for video action recognition,https://link.springer.com/article/10.1007/s11042-019-7404-z,"transformer proposed in [13], we propose a novel attention based  convolutional LSTM  module following by a softmax layer is  network and keep the basic architecture as our baseline.","H Ge, Z Yan, W Yu, L Sun",2019,Multimedia Tools and Applications,0.7634286273180023,0.8047890366375966,0.7841088319777995
Recurrent video restoration transformer with guided deformable attention,https://proceedings.neurips.cc/paper_files/paper/2022/hash/02687e7b22abc64e651be8da74ec610e-Abstract-Conference.html,"Transformer [77] is the de-facto standard architecture in natural  ture refinement module that  consists of a convolution layer for  Besides, in the attention mechanism, we can further divide","J Liang, Y Fan, X Xiang, R Ranjan",2022,Advances in ‚Ä¶,0.7846300507567916,0.7835853121424068,0.7841076814495992
CAM-VT: A weakly supervised cervical cancer nest image identification approach using conjugated attention mechanism and visual transformer,https://www.sciencedirect.com/science/article/pii/S0010482523005358,"designs an ensemble learning module to further improve the  architecture, mainly focusing  on three aspects: network depth,  It adds class tokens into ViT Transformer Layer and then","Z Fan, X Wu, C Li, H Chen, W Liu, Y Zheng",2023,Computers in Biology ‚Ä¶,0.76579378199173,0.8023737717377843,0.7840837768647572
A CBAM based multiscale transformer fusion approach for remote sensing image change detection,https://ieeexplore.ieee.org/abstract/document/9855775/,attention mechanism on the basis of the convolutional neural  transformer with the  convolutional block attention module ( going through the transformer encoder layer. Split N into N,"W Wang, X Tan, P Zhang",2022,IEEE Journal of Selected ‚Ä¶,0.7794492399533228,0.7884752357296099,0.7839622378414663
Perceiver: General perception with iterative attention,http://proceedings.mlr.press/v139/jaegle21a.html,ceiver ‚Äì a model that builds upon Transformers and hence  The model leverages an asymmetric  attention mechanism to  architecture from two components: (i) a cross-attention module,"A Jaegle, F Gimeno, A Brock",2021,International ‚Ä¶,0.7833089978857616,0.7845773900445276,0.7839431939651447
Sentiment analysis with adaptive multi-head attention in Transformer,https://arxiv.org/abs/2310.14505,We propose a novel framework based on the attention mechanism  an adaptive multi-head  attention architecture (AdaptAttn)  The multi-head self-attention module is a key component in,"F Meng, D Demeter",2023,arXiv preprint arXiv:2310.14505,0.772973484538893,0.7947982274066584,0.7838858559727757
Maformer: A transformer network with multi-scale attention fusion for visual recognition,https://www.sciencedirect.com/science/article/pii/S092523122400599X,"but effective module to explore the full potential of transformers for  Some existing transformers  explore the hybrid architecture to  attention mechanism, and X l denotes the output of l th","H Sun, Y Wang, X Wang, B Zhang, Y Xin, B Zhang",2024,Neurocomputing,0.7781592479087889,0.7895443369914878,0.7838517924501384
Spatial convolutional self-attention-based transformer module for strawberry disease identification under complex background,https://www.sciencedirect.com/science/article/pii/S0168169923005094,"of an image, attention mechanism has been introduced to  Block ‚Ö£ have the same network  architecture with that of Block ‚Ö°.  map by using the output layer W o . In summary, the SCSA-","G Li, L Jiao, P Chen, K Liu, R Wang, S Dong",2023,‚Ä¶ and Electronics in ‚Ä¶,0.7708903792838229,0.7967560959237502,0.7838232376037866
Dual-aspect self-attention based on transformer for remaining useful life prediction,https://ieeexplore.ieee.org/abstract/document/9737516/,"In this method, we apply the transformer architecture [24] to  attention mechanism and temporal  convolutional network ( encoder layer uses the multihead self-attention mechanism [24] to","Z Zhang, W Song, Q Li",2022,IEEE Transactions on Instrumentation ‚Ä¶,0.776380365022901,0.7912448636841034,0.7838126143535022
Activating more pixels in image super-resolution transformer,http://openaccess.thecvf.com/content/CVPR2023/html/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.html,"Besides, we introduce an overlapping crossattention module to achieve more direct   self-attention. Our OCAB consists of an overlapping cross-attention (OCA) layer and an MLP layer","X Chen, X Wang, J Zhou, Y Qiao",2023,Proceedings of the ‚Ä¶,0.7711884144450288,0.7963974236899932,0.783792919067511
Attcat: Explaining transformers via attentive class activation tokens,https://proceedings.neurips.cc/paper_files/paper/2022/hash/20e45668fefa793bd9f2edf19be12c4b-Abstract-Conference.html,"Figure 1: An illustration of Transformer architecture. The left  Each layer consists of a  self-attention module and a skip  and (b) a feed-forward network module, coupled with layer","Y Qiang, D Pan, C Li, X Li, R Jang",2022,Advances in neural ‚Ä¶,0.7771233238431783,0.7903661063131968,0.7837447150781875
Pyramid medical transformer for medical image segmentation,https://arxiv.org/abs/2104.14702,"network architecture, namely Pyramid Medical Transformer ( axial attention module does  not concern global attention  The first integrates the attention mechanism into their CNN","Z Zhang, W Zhang",2021,arXiv preprint arXiv:2104.14702,0.7787459787267698,0.7885156313823927,0.7836308050545813
Reason Generation for Point of Interest Recommendation Via a Hierarchical Attention-Based Transformer Model,https://ieeexplore.ieee.org/abstract/document/10330074/,"architecture of our hierarchical attention-based Transformer ( as the pretraining model in the  embedding layer. In addition,  archical attention mechanism containing word-level attention","Y Wu, G Zhao, M Li, Z Zhang",2023,IEEE Transactions on ‚Ä¶,0.7802386544530622,0.7869838677331323,0.7836112610930972
Beyond self-attention: External attention using two linear layers for visual tasks,https://ieeexplore.ieee.org/abstract/document/9912362/,"a novel attention mechanism which we call external attention,  attention module named  external attention, which computes  with common CNN-based and transformer-based methods.","MH Guo, ZN Liu, TJ Mu, SM Hu",2022,IEEE Transactions on Pattern ‚Ä¶,0.763547508964231,0.8035841760608479,0.7835658425125394
Asymmetric cross-attention hierarchical network based on CNN and transformer for bitemporal remote sensing images change detection,https://ieeexplore.ieee.org/abstract/document/10045704/,a transformer module in the UNet architecture to form a CNN- CNN with the Transformer in  parallel within the module. In  the asymmetric multi-head cross-attention mechanism is critical,"X Zhang, S Cheng, L Wang, H Li",2023,IEEE Transactions on ‚Ä¶,0.7752193799695262,0.7917148357721455,0.7834671078708358
FusionNet: a convolution‚Äìtransformer fusion network for hyperspectral image classification,https://www.mdpi.com/2072-4292/14/16/4066,"that the network that uses the attention mechanism can learn  layer with Transformer,  and investigated Transformer  ‚ÄìTransformer module with an additional convolution module","L Yang, Y Yang, J Yang, N Zhao, L Wu, L Wang",2022,Remote Sensing,0.7727149125569126,0.7936991097984731,0.7832070111776929
Learning Attention from Attention: Efficient Self-Refinement Transformer for Face Super-Resolution.,https://www.ijcai.org/proceedings/2023/0115.pdf,"module which integrates shallowlayer structure and deep- mechanism for Transformer, called  Region Selection  ‚Ä¢ We propose an efficient self-refinement Transformerbased architecture","G Li, J Shi, Y Zong, F Wang, T Wang, Y Gong",2023,IJCAI,0.7696848860622825,0.7967242142103559,0.7832045501363192
Learning affinity from attention: End-to-end weakly-supervised semantic segmentation with transformers,http://openaccess.thecvf.com/content/CVPR2022/html/Ru_Learning_Affinity_From_Attention_End-to-End_Weakly-Supervised_Semantic_Segmentation_With_Transformers_CVPR_2022_paper.html,(AFA) module to learn semantic affinity from the multihead  We argue that the Transformer  architecture naturally benefits  Embedded discriminative attention mechanism for weakly,"L Ru, Y Zhan, B Yu, B Du",2022,‚Ä¶ of the IEEE/CVF conference on ‚Ä¶,0.7777333909801818,0.7886155377823323,0.783174464381257
Music transformer,https://arxiv.org/abs/1809.04281,"the Transformer with our relative attention mechanism on two  , hence we simply adopt their  architecture. Table 3 shows that  attention-based models is that we can visualize its attention","CZA Huang, A Vaswani, J Uszkoreit, N Shazeer",2018,arXiv preprint arXiv ‚Ä¶,0.778632252749681,0.7876175126122259,0.7831248826809534
Generating the captions for remote sensing images: A spatial-channel attention based memory-guided transformer approach,https://www.sciencedirect.com/science/article/pii/S0952197622002317,"Further, an attention mechanism was integrated with an encoder‚Äìdecoder architecture to  co- In nutshell, Transformer‚Äôs decoder layer relies on MHA module to attend sequence patterns","GO Gajbhiye, AV Nandedkar",2022,Engineering Applications of Artificial ‚Ä¶,0.775705575519343,0.7904011644640074,0.7830533699916753
Rstnet: Captioning with adaptive attention on visual and non-visual words,http://openaccess.thecvf.com/content/CVPR2021/html/Zhang_RSTNet_Captioning_With_Adaptive_Attention_on_Visual_and_Non-Visual_Words_CVPR_2021_paper.html,We apply the GA module and AA module to our transformer based image captioning   transformer architecture for captioning. [13] proposed a GLU like structure on attention mechanism,"X Zhang, X Sun, Y Luo, J Ji, Y Zhou",2021,Proceedings of the ‚Ä¶,0.7717351799279479,0.7943169192990397,0.7830260496134938
SIT: A spatial interaction-aware transformer-based model for freeway trajectory prediction,https://www.mdpi.com/2220-9964/11/2/79,"Although Transformer, a multi-head attention-based network, has  Compared to the pooling  methods, the attention mechanism  Although the Transformer architecture can capture longer","X Li, J Xia, X Chen, Y Tan, J Chen",2022,ISPRS International Journal of Geo ‚Ä¶,0.7691105077944667,0.7969247832484293,0.7830176455214479
A VGG attention vision transformer network for benign and malignant classification of breast ultrasound images,https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.15852,", we employed squeeze-and-excitation (SE) module to enhance  VGGA module followed by  a fully connected (FC) layer for  indicated that self-attention modules of our transformer could","X Qu, H Lu, W Tang, S Wang, D Zheng, Y Hou",2022,Medical ‚Ä¶,0.7631341258606076,0.8027298011989341,0.7829319635297709
ASCAM-Former: Blind image quality assessment based on adaptive spatial & channel attention merging transformer and image to patch weights sharing,https://www.sciencedirect.com/science/article/pii/S0957417422022862,feasibility of incorporating attention mechanism in a channel- channel attention mechanism  in a Transform architecture.  spatial and channel attention merging module to dynamically,"X Ma, S Zhang, Y Wang, R Li, X Chen, D Yu",2023,Expert Systems with ‚Ä¶,0.7705581267184042,0.7952923328025135,0.7829252297604589
Spatial attention-based convolutional transformer for bearing remaining useful life prediction,https://iopscience.iop.org/article/10.1088/1361-6501/ac7c5b/meta,"In the proposed architecture, a gated convolutional unit layer  of a CNN and spatial attention  mechanism is effective in  by a transformer network; (b) the transformer network is able to","C Chen, T Wang, Y Liu, L Cheng",2022,‚Ä¶ Science and Technology,0.7794496144399361,0.7862968725733023,0.7828732435066192
BVA-Transformer: Image-text multimodal classification and dialogue model architecture based on Blip and visual attention mechanism,https://www.sciencedirect.com/science/article/pii/S014193822400074X,"This paper proposes BVA-Transformer model architecture for  ) module based on visual  attention in the BVA-Transformer,  network (FFN) layer in Transformers. In the Decoder of BVA-","K Zhang, F Wu, G Zhang, J Liu, M Li",2024,Displays,0.7669151130160323,0.7985532030182377,0.782734158017135
Patchformer: An efficient point transformer with patch attention,http://openaccess.thecvf.com/content/CVPR2022/html/Zhang_PatchFormer_An_Efficient_Point_Transformer_With_Patch_Attention_CVPR_2022_paper.html,"Benefitting from SA module, Transformer is capable of modeling  complexity of the attention  mechanism and limitations, we first  : replace PAT with EdgeConv layer in our architecture.","C Zhang, H Wan, X Shen, Z Wu",2022,Proceedings of the IEEE ‚Ä¶,0.7781865509585503,0.787274610214545,0.7827305805865477
A multi-head attention-based transformer model for traffic flow forecasting with a comparative analysis to recurrent neural networks,https://www.sciencedirect.com/science/article/pii/S0957417422006443,"a multi-head attention mechanism based transformer for  have any embedded recurrent  neural network layer, this study uses  the encoder‚Äìdecoder architecture deteriorated the model‚Äôs","S Reza, MC Ferreira, JJM Machado",2022,Expert Systems with ‚Ä¶,0.7741808181295035,0.7911034789335519,0.7826421485315277
Additional Self-Attention Transformer With Adapter for Thick Haze Removal,https://ieeexplore.ieee.org/abstract/document/10443626/,"neural network (CNN)-based, and Transformer-based  module comprises a new Additional  Attention mechanism  adapter module in this letter does not use the linear layer combination","Z Cai, J Ning, Z Ding, B Duo",2024,IEEE Geoscience and Remote ‚Ä¶,0.7698224520934589,0.7951094537238597,0.7824659529086593
UATNet: U-shape attention-based transformer net for meteorological satellite cloud recognition,https://www.mdpi.com/2072-4292/14/1/104,"network model based on the U-shaped architecture, in which  connection, and the attention  mechanism is designed to  the number of attention heads to 4 and build a 4-layer CCT.","Z Wang, J Zhao, R Zhang, Z Li, Q Lin, X Wang",2021,Remote Sensing,0.7789841284947647,0.785894660345301,0.7824393944200329
Multi-focus image fusion: Transformer and shallow feature attention matters,https://www.sciencedirect.com/science/article/pii/S0141938222001718,"network based on Transformer and attention mechanism,  decoding module has no  intermediate attention mechanism,  of the network architecture composed of the two Transformer","P Wu, L Jiang, Z Hua, J Li",2023,Displays,0.7841541169251415,0.7804674079639168,0.7823107624445291
Transformer-based multi-level attention integration network for video saliency prediction,https://link.springer.com/article/10.1007/s11042-024-19404-4,"In addition, we add the Transformer module to mine the  introduce the explicit circular  attention mechanism proposed by [ the MLIA and Transformer architecture for establishing long-","R Tan, M Sun, Y Liang",2024,Multimedia Tools and Applications,0.7677888071579064,0.7968198870276426,0.7823043470927745
‚Ä¶ framework for disease detection in video capsule endoscopy images using a vision transformer and convolutional neural network with a specific attention mechanism,https://link.springer.com/article/10.1007/s11042-023-18039-1,"The best features selected are fed to the Multi-Layer  2 and 3, we can divide the CNN  architecture into three main  , attention mechanism, CNN module, and ViT. We observed that the","Y Oukdach, Z Kerkaou, M El Ansari, L Koutti",2024,Multimedia Tools and ‚Ä¶,0.7633864817445888,0.8008736700170557,0.7821300758808223
Attention mechanism in neural networks: where it comes and where it goes,https://link.springer.com/article/10.1007/s00521-022-07366-3,"A recurrent soft attention based model learns to focus  part of the Transformer, masked  multi-head attention is applied  with the vanilla Transformer architecture on image generation and",D Soydaner,2022,Neural Computing and Applications,0.7734127244191759,0.7908377303122499,0.7821252273657129
Lightweight transformer image feature extraction network,https://peerj.com/articles/cs-1755/,"Two changes were made to the Transformer architecture,  are compared with the attention  mechanism that retains two  After the model lightweight token pruning module is introduced","W Zheng, S Lu, Y Yang, Z Yin, L Yin",2024,PeerJ Computer Science,0.7906791659382466,0.7735335677863852,0.7821063668623158
SwinPA-Net: Swin transformer-based multiscale feature pyramid aggregation network for medical image segmentation,https://ieeexplore.ieee.org/abstract/document/9895210/,"Although the above transformer-based architecture can  Under the action of the LPA module,  the attention mechanism is  -layer LPA module is better than a one-layer global attention,","H Du, J Wang, M Liu, Y Wang",2022,‚Ä¶ on Neural Networks and ‚Ä¶,0.7839774084564926,0.780193861173814,0.7820856348151533
MAXFormer: Enhanced transformer for medical image segmentation with multi-attention and multi-scale features fusion,https://www.sciencedirect.com/science/article/pii/S0950705123007372,"The attention mechanism in the Transformer block is  model architecture. In the following  sections, we will introduce the Max Transformer block and Refined Fused Connection module","Z Liang, K Zhao, G Liang, S Li, Y Wu, Y Zhou",2023,Knowledge-Based Systems,0.7737966040989388,0.7902382909561656,0.7820174475275522
Multi-Scale Transformer and Attention Mechanism for Magnetic Spatiotemporal Sequence Localization,https://ieeexplore.ieee.org/abstract/document/10436406/,"4) Localization module includes an FC layer activated by the  noises, we design a data  denoising module based on DAEs.  method with a client-server architecture. The client side was","Q Wang, L Wang, M Fu, J Wang, L Sun",2024,IEEE Internet of ‚Ä¶,0.7822257821679315,0.7818055370565763,0.7820156596122538
Efficient conformer with prob-sparse attention mechanism for end-to-endspeech recognition,https://arxiv.org/abs/2106.09236,The Transformer architecture with self-attention has recently  The prediction network has  1 LSTM layer with 256 hidden  consumption of the self-attention module for sentences with,"X Wang, S Sun, L Xie, L Ma",2021,arXiv preprint arXiv:2106.09236,0.7720075922093598,0.7917538227714622,0.781880707490411
Transformer based multi-grained attention network for aspect-based sentiment analysis,https://ieeexplore.ieee.org/abstract/document/9265203/,And then we utilize the attention mechanism multiple times to  improvement of multilayer  network architecture fitting and  the proposed model not only employs Transformer module to,"J Sun, P Han, Z Cheng, E Wu, W Wang",2020,IEEE Access,0.7811816881904846,0.7822845936428807,0.7817331409166827
Transformer-Based Fused Attention Combined with CNNs for Image Classification,https://link.springer.com/article/10.1007/s11063-023-11402-1,"the hierarchical architecture of the Swin Transformer by  , this paper introduces an attention  mechanism to the sequence  convolution module following the attention extraction layer. As","J Jiang, H Xu, X Xu, Y Cui, J Wu",2023,Neural Processing Letters,0.7760397776961523,0.7873836983029965,0.7817117379995744
Spatial-channel transformer network for trajectory prediction on the traffic scenes,https://arxiv.org/abs/2101.11472,A channel-wise module is inserted to measure the social  Recently the transformer architecture  has also been  use complete attention mechanism to process time-series data and model,"J Zhao, X Li, Q Xue, W Zhang",2021,arXiv preprint arXiv:2101.11472,0.7790174206571503,0.7843584819070345,0.7816879512820925
Etma: Efficient transformer-based multilevel attention framework for multimodal fake news detection,https://ieeexplore.ieee.org/abstract/document/10077443/,": a visual attention-based encoder, a textual attention-based  the attention mechanism and  LSTM network. 4) MVAE [25 We first remove the self-attention block from the architecture and","A Yadav, S Gaba, H Khan, I Budhiraja",2023,IEEE Transactions ‚Ä¶,0.7698320500909666,0.7934443167206454,0.7816381834058059
Multimodal tweet classification in disaster response systems using transformer-based bidirectional attention model,https://link.springer.com/article/10.1007/s00521-022-07790-5,"for image, biLSTM and attention mechanism. We put forward  is the key component in the  transformer module. In addition,  We present a neural network architecture that considers both","R Koshy, S Elango",2023,Neural Computing and Applications,0.7711714315191037,0.7918503292690129,0.7815108803940582
Transcam: Transformer attention-based cam refinement for weakly supervised semantic segmentation,https://www.sciencedirect.com/science/article/pii/S1047320323000500,of the multi-head self-attention module in the l th transformer  a linear layer to the class token  at the end of the transformer  that leverages the transformer architecture for the WSSS task.,"R Li, Z Mai, Z Zhang, J Jang, S Sanner",2023,Journal of Visual Communication ‚Ä¶,0.768680230289958,0.7942279029930992,0.7814540666415286
Transformer technology in molecular science,https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1725,"Additionally, the attention mechanism within transformers facilitates the  decoder architecture,  the model comprises three key components, as illustrated in Figure 9: an Attention module","J Jiang, L Ke, L Chen, B Dou, Y Zhu",2024,Wiley ‚Ä¶,0.7884855961401301,0.7743829119684438,0.7814342540542869
Transformer-based local-global guidance for image captioning,https://www.sciencedirect.com/science/article/pii/S0957417423002750,"using a single attention mechanism. In this paper, a new  present a new transformer-based  architecture without recurrence  a generator network and a selector module to collaboratively","H Parvin, AR Naghsh-Nilchi, HM Mohammadi",2023,Expert Systems with ‚Ä¶,0.7784981659215914,0.7842278072240004,0.7813629865727959
Action unit detection by exploiting spatial-temporal and label-wise attention with transformer,https://openaccess.thecvf.com/content/CVPR2022W/ABAW/html/Wang_Action_Unit_Detection_by_Exploiting_Spatial-Temporal_and_Label-Wise_Attention_With_CVPRW_2022_paper.html,", we proposed a transformer based correlation module to learn  We therefore employ attention  mechanism to focus on  18 model, proposed CNN-transformer hybrid architecture obtain","L Wang, J Qi, J Cheng, K Suzuki",2022,Proceedings of the IEEE ‚Ä¶,0.7747805103407931,0.7877833296711467,0.78128192000597
Explicit sparse transformer: Concentrated attention through explicit selection,https://arxiv.org/abs/1912.11637,"attention mechanism and the attention-based framework of  we propose a novel model,  Explicit Sparse Transformer, which  of the attention at the top layer of the vanilla Transformer, and","G Zhao, J Lin, Z Zhang, X Ren, Q Su, X Sun",2019,arXiv preprint arXiv ‚Ä¶,0.7695261574747772,0.792736925834207,0.7811315416544921
A transformer-based siamese network for change detection,https://ieeexplore.ieee.org/abstract/document/9883686/,"paper presents a transformer-based Siamese network architecture ( structured transformer  encoder with Multi-Layer Perception ( encoder is self-attention module. In the original work [7],","WGC Bandara, VM Patel",2022,IGARSS 2022-2022 IEEE ‚Ä¶,0.7703816191072751,0.7917871965513084,0.7810844078292918
T-gsa: Transformer with gaussian-weighted self-attention for speech enhancement,https://ieeexplore.ieee.org/abstract/document/9053591/,The multi-head attention module in our proposed T-GSA is  We proposed a complex  Transformer architecture for speech  the decoder layer of the complex Transformer network. Hu,"J Kim, M El-Khamy, J Lee",2020,ICASSP 2020-2020 IEEE ‚Ä¶,0.7654672221036203,0.7964721191093832,0.7809696706065017
NA-segformer: A multi-level transformer model based on neighborhood attention for colonoscopic polyp segmentation,https://www.nature.com/articles/s41598-024-74123-y,a patch merging module with a neighbor attention mechanism based  Each encoder layer in  the Segmenter captures global  Transformer-based multi-level encoder-decoder architecture,"D Liu, C Lu, H Sun, S Gao",2024,Scientific Reports,0.786675682923301,0.7752397423579446,0.7809577126406229
Gene transformer: Transformers for the gene expression-based classification of lung cancer subtypes,https://arxiv.org/abs/2108.11833,"with a multi-head self-attention module by identifying relevant  attention mechanism, in the  Gene Transformer architecture,  Our findings indicate that employing the attention mechanism","A Khan, B Lee",2021,arXiv preprint arXiv:2108.11833,0.7810924804094195,0.7808014533461828,0.7809469668778011
Combining convolutional attention mechanism and residual deformable Transformer for infarct segmentation from CT scans of acute ischemic stroke patients,https://www.frontiersin.org/articles/10.3389/fneur.2023.1178637/full,"SETR (19) employs a Transformer as the encoder and a CNN architecture as the decoder to   block attention module, and the green rectangle is the Deformable Transformer layer. The","Z Xu, C Ding",2023,Frontiers in Neurology,0.7743966942126028,0.7873278512201547,0.7808622727163788
TSCA-Net: Transformer based spatial-channel attention segmentation network for medical images,https://www.sciencedirect.com/science/article/pii/S0010482524000222,"and the application of attention mechanism in medical images.  However, the  Transformer-based channel attention module  We are expected to optimize the attention","Y Fu, J Liu, J Shi",2024,Computers in Biology and Medicine,0.7718173770725449,0.7895971756444663,0.7807072763585057
Batch Transformer: Look for Attention in Batch,https://arxiv.org/abs/2407.04218,"the proposed class batch attention (CBA) module, to prevent  Recently, attention mechanism  models have been applied to  batch transformer network (BTN) architecture with multi-level","MB Her, J Jeong, H Song, JH Han",2024,arXiv preprint arXiv:2407.04218,0.7797927780536114,0.7810700757819926,0.780431426917802
Molecule attention transformer,https://arxiv.org/abs/2002.08264,augment the attention mechanism in Transformer using inter- model based on the state-of-the-art  Transformer architecture  Transformer is that it augments the self-attention module using,"≈Å Maziarka, T Danel, S Mucha, K Rataj, J Tabor",2020,arXiv preprint arXiv ‚Ä¶,0.7792196962083604,0.7815754683580427,0.7803975822832016
Multimodal transformer fusion for continuous emotion recognition,https://ieeexplore.ieee.org/abstract/document/9053762/,"It extends conventional attention mechanism to have h multiple  Besides, every multi-head  attention module is followed with  combine the Transformer network and LSTM layer to explore","J Huang, J Tao, B Liu, Z Lian",2020,ICASSP 2020-2020 IEEE ‚Ä¶,0.7691864130958798,0.7915754117715326,0.7803809124337062
Human behavior recognition based on sparse transformer with channel attention mechanism,https://www.frontiersin.org/articles/10.3389/fphys.2023.1239453/full,"The Transformer architecture is a deep neural network initially developed for natural language  processing.  In the self-attention module of the Transformer model, we introduced a dual","K Cao, M Wang",2023,Frontiers in Physiology,0.7757988583740147,0.7849209684169687,0.7803599133954917
A multi-step ahead global solar radiation prediction method using an attention-based transformer model with an interpretable mechanism,https://www.sciencedirect.com/science/article/pii/S0360319923000691,"model, which consists only of the attention mechanism. The  This architecture provides  great flexibility in practical  multi-head attention layer, a multi-head attention layer, and a","Y Zhou, Y Li, D Wang, Y Liu",2023,International Journal of Hydrogen Energy,0.7765550058690194,0.7840055599942497,0.7802802829316345
Spatial-temporal self-attention transformer networks for battery state of charge estimation,https://www.mdpi.com/2079-9292/12/12/2598,"a specialized Transformer-based network architecture, called  The attention-based  Transformer model [43], which is  The attention mechanism is a fundamental component of the","D Shi, J Zhao, Z Wang, H Zhao, J Wang, Y Lian",2023,Electronics,0.772683829316471,0.7875506553102665,0.7801172423133687
Multi-modal motion prediction with transformer-based neural network for autonomous driving,https://ieeexplore.ieee.org/abstract/document/9812060/,We also demonstrate that the multi-modal attention module can automatically  propose to  modify the multi-head attention mechanism in the Transformer to multi-modal  architecture. The,"Z Huang, X Mo, C Lv",2022,2022 International Conference on ‚Ä¶,0.7768655841116073,0.7833060842806037,0.7800858341961054
Lawin transformer: Improving semantic segmentation transformer with multi-scale representations via large window attention,https://arxiv.org/abs/2201.01615,"a novel window attention mechanism named large window  R, a SPP module evolves into  a large window attention spatial  window attention and describe the architecture of LawinASPP","H Yan, C Zhang, M Wu",2022,arXiv preprint arXiv:2201.01615,0.777515394314151,0.7826152294673911,0.780065311890771
Transfg: A transformer architecture for fine-grained recognition,https://ojs.aaai.org/index.php/AAAI/article/view/19967,tion Module that can be applied to most of the transformer ar its innate multi-head attention  mechanism. To fully exploit the  change the input to the last Transformer Layer. Suppose the,"J He, JN Chen, S Liu, A Kortylewski, C Yang",2022,Proceedings of the ‚Ä¶,0.7831182985900489,0.7762666689697482,0.7796924837798985
CATNet: Cascaded attention transformer network for marine species image classification,https://www.sciencedirect.com/science/article/pii/S0957417424017998,"transformer module, our STM employs the parallel learning strategy of the multi-head attention  mechanism  of the multi-head attention module normalized by the pass layer when l = 1 . b","W Zhang, G Chen, P Zhuang, W Zhao",2024,Expert Systems with ‚Ä¶,0.7720967773988552,0.7872570644068076,0.7796769209028314
Domain adaptation via bidirectional cross-attention transformer,https://arxiv.org/abs/2201.05887,"transformer with a bidirectional cross-attention mechanism to  We leverage the cross-attention  module to produce mixup  As shown in the top of Figure 3, the overall architecture of the","X Wang, P Guo, Y Zhang",2022,arXiv preprint arXiv:2201.05887,0.7723818986916584,0.7866975088607261,0.7795397037761922
The devil is in the details: Window-based attention for image compression,http://openaccess.thecvf.com/content/CVPR2022/html/Zou_The_Devil_Is_in_the_Details_Window-Based_Attention_for_Image_CVPR_2022_paper.html,the neural networks with the attention mechanism for  a flexible attention module  combined with neural networks to  the attention mechanism in the transformer are incompatible.,"R Zou, C Song, Z Zhang",2022,‚Ä¶ of the IEEE/CVF conference on ‚Ä¶,0.7624290726853624,0.7965430792993005,0.7794860759923314
MALS-Net: A multi-head attention-based LSTM sequence-to-sequence network for socio-temporal interaction modelling and trajectory prediction,https://www.mdpi.com/1424-8220/23/1/530,", the multi-head attention mechanism of the transformer does  data, we propose another  multi-head attention layer (TMHA),  architecture as a replacement for the traditional transformer","F Hasan, H Huang",2023,Sensors,0.770539608660649,0.7883969524333969,0.779468280547023
Re-transformer: a self-attention based model for machine translation,https://www.sciencedirect.com/science/article/pii/S1877050921011509,", Re-Transformer modifies the basic architecture; there are  Self-Attention layer to Feed  Forward layer assists the model  models combine an attention mechanism to help the model to","HI Liu, WL Chen",2021,Procedia Computer Science,0.7758683868048042,0.7828623185930621,0.7793653526989331
Multiple paddy disease recognition methods based on deformable transformer attention mechanism in complex scenarios,https://www.tandfonline.com/doi/abs/10.1080/1206212X.2023.2263254,"network architecture fuses multi-scale features by adding a feature fusion module after the  backbone network of the last decoder layer, we employ two Feed Forward Networks (FFNs) to","X Zhang, H Dong, L Gong, X Cheng",2023,International Journal of ‚Ä¶,0.7795662307013426,0.7790894149605972,0.7793278228309699
Dae-former: Dual attention-guided efficient transformer for medical image segmentation,https://link.springer.com/chapter/10.1007/978-3-031-46005-0_8,"U-Net-like pure Transformer architecture, namely, the DAE- -attention module in each skip  connection path. Our contributions are as follows: ‚ù∂ a novel efficient dual attention mechanism","R Azad, R Arimond, EK Aghdam, A Kazerouni",2023,‚Ä¶ Workshop on PRedictive ‚Ä¶,0.7691090560597085,0.7894802914077319,0.7792946737337202
Attention-based generative adversarial network in medical imaging: A narrative review,https://www.sciencedirect.com/science/article/pii/S0010482522006837,"that Transformer-based GAN will be a promising model in  ‚Äúgenerative adversarial network‚Äù  and ‚Äúattention mechanism‚Äù, and  The architecture of the Transformer makes few assumptions","J Zhao, X Hou, M Pan, H Zhang",2022,Computers in Biology and Medicine,0.7737606051032287,0.7847511700227372,0.7792558875629829
Deformable cross-attention transformer for medical image registration,https://link.springer.com/chapter/10.1007/978-3-031-45673-2_12,module differs from existing SA and CA modules in that it employs the windowed attention  mechanism [ computation and the full Transformer architecture used by the model. To address,"J Chen, Y Liu, Y He, Y Du",2023,‚Ä¶ Workshop on Machine Learning in Medical ‚Ä¶,0.7716261906086961,0.7866716964685209,0.7791489435386085
Convolution transformer mixer for hyperspectral image classification,https://ieeexplore.ieee.org/abstract/document/9903640/,"spatial convolution module and a transformer encoder module,  of convolution operation  and attention mechanism, we intro a 1D pooling layer is adopted to reduce network parameters","J Zhang, Z Meng, F Zhao, H Liu",2022,IEEE Geoscience and ‚Ä¶,0.7734363119409042,0.784722081993023,0.7790791969669636
Vehicle trajectory prediction based on intention-aware non-autoregressive transformer with multi-attention learning for Internet of Vehicles,https://ieeexplore.ieee.org/abstract/document/9832594/,", we propose a multiple attention mechanism capturing the  overall network architecture of  our proposed iNATran model  we propose a social attention learning (SAL) module to learn the","X Chen, H Zhang, F Zhao, Y Cai",2022,IEEE Transactions on ‚Ä¶,0.7652129367487075,0.7928998259872313,0.7790563813679694
Transformer-based Monocular Depth Estimation with Attention Supervision.,https://www.bmvc2021-virtualconference.com/assets/papers/0244.pdf,"To this end, we propose Attention-based Up-sample Block (AUB) to compensate  attention  mechanism to depth estimation, the attention maps extracted from the last  in our architecture.","W Chang, Y Zhang, Z Xiong",2021,BMVC,0.767607571544423,0.7903676902164981,0.7789876308804606
Exploiting multi-scale parallel self-attention and local variation via dual-branch transformer-CNN structure for face super-resolution,https://ieeexplore.ieee.org/abstract/document/10207832/,dual-branch module which consists of Transformer and CNN  blocks and introduced  attention mechanism to refine the  most important module in the whole network architecture. It,"J Shi, Y Wang, Z Yu, G Li, X Hong",2023,IEEE Transactions on ‚Ä¶,0.76298999139643,0.7949180214970282,0.7789540064467291
Dynamic detr: End-to-end object detection with dynamic attention,https://openaccess.thecvf.com/content/ICCV2021/html/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.html?ref=https://githubhelp.com,"self-attention module in Transformer encoders, we propose a dynamic encoder to approximate  the Transformer encoder‚Äôs attention mechanism  ral network and a top down architecture","X Dai, Y Chen, J Yang, P Zhang",2021,Proceedings of the ‚Ä¶,0.7698269455057914,0.7879398613501299,0.7788834034279607
Transformer architecture and attention mechanisms in genome data analysis: a comprehensive review,https://www.mdpi.com/2079-7737/12/7/1033,the transformer architecture and the attention mechanism in  The model leverages an  attention-based mechanism to learn  An attention mechanism layer is incorporated into each base,"SR Choi, M Lee",2023,Biology,0.7775769564838273,0.7801041798125082,0.7788405681481678
Dual-branch adaptive attention transformer for occluded person re-identification,https://www.sciencedirect.com/science/article/pii/S0262885623000070,"this two-stage architecture also complicates the model. To solve  Token Attention (STA)  module. STA can utilize the multi-headed  , the attention mechanism is used to select the network","Y Lu, M Jiang, Z Liu, X Mu",2023,Image and Vision Computing,0.7724914731314636,0.7850531703727475,0.7787723217521055
Laplacian mesh transformer: Dual attention and topology aware network for 3D mesh classification and segmentation,https://link.springer.com/chapter/10.1007/978-3-031-19818-2_31,This paper builds a dual attention architecture in a topology- Then we apply a final  attention-based fusion module to learn  we propose the dual attention mechanism that achieves,"XJ Li, J Yang, FL Zhang",2022,European Conference on Computer Vision,0.7753576719915707,0.782134530260822,0.7787461011261964
Self-attention encoding and pooling for speaker recognition,https://arxiv.org/abs/2008.01077,"[8] for a Transformer architecture and appeared very effective  employ multi-head attention  mechanism in the pooling layer to  This layer is an additive attention based mechanism, which","P Safari, M India, J Hernando",2020,arXiv preprint arXiv:2008.01077,0.7664460534575079,0.7907566954443506,0.7786013744509293
"MDF-SA-DDI: predicting drug‚Äìdrug interaction events based on multi-source drug fusion, multi-source feature fusion and transformer self-attention mechanism",https://academic.oup.com/bib/article-abstract/23/1/bbab421/6406700,"Therefore, we add a self-attention layer before the output layer of the  Multi-head attention  mechanism  and input them to the multi-head attention module, which is also called the","S Lin, Y Wang, L Zhang, Y Chu, Y Liu",2022,Briefings in ‚Ä¶,0.771797619454988,0.7851133398692518,0.7784554796621199
Multiscaled multi-head attention-based video transformer network for hand gesture recognition,https://ieeexplore.ieee.org/abstract/document/10035507/,The attention mechanism decides and identifies the most  One such model which is based  on the attention mechanism  hand gestures based on transformer architecture has been pro,"M Garg, D Ghosh, PM Pradhan",2023,IEEE Signal Processing ‚Ä¶,0.7682383398319729,0.7884662709572365,0.7783523053946046
LAS-transformer: An enhanced transformer based on the local attention mechanism for speech recognition,https://www.mdpi.com/2078-2489/13/5/250,"at the embedding layer. Moreover, we propose a local attention module to explicitly   From speech to letters-using a novel neural network architecture for grapheme based ASR. In","P Fu, D Liu, H Yang",2022,Information,0.7722400033988355,0.7842579115108645,0.77824895745485
Improving transformer-based networks with locality for automatic speaker verification,https://ieeexplore.ieee.org/abstract/document/10096333/,"layer allows CNNs to model the local dependencies well, but it  architecture of Conformer  block is shown in the left side of Fig. 1(b). It consists of multi-head self-attention (MSA) module","M Sang, Y Zhao, G Liu, JHL Hansen",2023,ICASSP 2023-2023 ‚Ä¶,0.778824382396319,0.7776486146285659,0.7782364985124425
Hybrid transformer and cnn attention network for stereo image super-resolution,https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/html/Cheng_Hybrid_Transformer_and_CNN_Attention_Network_for_Stereo_Image_Super-Resolution_CVPRW_2023_paper.html,", we propose a hybrid architecture that utilizes the strong long RCAN [39] incorporates the  attention mechanism in a basic  images using a transformer-based SISR module and a CNN","M Cheng, H Ma, Q Ma, X Sun, W Li",2023,Proceedings of the ‚Ä¶,0.7706355774942663,0.7854723687220189,0.7780539731081426
Fusformer: A transformer-based fusion network for hyperspectral image super-resolution,https://ieeexplore.ieee.org/abstract/document/9841513/,"transformer module, a network architecture (called Fusformer) is designed for the HISR  problem. Our method integrates a self-attention mechanism  With a simple fully connected layer,","JF Hu, TZ Huang, LJ Deng, HX Dou",2022,‚Ä¶ and Remote Sensing ‚Ä¶,0.7655983048488749,0.7901926094381482,0.7778954571435115
Transformer-based multi-attention hybrid networks for skin lesion segmentation,https://www.sciencedirect.com/science/article/pii/S0957417423035182,"Gated External Attention module ‚Äî DGEA module, which  overview of the overall network  architecture TMAHU-Net  propose a novel attention mechanism that utilizes multiscale","Z Dong, J Li, Z Hua",2024,Expert Systems with Applications,0.7756250246300757,0.7800275536474939,0.7778262891387848
Hardware accelerator for multi-head attention and position-wise feed-forward in the transformer,https://ieeexplore.ieee.org/abstract/document/9524802/,"of the attention mechanism, the Transformer and Transformer the proposed architecture,  the latency of layer normalization  The Softmax module in the proposed architecture is used to","S Lu, M Wang, S Liang, J Lin",2020,2020 IEEE 33rd ‚Ä¶,0.7766591599299175,0.7788308905997632,0.7777450252648404
MSGformer: A multi-scale grid transformer network for 12-lead ECG arrhythmia detection,https://www.sciencedirect.com/science/article/pii/S1746809423009321,"grid attention mechanism to capture temporal features. The  Specifically, through  enhanced attention-based QKV  The original Transformer architecture is an effective model","C Ji, L Wang, J Qin, L Liu, Y Han, Z Wang",2024,Biomedical Signal Processing ‚Ä¶,0.7660348606632543,0.7893592871031141,0.7776970738831842
Lite vision transformer with enhanced self-attention,http://openaccess.thecvf.com/content/CVPR2022/html/Yang_Lite_Vision_Transformer_With_Enhanced_Self-Attention_CVPR_2022_paper.html,"network (FFN) that follows the self-attention layer. Both Swin- network [19,28], we formalize  RASA as a recursive module with  on transformer architecture with enhanced self-attention","C Yang, Y Wang, J Zhang, H Zhang",2022,Proceedings of the ‚Ä¶,0.7544964615233147,0.8008694371705453,0.7776829493469299
Xmorpher: Full transformer for deformable medical image registration via cross attention,https://link.springer.com/chapter/10.1007/978-3-031-16446-0_21,"(c) Our cross-attention-based fusion with inner-network  a new attention mechanism, Cross  Attention Transformer (CAT) block : 1) A X-shape transformer architecture with dual parallel U-","J Shi, Y He, Y Kong, JL Coatrieux, H Shu",2022,‚Ä¶ Conference on Medical ‚Ä¶,0.7730371216135513,0.7819402631897623,0.7774886924016569
Informer: Beyond efficient transformer for long sequence time-series forecasting,http://ojs.aaai.org/index.php/AAAI/article/view/17325,of the self-attention mechanism and Transformer architecture  ProbSparse Self-attention  Based on the proposed mea We add a max-pooling layer with stride 2 and downsample Xt,"H Zhou, S Zhang, J Peng, S Zhang, J Li",2021,Proceedings of the ‚Ä¶,0.7661468037869676,0.788677013257546,0.7774119085222568
A novel transformer-based DL model enhanced by position-sensitive attention and gated hierarchical LSTM for aero-engine RUL prediction,https://www.nature.com/articles/s41598-024-59095-3,the attention mechanism employed by the Transformer encoder and architecture of the  Transformer encoder module. The  module consists of a simple fully connected (FC) layer and,X Chen,2024,Scientific Reports,0.7713722394184488,0.7834358798790344,0.7774040596487416
Improved transformer net for hyperspectral image classification,https://www.mdpi.com/2072-4292/13/11/2216,The proposed model uses the spectral attention mechanism  proposes a self-attention-based  transformer (SAT) model for  neural network (CNN) [58] (CNN architecture with five layers of,"Y Qing, W Liu, L Feng, W Gao",2021,Remote Sensing,0.7586135393621682,0.7955729725943931,0.7770932559782806
Crackformer: Transformer network for fine-grained crack detection,http://openaccess.thecvf.com/content/ICCV2021/html/Liu_CrackFormer_Transformer_Network_for_Fine-Grained_Crack_Detection_ICCV_2021_paper.html,"Therefore, we seek the help from scalingattention mechanism propose novel self-attention  blocks as the basic module. To  We derive our model from the SegNet basic architecture and","H Liu, X Miao, C Mertz, C Xu",2021,Proceedings of the IEEE ‚Ä¶,0.7709844524940475,0.7829546702837902,0.7769695613889188
Streaming automatic speech recognition with the transformer model,https://ieeexplore.ieee.org/abstract/document/9054476/,) compared to recurrent neural network (RNN) based system  -decoder attention mechanism  of the transformer model to  transformer architecture consists of a two-layer CNN module,"N Moritz, T Hori, J Le",2020,ICASSP 2020-2020 IEEE International ‚Ä¶,0.7690366415081646,0.7847772414292465,0.7769069414687055
Remote sensing image change detection based on deep multi-scale multi-attention Siamese transformer network,https://www.mdpi.com/2072-4292/15/3/842,"change information, the attention mechanism is added in  attention module combining a  convolution and self-attention module  and the self-attention together in the same architecture. It","M Zhang, Z Liu, J Feng, L Liu, L Jiao",2023,Remote Sensing,0.7635515659353002,0.7902028455704582,0.7768772057528792
Cat: Cross attention in vision transformer,https://ieeexplore.ieee.org/abstract/document/9859720/,"attention mechanism in Transformer termed Cross Attention,  1) and other global attentionbased  methods. The FLOPscpga is  In all architecture we make, the architecture with the best","H Lin, X Cheng, X Wu, D Shen",2022,2022 IEEE international ‚Ä¶,0.7688555264722424,0.7848088765955687,0.7768322015339055
Local enhancing transformer with temporal convolutional attention mechanism for bearings remaining useful life prediction,https://ieeexplore.ieee.org/abstract/document/10177813/,"Recently, the Transformer, a novel network architecture  Transformer by introducing a  standard convolutional layer to  , a TCN attention module combing TCN and SE attention [37] is","H Peng, B Jiang, Z Mao, S Liu",2023,IEEE Transactions on ‚Ä¶,0.7743660145202738,0.7791984907172178,0.7767822526187458
Transnorm: Transformer provides a strong spatial normalization mechanism for a deep segmentation model,https://ieeexplore.ieee.org/abstract/document/9908565/,architecture that provides a strong 57 Spatial Normalization  fed into a 149 Transformer  encoder followed by an MLP layer to  attention mechanism based on 204 the Transformer module,"R Azad, MT Al-Antary, M Heidari, D Merhof",2022,IEEe Access,0.7812126504573816,0.7723158555017691,0.7767642529795753
Mult: An end-to-end multitask learning transformer,http://openaccess.thecvf.com/content/CVPR2022/html/Bhattacharjee_MulT_An_End-to-End_Multitask_Learning_Transformer_CVPR_2022_paper.html,"Detailed overview of our MulT architecture. Our MulT  tasks via a shared attention mechanism  (shown in the bottom left), which we introduce in this work. The encoder module (in green)","D Bhattacharjee, T Zhang",2022,Proceedings of the ‚Ä¶,0.7759095901223176,0.7774225035140141,0.7766660468181659
Monaural Multi-Talker Speech Recognition with Attention Mechanism and Gated Convolutional Networks.,https://ai.tencent.com/ailab/media/publications/MonauralMulti-TalkerSpeechRecognitionwithAttentionMechanismand_GatedConvolutionalNetworks._pdf.pdf,model architecture that incorporates the attention  new model has an encoding transformer  that is a 3-layer BLSTM and a predictor module that is a 3-layer LSTM with 384 cells per layer.,"X Chang, Y Qian, D Yu",2018,INTERSPEECH,0.7666915333910826,0.7866347289622841,0.7766631311766834
Efficient self-attention mechanism and structural distilling model for Alzheimer's disease diagnosis,https://www.sciencedirect.com/science/article/pii/S0010482522005108,"While CNNs were developing, a model called Transformer  the structural distilling layer,  which is a computational module that  of the model was improved by the attention mechanism to","J Zhu, Y Tan, R Lin, J Miao, X Fan, Y Zhu",2022,Computers in Biology ‚Ä¶,0.7671489948579634,0.7858552039566616,0.7765020994073125
Transmil: Transformer based correlated multiple instance learning for whole slide image classification,https://proceedings.neurips.cc/paper_files/paper/2021/hash/10c272d06794d3e5785d5e7c5356e9ff-Abstract.html,"Then the attention mechanism was gradually applied to computer vision tasks, including   a TPT module with two Transformer layers and a position encoding layer, where Transformer","Z Shao, H Bian, Y Chen, Y Wang",2021,Advances in neural ‚Ä¶,0.7700643780719729,0.7829348196898708,0.7764995988809218
Dual attention transformer network for hyperspectral image classification,https://www.sciencedirect.com/science/article/pii/S095219762301535X,"the attention mechanism not only effectively enhances model  1 illustrates the overall  architecture of the DATN model. This  our proposed SSHT module, thereby allowing the network to","Z Shu, Y Wang, Z Yu",2024,Engineering Applications of Artificial Intelligence,0.7640781903213218,0.7888623793604237,0.7764702848408728
ReTransformer: ReRAM-based processing-in-memory architecture for transformer acceleration,https://dl.acm.org/doi/abs/10.1145/3400302.3415640,"-based NLP tasks, attention mechanism is a popular and  , an outstanding self-attention  based model ‚Äì Transformer [28 between the linear layer and MatMul in Transformer. Fig. 6(a","X Yang, B Yan, H Li, Y Chen",2020,‚Ä¶ of the 39th International Conference on ‚Ä¶,0.7717905638604434,0.7808263601012648,0.7763084619808541
Transformers in medical image analysis,https://www.sciencedirect.com/science/article/pii/S2667102622000717,"the core principle of the attention mechanism, followed by a  A typical transformer  architecture is shown in Figure 3 and  As an attention-based network, transformer is suitable for","K He, C Gan, Z Li, I Rekik, Z Yin, W Ji, Y Gao, Q Wang",2023,Intelligent ‚Ä¶,0.7794278653307933,0.7730034315463495,0.7762156484385714
Transformer and group parallel axial attention co-encoder for medical image segmentation,https://www.nature.com/articles/s41598-022-20440-z,"Specifically, we propose a new attention mechanism to  The network is based on U-shape  architecture. The encoder  To further preserve global information, we introduce a module at the","C Li, L Wang, Y Li",2022,Scientific Reports,0.774913233712953,0.7773494102609966,0.7761313219869748
TRS: Transformers for remote sensing scene classification,https://www.mdpi.com/2072-4292/13/20/4143,"through the attention mechanism. The self-attention-based structure proposed in Transformer  [ In further works, we will attempt to apply the complete Transformer architecture (encoder +","J Zhang, H Zhao, J Li",2021,Remote Sensing,0.775006108931799,0.7772019206487752,0.7761040147902871
A Siamese network based on multiple attention and multilayer transformers for change detection,https://ieeexplore.ieee.org/abstract/document/10288523/,attention mechanism or a spatial attention mechanism [40] the attention mechanism to  encoder‚Äìdecoder architecture  extraction module are fed into a four-layer transformer encoder to,"W Tang, K Wu, Y Zhang, Y Zhan",2023,IEEE Transactions on ‚Ä¶,0.7762205417852917,0.7758719908101841,0.7760462662977379
Defect transformer: An efficient hybrid transformer architecture for surface defect detection,https://www.sciencedirect.com/science/article/pii/S0263224123001781,"setting of encoder module in our network architecture. The  of upsampling operation and  convolution layer utilized in this paper  it with the self-attention modules as in most transformers,","J Wang, G Xu, F Yan, J Wang, Z Wang",2023,Measurement,0.7686507412586039,0.783175089083665,0.7759129151711344
Set transformer: A framework for attention-based permutation-invariant neural networks,http://proceedings.mlr.press/v97/lee19d.html,"deep neural network architecture called the Set Transformer, ( Section 2.1), but a distinguishing  feature is that each layer in  , we adapt the multihead attention mechanism used in Trans","J Lee, Y Lee, J Kim, A Kosiorek",2019,‚Ä¶ on machine learning,0.7768827902973497,0.774870775517521,0.7758767829074353
Sam: Self attention mechanism for scene text recognition based on swin transformer,https://link.springer.com/chapter/10.1007/978-3-030-98358-1_35,", the attention mechanism is usually combined with RNN structures as a module to predict  the  Eventually, the final results are obtained by connecting the outputs and applying a layer","X Shuai, X Wang, W Wang, X Yuan, X Xu",2022,International Conference on ‚Ä¶,0.7641496205112118,0.7875288417861597,0.7758392311486857
A hybrid transformer model for obstructive sleep apnea detection based on self-attention mechanism using single-lead ECG,https://ieeexplore.ieee.org/abstract/document/9837102/,", a hybrid Transformer model leveraging attention mechanism is  processing module. Figure  1 shows the constructed data.  three parallel two-layer convolutional networks with different","S Hu, W Cai, T Gao, M Wang",2022,IEEE Transactions on ‚Ä¶,0.7668573137322487,0.7844616746013465,0.7756594941667976
Improving transformer-based conversational ASR by inter-sentential attention mechanism,https://arxiv.org/abs/2207.00883,"end-to-end architecture for conversational speech recog Inspired by [23], we include a residual  attention module in the encoder layer and Attn is the dot-product attention mechanism, as","K Wei, P Guo, N Jiang",2022,arXiv preprint arXiv:2207.00883,0.763207589624022,0.7879138041906933,0.7755606969073576
Transformer in convolutional neural networks,https://homes.esat.kuleuven.be/~konijn/publications/2021/Liu2.pdf,"Motivated by this, we introduce a novel architecture  this module is less powerful for ‚Äúlocal-invariant""  vision data. Combining the H-MHSA module with a more potent convolutional layer","Y Liu, G Sun, Y Qiu, L Zhang",2021,arXiv preprint arXiv ‚Ä¶,0.767391125389424,0.78344897923009,0.775420052309757
Multi-head self-attention transformer for dogecoin price prediction,https://ieeexplore.ieee.org/abstract/document/9538640/,"In this paper, a multi-head attention-based transformer  The transformer uses a multi-head  attention mechanism to map  Figure 2 shows the overall architecture of the transformer model.","S Sridhar, S Sanagavarapu",2021,2021 14th International ‚Ä¶,0.7615035585734434,0.7893253377058913,0.7754144481396674
Attention mechanism and context modeling system for text mining machine translation,https://arxiv.org/abs/2408.04216,"Transformer is its encoder module[30], which is composed of a series of stacked encoder  layers with a consistent architecture , in the multi-head attention mechanism of the Transformer,","S Bo, Y Zhang, J Huang, S Liu, Z Chen, Z Li",2024,arXiv preprint arXiv ‚Ä¶,0.7712909536655107,0.7795302421769869,0.7754105979212488
Transformer encoder with multi-modal multi-head attention for continuous affect recognition,https://ieeexplore.ieee.org/abstract/document/9257201/,"features through a multi-head attention mechanism; and finally, (3)  into the LSTM based  encoder-decoder architecture. More  the multi-head attention module used in the transformer-","H Chen, D Jiang, H Sahli",2020,IEEE Transactions on Multimedia,0.7684292052261589,0.7823444230469614,0.7753868141365601
HyperAttentionDTI: improving drug‚Äìprotein interaction prediction by sequence-based deep learning with attention mechanism,https://academic.oup.com/bioinformatics/article-abstract/38/3/655/6401997,"attention-based models, our model infers an attention vector  into attention vectors, da i and  pa j , by multi-layer perceptron  Then it utilizes Transformer embedding modules to obtain the","Q Zhao, H Zhao, K Zheng, J Wang",2022,Bioinformatics,0.7591824698381905,0.7913101745796264,0.7752463222089084
An improved U-net segmentation model that integrates a dual attention mechanism and a residual network for transformer oil leakage detection,https://www.mdpi.com/1996-1073/15/12/4238,"U-Net architecture, we removed the full connection layer in the original ResNet18 network  and  are more consistent with the ground truth than the model with only one attention module.","X Li, X Liu, Y Xiao, Y Zhang, X Yang, W Zhang",2022,Energies,0.7707614037254872,0.779638616632361,0.775200010178924
An integrated multi-head dual sparse self-attention network for remaining useful life prediction,https://www.sciencedirect.com/science/article/pii/S095183202300011X,"As for the single-head attention mechanism, it is assumed that  The Transformer is a multi-layer  encoder‚Äìdecoder model,  designs the encoder module of the Transformer model. After","J Zhang, X Li, J Tian, H Luo, S Yin",2023,Reliability Engineering & System Safety,0.7647675250883098,0.7850509877482659,0.7749092564182878
Attention fusion of transformer-based and scale-based method for hyperspectral and LiDAR joint classification,https://www.mdpi.com/2072-4292/15/3/650,We propose a module named fusion transformer (FUTR) for  obtained by the second  convolution layer in the stage that uses  fusion technique and cross attention mechanism for the,"M Zhang, F Gao, T Zhang, Y Gan, J Dong, H Yu",2023,Remote Sensing,0.7605237335866262,0.7892529320683286,0.7748883328274774
Centerformer: Center-based transformer for 3d object detection,https://link.springer.com/chapter/10.1007/978-3-031-19839-7_29,"transformer module, we use a deformable cross attention  The architecture of our model is  illustrated in Fig. 2. We use a  the fusion due to the attention mechanism. To further explore the","Z Zhou, X Zhao, Y Wang, P Wang",2022,European Conference on ‚Ä¶,0.7695717285307568,0.780021710196393,0.774796719363575
A transformer-based approach combining deep learning network and spatial-temporal information for raw EEG classification,https://ieeexplore.ieee.org/abstract/document/9845479/,"The attention mechanism of the Transformer has  the CNN module and the  Transformer module. CNN was  : We adopted the network architecture of Transformer [25], which","J Xie, J Zhang, J Sun, Z Ma, L Qin, G Li",2022,‚Ä¶ on Neural Systems ‚Ä¶,0.7646277655428763,0.7847194672621425,0.7746736164025094
Image captioning using transformer-based double attention network,https://www.sciencedirect.com/science/article/pii/S0952197623007297,"problem in transformers, a Masked Self-Attention module is  Therefore, the dropout layer  causes the proposed architecture better  task with a global attention mechanism. The semantic","H Parvin, AR Naghsh-Nilchi, HM Mohammadi",2023,Engineering Applications of ‚Ä¶,0.7676804146075383,0.7815763268856613,0.7746283707465997
Glalt: Global-local attention-augmented light transformer for scene text recognition,https://ieeexplore.ieee.org/abstract/document/10059008/,attention mechanism. The encoder integrates the self-attention module with the convolution  module  encoding and decoding mechanism in the attention architecture but also leverage,"H Zhang, G Luo, J Kang, S Huang",2023,‚Ä¶ on Neural Networks ‚Ä¶,0.7644245238866776,0.7847522956412815,0.7745884097639795
Cswin transformer: A general vision transformer backbone with cross-shaped windows,http://openaccess.thecvf.com/content/CVPR2022/html/Dong_CSWin_Transformer_A_General_Vision_Transformer_Backbone_With_Cross-Shaped_Windows_CVPR_2022_paper.html,", the Transformer architecture with full-attention mechanism [12]  operates directly upon V  and acts as a parallel module.  of l-th Transformer block or the precedent convolutional layer of","X Dong, J Bao, D Chen, W Zhang",2022,Proceedings of the ‚Ä¶,0.7732298234171664,0.7757282582277044,0.7744790408224353
Attention-based transformer-BiGRU for question classification,https://www.mdpi.com/2078-2489/13/5/214,"Our purpose of adding the Attention mechanism is to highlight  The experimental results show  that the model proposed in  , add an attention mechanism behind the two-layer network. On","D Han, T Tohti, A Hamdulla",2022,Information,0.7650986921198959,0.7835319883465185,0.7743153402332072
[Retracted] Research on Intelligent English Translation Method Based on the Improved Attention Mechanism Model,https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/9667255,"The attention mechanism module is mainly divided into the  module is the head attention  single-layer structure, the  the multiheaded attention network in the Transformer model with an",R Wang,2021,Scientific Programming,0.7702456530704501,0.7780221507184067,0.7741339018944284
Guideformer: Transformers for image guided depth completion,https://openaccess.thecvf.com/content/CVPR2022/html/Rho_GuideFormer_Transformers_for_Image_Guided_Depth_Completion_CVPR_2022_paper.html?ref=https://githubhelp.com,", a fully transformer-based architecture for dense depth com based on guided-attention  mechanism. It explicitly models  We introduce a guided-attention module (GAM) by extending","K Rho, J Ha, Y Kim",2022,‚Ä¶ of the IEEE/CVF Conference on ‚Ä¶,0.7692639875938843,0.7787032156024729,0.7739836015981786
TransBoNet: Learning camera localization with Transformer Bottleneck and Attention,https://www.sciencedirect.com/science/article/pii/S0031320323006738,"a framework based on hybrid attention mechanism which can be  We propose a new  attention-based neural network, which  , we use ResNet50 architecture as our basic network,","X Song, H Li, L Liang, W Shi, G Xie, X Lu, X Hei",2024,Pattern Recognition,0.7685784889336502,0.7793511773643956,0.773964833149023
Star-transformer: a spatio-temporal cross attention transformer for human action recognition,https://openaccess.thecvf.com/content/WACV2023/html/Ahn_STAR-Transformer_A_Spatio-Temporal_Cross_Attention_Transformer_for_Human_Action_Recognition_WACV_2023_paper.html,We therefore propose a STAR attention mechanism that can  -recognition model based on  the STAR-transformer module.  each layer of the transformer model and computes the token,"D Ahn, S Kim, H Hong, BC Ko",2023,Proceedings of the IEEE ‚Ä¶,0.7669828423419689,0.7805534054112675,0.7737681238766182
Weighted residual self-attention graph-based transformer for spectral‚Äìspatial hyperspectral image classification,https://www.tandfonline.com/doi/abs/10.1080/01431161.2023.2171744,"Therefore, in order to improve the layer-to-layer  The transformer architecture is performing  well due to its  Residual Self-attention Graph-based Transformer for the self-attention module (","B Zu, H Wang, J Li, Z He, Y Li, Z Yin",2023,International Journal of ‚Ä¶,0.7597431695851521,0.7877530315431167,0.7737481005641345
Omninet: Omnidirectional representations from transformers,https://proceedings.mlr.press/v139/tay21b.html,a brief background for the Transformer architecture. The  the core attention mechanism  here. Our choice of the efficient  layer to the pooling operation of the Omnidirectional module.,"Y Tay, M Dehghani, V Aribandi",2021,International ‚Ä¶,0.7678630889948568,0.779433301729203,0.7736481953620299
Enhancing dynamic ECG heartbeat classification with lightweight transformer model,https://www.sciencedirect.com/science/article/pii/S093336572200001X,a two-level attention mechanism: the local attention mechanism in the  Architecture of CNN  Input embedding with local attention.  ) is embedded into a CNN module that learns the local,"L Meng, W Tan, J Ma, R Wang, X Yin",2022,Artificial Intelligence in ‚Ä¶,0.7664301186493383,0.7805227828531507,0.7734764507512445
HMFT: Hyperspectral and Multispectral Image Fusion Super‚ÄêResolution Method Based on Efficient Transformer and Spatial‚ÄêSpectral Attention Mechanism,https://onlinelibrary.wiley.com/doi/abs/10.1155/2023/4725986,"and efficient hybrid architecture network based on Transformer is  our model with its variant,  which has no convolutional layer.  the FSM module to the MHA module of the Transformer to","B Qiao, B Xu, Y Xie, Y Lin, Y Liu",2023,Computational ‚Ä¶,0.7637323082924812,0.7830483746894457,0.7733903414909634
FAM: Improving columnar vision transformer with feature attention mechanism,https://www.sciencedirect.com/science/article/pii/S1077314224000626,", the multi-head attention sub-layer is utilized to model non- -stem with Feature Attention  Module (FAM) during model training and  that the network architecture significantly influences the","L Huang, X Bai, J Zeng, M Yu, W Pang",2024,Computer Vision and ‚Ä¶,0.7717787096226725,0.7746012015916734,0.773189955607173
Optimization-inspired cross-attention transformer for compressive sensing,http://openaccess.thecvf.com/content/CVPR2023/html/Song_Optimization-Inspired_Cross-Attention_Transformer_for_Compressive_Sensing_CVPR_2023_paper.html,"effect by a cross attention mechanism between adjacent iterations.  Architecture of our OCTUF,  which consists of K iterations. x  a Dual Cross Attention (DualCA) sub-module to efficiently","J Song, C Mou, S Wang, S Ma",2023,Proceedings of the ‚Ä¶,0.7561074018162165,0.7901747105043391,0.7731410561602778
Simplified self-attention for transformer-based end-to-end speech recognition,https://ieeexplore.ieee.org/abstract/document/9383581/,"a simplified self-attention (SSAN) layer which employs FSMN  In this paper, we focus on  attention-based models, aiming at  For the 1000-hour task, we use the best model architecture on","H Luo, S Zhang, M Lei, L Xie",2021,2021 IEEE Spoken Language ‚Ä¶,0.7546499764563359,0.7915750877146726,0.7731125320855042
A convolutional transformer architecture for remaining useful life estimation,https://ieeexplore.ieee.org/abstract/document/9612814/,global context capturing of attention mechanism with the local  convolutional module to the  vanilla Transformer architecture with a  One limitation of using local receptive field layer is that,"Y Ding, M Jia",2021,2021 Global Reliability and Prognostics and ‚Ä¶,0.7716397775380531,0.7739567590461516,0.7727982682921024
Sentiment classification based on part-of-speech and self-attention mechanism,https://ieeexplore.ieee.org/abstract/document/8962060/,"Currently, various attention-based neural networks have achieved successes   attention mechanism, we design a new Part-of-Speech based Transformer Attention Network(","K Cheng, Y Yue, Z Song",2020,IEEE Access,0.7653966002988531,0.7799911822643619,0.7726938912816075
Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition,https://ieeexplore.ieee.org/abstract/document/8462506/,"we find our proposed 2D-Attention mechanism achieves better  we present the model  architecture of the Speech-Transformer,  we apply 2D-Attention module to our big model, it shows","L Dong, S Xu, B Xu",2018,2018 IEEE international conference on ‚Ä¶,0.7666482430743343,0.7786011700280306,0.7726247065511824
LUCMT: Learnable under-sampling and reconstructed network with cross multi-head attention transformer for accelerating MR image reconstruction,https://www.sciencedirect.com/science/article/pii/S0169260724003523,"network employs a CS-MRI depth-expanded architecture,  In addition, we introduce a  multi-head attention mechanism  of the multi-head attention mechanism in the CMA module and","Z Yang, M Jiang, D Ruan, Y Li, T Tan, S Huang",2024,Computer Methods and ‚Ä¶,0.7562239835367532,0.7887450846910891,0.7724845341139212
Dlgsanet: lightweight dynamic local and global self-attention networks for image super-resolution,http://openaccess.thecvf.com/content/ICCV2023/html/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.html,"network designs of Transformers, we develop a simple yet effective multi-head dynamic local  self-attention (MHDLSA) module to  a channel attention mechanism to enable the network‚Äôs","X Li, J Dong, J Tang, J Pan",2023,Proceedings of the IEEE/CVF ‚Ä¶,0.7645541130941464,0.7798988051400161,0.7722264591170813
Object detection in medical images based on hierarchical transformer and mask mechanism,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/5863782,"the self-attention mechanism in the Transformer architecture  Therefore, we use the attention  mechanism to capture the  W-MSA module, the SW-MSA module, and the MLP module. The","Y Shou, T Meng, W Ai, C Xie, H Liu",2022,Computational ‚Ä¶,0.7661711770633056,0.778117656339598,0.7721444167014517
Graph transformer network with temporal kernel attention for skeleton-based action recognition,https://www.sciencedirect.com/science/article/pii/S0950705122000211,", and hence incorporating an attention mechanism to weigh  encoding module is unnecessary  in our graph transformer layer  robust network architecture kernel attention adaptive graph","Y Liu, H Zhang, D Xu, K He",2022,Knowledge-Based Systems,0.762237192572953,0.7817860948322088,0.7720116437025809
Learning dynamic and hierarchical traffic spatiotemporal features with transformer,https://ieeexplore.ieee.org/abstract/document/9520129/,Transformer only uses attention mechanism and fully  The overall architecture of the traffic  transformer is shown in Fig. 2 the second module is a fully connected feedforward layer. The,"H Yan, X Ma, Z Pu",2021,IEEE Transactions on Intelligent ‚Ä¶,0.7738940876958506,0.7700680711389669,0.7719810794174087
A Multi-Scale Cross-Fusion Medical Image Segmentation Network Based on Dual-Attention Mechanism Transformer,https://www.mdpi.com/2076-3417/13/19/10881,"network structure, and this network model uses our proposed DAT for coding and decoding  images. Our DAT module takes the form of a two-layer attention architecture as the network in","J Cui, L Wang, S Jiang",2023,Applied Sciences,0.7599774535991608,0.7838401395858806,0.7719087965925207
A novel transformer-based network with attention mechanism for automatic pavement crack detection,https://www.sciencedirect.com/science/article/pii/S0950061823015659,"-Decoder architecture with CNN is that it cannot model the long- A shared network that  includes the multi-layer perceptron ( original design of the CBAM module, we apply the sequential","F Guo, J Liu, C Lv, H Yu",2023,Construction and Building Materials,0.7729811198534702,0.7706705417008428,0.7718258307771565
Spatio-temporal graph transformer networks for pedestrian trajectory prediction,https://link.springer.com/chapter/10.1007/978-3-030-58610-2_30,"memory module, consistently being updated by the temporal  We show that with only attention  mechanism, STAR achieves  our experiment that Transformer based architecture provides","C Yu, X Ma, J Ren, H Zhao, S Yi",2020,"‚Ä¶ , Glasgow, UK, August 23‚Äì28, 2020 ‚Ä¶",0.775922920282575,0.7676473714550259,0.7717851458688005
A novel transformer-based attention network for image dehazing,https://www.mdpi.com/1424-8220/22/9/3428,Using the attention mechanism pays attention to detailed  a module that uses the Transformer  architecture to obtain channel  K ( x ) through a convolutional layer. Table 1 shows the,"G Gao, J Cao, C Bao, Q Hao, A Ma, G Li",2022,Sensors,0.7628614740641861,0.7806839112563626,0.7717726926602744
Brain network transformer,https://proceedings.neurips.cc/paper_files/paper/2022/hash/a408234a9b80604a9cf6ca518e474550-Abstract-Conference.html,Transformer-based designs to graph representation learning. GAT [57] firstly adapts the  attention mechanism to graph neural networks  a two-layer Multi-Head Self-Attention Module and,"X Kan, W Dai, H Cui, Z Zhang",2022,Advances in Neural ‚Ä¶,0.7689238333278801,0.7745725860948733,0.7717482097113767
Cross-view geo-localization with layer-to-layer transformer,https://proceedings.neurips.cc/paper/2021/hash/f31b20466ae89669f9741e047487eb37-Abstract.html,"a novel layer-to-layer Transformer (L2LTR) architecture with  a novel self-cross attention  mechanism to interact features  performance of selfattention-based model fluctuates a lot, while","H Yang, X Lu, Y Zhu",2021,Advances in Neural Information ‚Ä¶,0.7664352442514288,0.7769828743773839,0.7717090593144064
ResneSt-Transformer: Joint attention segmentation-free for end-to-end handwriting paragraph recognition model,https://www.sciencedirect.com/science/article/pii/S2590005623000255,"Subsequently, we develop an encoder module containing four transformer  The attention  mechanism in each block of our proposed architecture plays a crucial role in helping the model","M Hamdan, M Cheriet",2023,Array,0.7663648805809321,0.7769151419552853,0.7716400112681088
Boosted transformer for image captioning,https://www.mdpi.com/2076-3417/9/16/3260,"We apply the transformer architecture to the image captioning  In this paper, we stack a  vision-guided attention mechanism  a CGA module in the first encoder layer and a VGA module in","J Li, P Yao, L Guo, W Zhang",2019,Applied Sciences,0.758206049122031,0.7845462300501986,0.7713761395861148
Sotr: Segmenting objects with transformers,http://openaccess.thecvf.com/content/ICCV2021/html/Guo_SOTR_Segmenting_Objects_With_Transformers_ICCV_2021_paper.html,propose the twin attention mechanism to simplify the attention matrix  by transformer on  the multi-level upsampling module. As  We denote the backbone architecture with network-depth-,"R Guo, D Niu, L Qu, Z Li",2021,Proceedings of the IEEE/CVF ‚Ä¶,0.7815949249149117,0.7608087524038094,0.7712018386593605
Dilated transformer: residual axial attention for breast ultrasound image segmentation,https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9403584/,"axial attention scores to the axial attention mechanism,  of the multi-head on both height-layer  and width-axial layer  dilated convolution module which is often used in the architecture of","X Shen, L Wang, Y Zhao, R Liu, W Qian",2022,Quantitative Imaging in ‚Ä¶,0.7723064512863003,0.7698320307005707,0.7710692409934354
A time-aware self-attention based neural network model for sequential recommendation,https://www.sciencedirect.com/science/article/pii/S1568494622009437,"In this paper, we propose a Time-Aware Transformer for  Essentially the idea behind the  attention mechanism is to  accelerate neural network training, following [14], [17], we apply Layer","Y Zhang, B Yang, H Liu, D Li",2023,Applied Soft Computing,0.7617782736060383,0.7803027312376458,0.7710405024218421
Efficient long-range attention network for image super-resolution,https://link.springer.com/chapter/10.1007/978-3-031-19790-1_39,"module, which is further accelerated by using a shared  The existing transformer-based  models such as SwinIR [29]  Finally, by employing the proposed shared attention mechanism, we","X Zhang, H Zeng, S Guo, L Zhang",2022,European conference on computer ‚Ä¶,0.7633586538315852,0.7786002558544433,0.7709794548430142
Weighted feature fusion of dual attention convolutional neural network and transformer encoder module for ocean HABs classification,https://www.sciencedirect.com/science/article/pii/S095741742303381X,the attention mechanism with the convolutional neural network as  architecture leverages a  combination of the Transformer  We apply layer normalization (LN) before each block and use,"GK Wu, J Xu, YD Zhang, BY Wen, BP Zhang",2024,Expert Systems with ‚Ä¶,0.764765514220451,0.7768609217154308,0.7708132179679409
Conformer: Convolution-augmented transformer for speech recognition,https://arxiv.org/abs/2005.08100,as proposed in [6] deploys a feed forward module after the MHSA layer and is composed of   module in our Conformer architecture. The combination of convolution and self-attention has,"A Gulati, J Qin, CC Chiu, N Parmar, Y Zhang",2020,arXiv preprint arXiv ‚Ä¶,0.7622660348395927,0.7790582767478602,0.7706621557937264
Interpretable CNN-multilevel attention transformer for rapid recognition of pneumonia from chest X-ray images,https://ieeexplore.ieee.org/abstract/document/10050021/,"low computational complexity attention mechanism, which  Given that this attention module  contains N heads internally,  and input to the subsequent Transformer architecture, where ‚Äù√ó3‚Äù","S Chen, S Ren, G Wang, M Huang",2023,IEEE Journal of ‚Ä¶,0.7578693798593173,0.783122469914274,0.7704959248867957
SRRNet: A Transformer Structure with Adaptive 2D Spatial Attention Mechanism for Cell Phone-Captured Shopping Receipt Recognition,https://ieeexplore.ieee.org/abstract/document/9987538/,"Our model is largely inspired by transformer architecture, which  key module, adaptive 2D  spatial attention mechanism, can be  an embedding layer and a linear layer after position range","H Zhou, L Shao, H Zhang",2022,IEEE Transactions on Consumer ‚Ä¶,0.7635403530526519,0.7772836972387391,0.7704120251456955
Cloze-driven pretraining of self-attention networks,https://arxiv.org/abs/1903.07785,Our bi-directional transformer architecture predicts every  that our model also works well with  an ELMo module on NER  (2017) we apply layer normalization before the self-attention and,"A Baevski, S Edunov, Y Liu, L Zettlemoyer",2019,arXiv preprint arXiv ‚Ä¶,0.7604814333762011,0.7798956710247265,0.7701885522004638
Attransunet: An enhanced hybrid transformer architecture for ultrasound and histopathology image segmentation,https://www.sciencedirect.com/science/article/pii/S0010482522010733,"single-layer SFRM does not enable the network to enhance  the SFRM with the spatial  attention mechanism in the same  and Transformer, a Selective Feature Reinforcement Module (","X Li, S Pang, R Zhang, J Zhu, X Fu, Y Tian",2023,Computers in Biology and ‚Ä¶,0.7764533623875507,0.7637581119661409,0.7701057371768458
Enhancing heart disease prediction using a self-attention-based transformer model,https://www.nature.com/articles/s41598-024-51184-7,"This attention-based model architecture with self-attention  , we modify our model‚Äôs local-based  attention mechanism to  with an attention layer is followed by a classification layer. This","AU Rahman, Y Alsenani, A Zafar, K Ullah, K Rabie",2024,Scientific Reports,0.7544918178634304,0.7856568504846393,0.7700743341740348
TGDAUNet: Transformer and GCNN based dual-branch attention UNet for medical image segmentation,https://www.sciencedirect.com/science/article/pii/S001048252301048X,network and parallel attention mechanism to solve the problem of clinical focus segmentation.  TGAUNet uses the MF module and PSA module to  architecture of the TGDAUNet network,"P Song, J Li, H Fan, L Fan",2023,Computers in Biology and Medicine,0.7696597802489167,0.7699560933790193,0.769807936813968
Machine Translation Using Improved Attention-based Transformer with Hybrid Input,https://ieeexplore.ieee.org/abstract/document/9122317/,"In this study, an attention-based deep learning architecture is proposed for MT, with all   connections from the encoder output to the decoder's first layer). Attention Mechanism allows the","M Abrishami, MJ Rashti",2020,2020 6th International ‚Ä¶,0.7608534268378426,0.7784403069309805,0.7696468668844116
Global‚Äìlocal self-attention based transformer for speaker verification,https://www.mdpi.com/2076-3417/12/19/10154,"The attention mechanism is at the heart of Transformer‚Äôs  , followed by a statistical pooling  layer and two linear layers. In  work used self-attention as the backbone of our architecture. Its","F Xie, D Zhang, C Liu",2022,Applied Sciences,0.7595803299179914,0.7792457700407506,0.769413049979371
Hyperspectral image classification based on multibranch attention transformer networks,https://ieeexplore.ieee.org/abstract/document/9851412/,The representative spatial attention mechanism methods include spatial transformer  3)  Transformer Classification: The architecture of a singlelayer transformer encoder module in this,"J Bai, Z Wen, Z Xiao, F Ye, Y Zhu",2022,IEEE Transactions on ‚Ä¶,0.7719492431588735,0.7666160369951244,0.769282640076999
A hybrid enhanced attention transformer network for medical ultrasound image segmentation,https://www.sciencedirect.com/science/article/pii/S1746809423007620,"a channel enhanced self-attention-based transformer (ECAT 1, the basic architecture of our  proposed HEAT-Net is a U-Net its insertion at a shallow network layer would introduce more","T Jiang, W Xing, M Yu, D Ta",2023,Biomedical Signal Processing and Control,0.7561971082283119,0.7823577600954701,0.769277434161891
Relation transformer network,https://arxiv.org/abs/2004.06193,the attention mechanism of the transformer. An overview of the proposed Relation Transformer  architecture is  We incorporate self-attention module in the encoder of our transformer that,"R Koner, S Shit, V Tresp",2020,arXiv preprint arXiv:2004.06193,0.7695719901595446,0.7688911890437041,0.7692315896016244
Adversarial joint training with self-attention mechanism for robust end-to-end speech recognition,https://link.springer.com/article/10.1186/s13636-021-00215-6,"We propose a self-attention-based jointly trained adversarial framework  The location-based  attention mechanism comprises 10  The same as the Transformer, we train the network with","L Li, Y Kang, Y Shi, L K√ºrzinger, T Watzel",2021,EURASIP Journal on ‚Ä¶,0.7510878511118491,0.787081717733555,0.769084784422702
Shuffle transformer: Rethinking spatial shuffle for vision transformer,https://arxiv.org/abs/2106.03650,"layer with a residual connection into the Shuffle Transformer  module into the shuffle  transformer block for building rich crosswindow connections. Finally, the overall network architecture","Z Huang, Y Ben, G Luo, P Cheng, G Yu",2021,arXiv preprint arXiv ‚Ä¶,0.7658812020504053,0.7720135599627721,0.7689473810065888
A review on the attention mechanism of deep learning,https://www.sciencedirect.com/science/article/pii/S092523122100477X,"network architecture of attention models, the memory network -forward network (FFN) layer  and multi-head attention layer.  , the spatial transformer module is a dynamic mechanism that","Z Niu, G Zhong, H Yu",2021,Neurocomputing,0.7650662152023229,0.7727081343368692,0.768887174769596
CSwin-PNet: A CNN-Swin Transformer combined pyramid network for breast lesion segmentation in ultrasound images,https://www.sciencedirect.com/science/article/pii/S0957417422020425,channel attention (ICA) module using channel-wise attention to  architecture that is used  for the construction of global  the attention mechanism can encourage the network to pay,"H Yang, D Yang",2023,Expert Systems with Applications,0.7572224408431858,0.7804896690124561,0.7688560549278209
Improved transformer with multi-head dense collaboration,https://ieeexplore.ieee.org/abstract/document/9870037/,"CLC to the Transformerbased encoder-decoder architecture.  module of Transformer, we  adopt the standard Transformer [5 vanilla Transformer without the residual attention mechanism.","H Wang, X Shen, M Tu, Y Zhuang",2022,IEEE/ACM Transactions ‚Ä¶,0.756471654861687,0.781202592847435,0.768837123854561
ABT-GAMNet: A novel adaptive Boundary-aware transformer with Gated attention mechanism for automated skin lesion segmentation,https://www.sciencedirect.com/science/article/pii/S1746809423004044,between encoder and decoder networks. It has extracted the  given to the encoder layer in  every transformer to render the  typical design of a multi-head self-attention module (msa) and,"J Deepa, P Madhavan",2023,Biomedical Signal Processing and Control,0.7605089724573513,0.7766571409115977,0.7685830566844745
Efficient visual tracking via hierarchical cross-attention transformer,https://link.springer.com/chapter/10.1007/978-3-031-25085-9_26,"Without the FS module in our method, the attention mechanism  architecture of our hierarchical  cross-attention transformer is  In experiments, we find that the self-attention layer brings","X Chen, B Kang, D Wang, D Li, H Lu",2022,European Conference on Computer ‚Ä¶,0.7520420360004332,0.7850778737231181,0.7685599548617756
Transformers meet visual learning understanding: A comprehensive review,https://arxiv.org/abs/2203.12944,"First, the attention mechanism is reviewed, which plays an  visual Transformer model and  the principle of each module  -decoder architecture is also adopted in the Transformer model. It","Y Yang, L Jiao, X Liu, F Liu, S Yang, Z Feng",2022,arXiv preprint arXiv ‚Ä¶,0.7621009310227664,0.7749591880202805,0.7685300595215234
KEAHT: A knowledge-enriched attention-based hybrid transformer model for social sentiment analysis,https://link.springer.com/article/10.1007/s00354-022-00182-2,It provides the facility of attention mechanism and can solve  The whole architecture of  the proposed KEAHT model is  hybrid model by adding the knowledge-enriched layer in the,"D Tiwari, B Nagpal",2022,New Generation Computing,0.7608767705292491,0.7758502015943797,0.7683634860618144
U-net transformer: Self and cross attention for medical image segmentation,https://link.springer.com/chapter/10.1007/978-3-030-87589-3_28,", which combines a U-shaped architecture for image  Firstly, a self-attention module  leverages global interactions between  Our cross-attention mechanism shares the high-level","O Petit, N Thome, C Rambour, L Themyr",2021,Machine Learning in ‚Ä¶,0.7617412534194795,0.7749336554647309,0.7683374544421052
Knowing what it is: semantic-enhanced dual attention transformer,https://ieeexplore.ieee.org/abstract/document/9749944/,"a novel attention module termed Channel-wise Attention  In contrast, we propose a novel  attention mechanism to  -and interlayer global representation in transformer network,‚Äù in","Y Ma, J Ji, X Sun, Y Zhou, Y Wu",2022,IEEE Transactions on ‚Ä¶,0.7631503649453557,0.7733244148974232,0.7682373899213895
Bayesian Transformer Using Disentangled Mask Attention.,https://www.isca-archive.org/interspeech_2022/chien22_interspeech.pdf,"First, due to the natural property that attention mechanism  mask attention based on the  disentangled attention heads for  The first level involves latent variables of transformer layer","JT Chien, YH Huang",2022,INTERSPEECH,0.7629779664621924,0.7734844198577282,0.7682311931599604
Aspect-based sentiment classification with multi-attention network,https://www.sciencedirect.com/science/article/pii/S092523122030059X,a global and a local attention module to capture differently  is the first model in which an  attention mechanism performs aspect- We apply a transformer encoder to the word embedding to,"Q Xu, L Zhu, T Dai, C Yan",2020,Neurocomputing,0.7684812743080416,0.7675242201065328,0.7680027472072872
"Attention mechanism, transformers, BERT, and GPT: tutorial and survey",https://osf.io/preprints/m6gcn/,"model with and without attention mechanism as well as the  This module applies the  attention mechanism for h times.  Then, it is fed to a feedforward neural network with layer nor","B Ghojogh, A Ghodsi",2020,NA,0.7614251029830962,0.7742424754796892,0.7678337892313927
Advancing drug discovery with deep attention neural networks,https://www.sciencedirect.com/science/article/pii/S1359644624001922,"attention mechanism and its extended architectures, including graph attention networks (GATs),  transformers The present article focuses on recent advancements of attention-based",A Lavecchia,2024,Drug Discovery Today,0.765133856440388,0.7703842968644962,0.767759076652442
Diffusion kernel attention network for brain disorder classification,https://ieeexplore.ieee.org/abstract/document/9763540/,"attention to replace the original dot-product attention module  of the architecture of the  original Transformer and specific  attention mechanism is proposed. With this, the improved","J Zhang, L Zhou, L Wang, M Liu",2022,IEEE Transactions on ‚Ä¶,0.7572072531068129,0.7780500898365844,0.7676286714716987
Transformer-based deep reverse attention network for multi-sensory human activity recognition,https://www.sciencedirect.com/science/article/pii/S0952197623003342,"deep reverse transformer-based attention mechanism to guide  We put together a 3-block  CNN architecture, where each block  To be specific, we propose a reverse attention module to","R Pramanik, R Sikdar, R Sarkar",2023,Engineering Applications of Artificial ‚Ä¶,0.7593947072864351,0.7758245842509883,0.7676096457687117
A superior image inpainting scheme using Transformer-based self-supervised attention GAN model,https://www.sciencedirect.com/science/article/pii/S0957417423014082,"-supervised attention module in the Transformer to overcome  This paper constructs a new  Swin GAN overall architecture,  supervised attention mechanism and Swin Transformer-based","M Zhou, X Liu, T Yi, Z Bai, P Zhang",2023,Expert Systems with Applications,0.7596296558318352,0.7752905747099568,0.767460115270896
Grouped self-attention mechanism for a memory-efficient Transformer,https://www.researchgate.net/profile/Bumjun-Jung/publication/364126129_Grouped_self-attention_mechanism_for_a_memory-efficient_Transformer/links/638a363f7d9b40514e0b0c9e/Grouped-self-attention-mechanism-for-a-memory-efficient-Transformer.pdf,", which is the bottleneck of the Transformer architecture. This  decoder layer and the complexity  of the cross-attention module  GSA module is a type of local attention mechanism that can","B Jung, Y Mukuta, T Harada",2022,arXiv preprint arXiv:2210.00440,0.7577258650406775,0.7771383402728247,0.7674321026567511
LiteTransNet: An interpretable approach for landslide displacement prediction using transformer model with attention mechanism,https://www.sciencedirect.com/science/article/pii/S0013795224000449,"Additionally, the Transformer's attention-based feature  our lightweighted Transformer model  simplifies the network architecture  the attention map, we extract the last layer of the attention","Q Ge, J Li, X Wang, Y Deng, K Zhang, H Sun",2024,Engineering Geology,0.7662143705165945,0.768381704185824,0.7672980373512093
Transformer for single image super-resolution,https://openaccess.thecvf.com/content/CVPR2022W/NTIRE/html/Lu_Transformer_for_Single_Image_Super-Resolution_CVPRW_2022_paper.html,"Inspired by the high-pass filter, we design a High-frequency Filtering Module (HFM) to capture   residual network with residualin-residual architecture and channel attention mechanism.","Z Lu, J Li, H Liu, C Huang, L Zhang",2022,Proceedings of the ‚Ä¶,0.7582502742638704,0.7763381788113559,0.7672942265376131
Improving image captioning by leveraging intra-and inter-layer global representation in transformer network,https://ojs.aaai.org/index.php/AAAI/article/view/16258,"Transformer architecture, ie, Global Enhanced Transformer ( fed into the multi-head self-attention  module in each layer. By this  the baseline model by adopting the GEA module, which","J Ji, Y Luo, X Sun, F Chen, G Luo, Y Wu",2021,Proceedings of the AAAI ‚Ä¶,0.7594714700215005,0.7748946673274792,0.7671830686744898
High-performance transformer tracking,https://ieeexplore.ieee.org/abstract/document/9999490/,an attention-based feature fusion network and pro-  -decoder architecture in the original  transformer because it does  of the transformer and exploit the attention mechanism to design the,"X Chen, B Yan, J Zhu, H Lu, X Ruan",2022,IEEE Transactions on ‚Ä¶,0.7720263099343385,0.7621889529346179,0.7671076314344782
Double-stream position learning transformer network for image captioning,https://ieeexplore.ieee.org/abstract/document/9791335/,"‚Ä¢ We propose a double-stream Transformer architecture to  -stream Transformer encoder, we  apply the RPL module to  an Adaptive Fusion Attention mechanism for the language decoder","W Jiang, W Zhou, H Hu",2022,‚Ä¶ on Circuits and Systems for Video ‚Ä¶,0.7648156623024329,0.7688431914944228,0.7668294268984279
Hyperspectral image classification based on graph transformer network and graph attention mechanism,https://ieeexplore.ieee.org/abstract/document/9793640/,"to the graph convolution network model. The graph transformer layer (GT-layer) is adopted   But in this paper, with the use of the GT-layer module, which is introduced in III -B, we do not","X Zhao, J Niu, C Liu, Y Ding",2022,IEEE Geoscience and ‚Ä¶,0.7540675899763993,0.779414188428086,0.7667408892022427
T-TAME: Trainable Attention Mechanism for Explaining Convolutional Networks and Vision Transformers,https://ieeexplore.ieee.org/abstract/document/10539635/,"images, thanks to its multi-head attention layer, and we confirm  : a trainable attention  mechanism architecture, along with a  the Attention Mechanism ‚Ä¢ The fusion module of the","MV Ntrougkas, N Gkalelis, V Mezaris",2024,IEEE Access,0.7544591587547689,0.7785757949013488,0.7665174768280588
Sequential transformer via an outside-in attention for image captioning,https://www.sciencedirect.com/science/article/pii/S0952197621004073,"generating process, an attention mechanism is used in  to integrate such module into the  Transformer encoder‚Äìdecoder  replace the attention layer in Sequence Memory Module, while","Y Wei, C Wu, G Li, H Shi",2022,Engineering Applications of Artificial Intelligence,0.7651165058806525,0.7674924375633967,0.7663044717220246
Dual self-attention Swin transformer for hyperspectral image super-resolution,https://ieeexplore.ieee.org/abstract/document/10123084/,by integrating it with the Swin Transformer architecture.  DSSTSR network uses a multi-layer  perceptron (MLP) layer  Denoising module and Dual Self-Attention Swin Transformer module,"Y Long, X Wang, M Xu, S Zhang",2023,IEEE Transactions on ‚Ä¶,0.7542318492492546,0.7783508001041486,0.7662913246767016
Attention-aligned transformer for image captioning,https://ojs.aaai.org/index.php/AAAI/article/view/19940,"Such attention module learns the attended features that  Attention mechanism plays an  essential role in image captioning, which  Figure 3: Architecture of the A2 Transformer. Mask pertur",Z Fei,2022,proceedings of the AAAI Conference on Artificial ‚Ä¶,0.759456081650514,0.7729838588612062,0.7662199702558601
Remote sensing image change detection transformer network based on dual-feature mixed attention,https://ieeexplore.ieee.org/abstract/document/9905616/,"convolutional networks, attention mechanism and transformer -feature mixed attention based  transformer network (DMATNet mulit-head self-attention based transformer encoder layer. In","X Song, Z Hua, J Li",2022,IEEE Transactions on Geoscience and ‚Ä¶,0.7652334405147372,0.766949763448335,0.766091601981536
Self-and-mixed attention decoder with deep acoustic structure for transformer-based lvcsr,https://arxiv.org/abs/2006.10407,We also design a mixed attention mechanism that learns the  Multi-head attention is the  core module of the Transformer  Figure 1 shows an encoder-decoder architecture for ASR. We,"X Zhou, G Lee, E Yƒ±lmaz, Y Long, J Liang",2020,arXiv preprint arXiv ‚Ä¶,0.7499983685908156,0.7816301103077711,0.7658142394492933
Multi-modal learning for AU detection based on multi-head fused transformers,https://ieeexplore.ieee.org/abstract/document/9667030/,"Meanwhile, the attention mechanism has been adopted in  that are utilized transformer  architecture for both feature  multi-head fusion attention module in the fusion transformer to","X Zhang, L Yin",2021,2021 16th IEEE International Conference on ‚Ä¶,0.7613780688805143,0.7701733225349706,0.7657756957077424
EEG emotion recognition using attention-based convolutional transformer neural network,https://www.sciencedirect.com/science/article/pii/S1746809423002689,"of all time slices, and feed them into the transformer-based temporal encoding layer to use   spatial and spectral attention mechanism. Next, we use the convolution module to extract the","L Gong, M Li, T Zhang, W Chen",2023,Biomedical Signal Processing and Control,0.7480454797251294,0.7833734910879089,0.7657094854065192
Multimodal Transformer Networks for Pedestrian Trajectory Prediction.,https://www.ijcai.org/proceedings/2021/0174.pdf,network is only attention-based that can efficiently model long of a cross-attention module  and a feed-forward layer. Then the  architecture takes the advantage of attention mechanism to,"Z Yin, R Liu, Z Xiong, Z Yuan",2021,IJCAI,0.7621642262851419,0.7690904848375436,0.7656273555613428
"‚Ä¶ : A Multi-Branch Fault Diagnosis Method for Scroll Compressors Using Swin Transformer Sliding Window, Shallow ResNet, and Global Attention Mechanism  ‚Ä¶",https://www.mdpi.com/1424-8220/24/19/6237,"of the module via identity mapping, ensuring that each layer  a fully attention-based design,  the Swin Transformer model  the architecture of the proposed multi-channel SSG-Net model","Z Xu, T Liu, Z Xia, Y Fan, M Yan, X Dang",2024,Sensors,0.7594458495394933,0.7710392080912809,0.7652425288153871
Depression detection in speech using transformer and parallel convolutional neural networks,https://www.mdpi.com/2079-9292/12/2/328,"improved transformer with a linear attention mechanism as a  the transformer module  included four transformer layers with  ) [72,73], the CNN architecture used in this paper set three","F Yin, J Du, X Xu, L Zhao",2023,Electronics,0.7666446894053088,0.76372319566263,0.7651839425339695
ST-MDAMNet: Swin transformer combines multi-dimensional attention mechanism for semantic segmentation of high-resolution earth surface images,https://www.sciencedirect.com/science/article/pii/S0273117724006471,"field, traditional convolutional neural networks (CNN) cannot  Swin Transformer encoder to  effectively enhance the model‚Äôs  We demonstrate the effectiveness of each module through","B Liu, B Li, H Liu, S Li",2024,Advances in Space Research,0.7517081127699032,0.7781305901663769,0.76491935146814
COVID-19 diagnosis based on swin transformer model with demographic information fusion and enhanced multi-head attention mechanism,https://www.sciencedirect.com/science/article/pii/S0957417423033079,of the Swin Transformer layer are retained to reconstruct a regression model that predict the   In order to test the effectiveness of each module and compare our model with other networks,"Y Sun, J Lian, Z Teng, Z Wei, Y Tang, L Yang",2024,Expert Systems with ‚Ä¶,0.7547868747864761,0.7748690349901106,0.7648279548882934
RDTNet: A residual deformable attention based transformer network for breast cancer classification,https://www.sciencedirect.com/science/article/pii/S0957417424004342,"multi-head deformable self-attention  CNN architecture and a residual deformable transformer  layer. The proposed RDTNet enjoys the benefits of both CNN and ViT, allowing the model",DR Nayak,2024,Expert Systems with Applications,0.7494626615188495,0.7800043184649024,0.764733489991876
TiM‚ÄêNet: Transformer in M‚ÄêNet for Retinal Vessel Segmentation,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/9016401,"dual-attention mechanism and Transformer module are plug- the dual-attention mechanism  behind the encoder layer to  Hence, it consists of the M-Net architecture, a new encoder","H Zhang, X Zhong, Z Li, Y Chen, Z Zhu",2022,Journal of ‚Ä¶,0.7612734891535373,0.7676080349934113,0.7644407620734743
Transformer-based attention networks for continuous pixel-wise prediction,http://openaccess.thecvf.com/content/ICCV2021/html/Yang_Transformer-Based_Attention_Networks_for_Continuous_Pixel-Wise_Prediction_ICCV_2021_paper.html,"In this paper, we propose TransDepth, an architecture that  embedding module is removed  from our linear Transformer, but  , a network equipped with a channel attention mechanism to","G Yang, H Tang, M Ding, N Sebe",2021,Proceedings of the ‚Ä¶,0.7580415813962577,0.770394819380243,0.7642182003882503
LPT-Net: A Line-Pad Transformer Network for efficiency coal gangue segmentation with linear multi-head self-attention mechanism,https://www.sciencedirect.com/science/article/pii/S026322412301607X,"of the second layer and MSA1 for MSA2 of the fourth layer.  LPT-Net, based on the Transformer  architecture, could benefit  We build L-MSA module based on linear attention mechanism","T Ye, H Chen, H Ren, Z Zheng, Z Zhao",2024,Measurement,0.7581377385573274,0.7699024620368811,0.7640201002971042
Global self-attention as a replacement for graph convolution,https://dl.acm.org/doi/abs/10.1145/3534678.3539296,"In relation to our work, we discuss self-attention based GNN models, where the attention   dynamically formed by the attention mechanism. However, the basic transformer does not have","MS Hussain, MJ Zaki, D Subramanian",2022,Proceedings of the 28th ACM ‚Ä¶,0.746091528028118,0.7816155068674967,0.7638535174478074
Refiner: Refining self-attention for vision transformers,https://arxiv.org/abs/2106.03714,"local attention mechanism that combines both strengths of  the baseline model and replace  the self-attention module with  Thus, we design the architecture of Refiner-ViT based on the","D Zhou, Y Shi, B Kang, W Yu, Z Jiang, Y Li",2021,arXiv preprint arXiv ‚Ä¶,0.7491652851514115,0.7784895928616804,0.7638274390065459
Modeling air quality PM2. 5 forecasting using deep sparse attention-based transformer networks,https://link.springer.com/article/10.1007/s13762-023-04900-1,"In our STN, a multi-head sparse attention mechanism is  masked sparse attention block,  a multi-head attention layer,  LSTMs are a special kind of recurrent architecture used for","Z Zhang, S Zhang",2023,International Journal of Environmental Science and ‚Ä¶,0.7545344893639583,0.7730068864792256,0.763770687921592
Modeling transformer architecture with attention layer for human activity recognition,https://link.springer.com/article/10.1007/s00521-023-09362-7,"introduced a temporal attention mechanism that discovers an  via the video action transformer  network. Video action  Additionally, we utilize BERT, an attention-based mechanism, to","G Pareek, S Nigam, R Singh",2024,Neural Computing and Applications,0.7565422187788027,0.7707320688657207,0.7636371438222617
"Tgc-yolov5: An enhanced yolov5 drone detection model based on transformer, gam & ca attention mechanism",https://www.mdpi.com/2504-446X/7/7/446,": First, the Transformer encoder module is incorporated into  , all with the same model  architecture but different widths and  eighth layer of the original Yolov5s version with a Transformer","Y Zhao, Z Ju, T Sun, F Dong, J Li, R Yang, Q Fu, C Lian",2023,Drones,0.7574981286289308,0.7695296620294121,0.7635138953291715
Aiatrack: Attention in attention for transformer visual tracking,https://link.springer.com/chapter/10.1007/978-3-031-20047-2_9,"this insight to the attention mechanism for the first time, making  AiA module, we design a  simple yet effective Transformer  of a network backbone, a Transformer architecture, and two","S Gao, C Zhou, C Ma, X Wang, J Yuan",2022,European Conference on ‚Ä¶,0.7613997392407551,0.7649736505890197,0.7631866949148873
Conversational question answering over knowledge graphs with transformer and graph attention networks,https://arxiv.org/abs/2104.01569,"a transformer architecture extended with Graph Attention  multi-head attention mechanism.  The decoder output is  Furthermore, we also introduce a graph attentionbased module, which","E Kacupaj, J Plepi, K Singh, H Thakkar",2021,arXiv preprint arXiv ‚Ä¶,0.7564417932289714,0.7697407404649707,0.763091266846971
Multi-behavior hypergraph-enhanced transformer for sequential recommendation,https://dl.acm.org/doi/abs/10.1145/3534678.3539342,"We propose a multi-scale Transformer module to  the overall architecture of our proposed  MBHT model which  structure in [22], we design a low-rank-based self-attention layer without","Y Yang, C Huang, L Xia, Y Liang, Y Yu",2022,Proceedings of the 28th ‚Ä¶,0.7593114062639098,0.7667417877924207,0.7630265970281653
EAPT: efficient attention pyramid transformer for image processing,https://ieeexplore.ieee.org/abstract/document/9580642/,"of the i-th layer to obtain the windows of the (i + 1)-th layer.  En-DeC module, which is based  on an encode-decode architecture  However, such an attention mechanism is not capable of","X Lin, S Sun, W Huang, B Sheng, P Li",2021,IEEE Transactions on ‚Ä¶,0.7522703608388701,0.7734312854878183,0.7628508231633442
Self-attention based molecule representation for predicting drug-target interaction,http://proceedings.mlr.press/v106/shin19a.html?ref=https://githubhelp.com,"a new deep DTI model, Molecule Transformer DTI (MT-DTI),  We first describe the proposed  MT-DTI model architecture ( Each Transformer block consists of a self-attention layer and","B Shin, S Park, K Kang, JC Ho",2019,Machine learning for ‚Ä¶,0.7545845546391681,0.7707629531355751,0.7626737538873716
A Joint Architecture of Mixed-Attention Transformer and Octave Module for Hyperspectral Image Denoising,https://ieeexplore.ieee.org/abstract/document/10410657/,"extraction module and spatial-channel attention mechanism.  built with layer normalization  (LayerNorm), attention module,  module without the inclusion of an attention network or base","M Ashraf, L Chen, X Zhou",2024,IEEE Journal of Selected ‚Ä¶,0.7574737375701479,0.76734076203453,0.762407249802339
Multi-Head-Self-Attention based YOLOv5X-transformer for multi-scale object detection,https://link.springer.com/article/10.1007/s11042-023-15773-4,"excitation attention mechanism in the YOLOv3 model. In this  last C3 layer is replaced with  a transformer block followed by  -Transformer model used a transformer architecture, it used","P Vasanthi, L Mohan",2024,Multimedia Tools and Applications,0.7493721400198643,0.774925021370605,0.7621485806952346
Structural rotor fault diagnosis using attention-based sensor fusion and transformers,https://ieeexplore.ieee.org/abstract/document/9625031/,"AM is found in the DL architecture called transformers [27], [28] -wise feed-forward layer with  residual connections and layer  of both multi-head attention mechanism and RNNs. General","AG Nath, SS Udmale, D Raghuwanshi",2021,IEEE Sensors ‚Ä¶,0.7617403380532148,0.7621270522087318,0.7619336951309733
Attention swin u-net: Cross-contextual attention mechanism for skin lesion segmentation,https://ieeexplore.ieee.org/abstract/document/10230337/,", recently a Transformer based U-Net architecture that  incorporating the attention mechanism  into the Transformer skip  U-Net model [10], we propose Att-SwinU-Net, an attention-based","EK Aghdam, R Azad, M Zarvani",2023,2023 IEEE 20th ‚Ä¶,0.7571156904153599,0.7667184505505622,0.761917070482961
RSAM: Robust self-attention based multi-horizon model for solar irradiance forecasting,https://ieeexplore.ieee.org/abstract/document/9301241/,A self-attention based Transformer model belonging to the family  attention mechanism for  multivariate solar time-series  uses self-attention based deep learning architecture because of,"S Sharda, M Singh, K Sharma",2020,IEEE Transactions on ‚Ä¶,0.7433753276391842,0.7802699849063834,0.7618226562727839
Medical image segmentation using transformer networks,https://ieeexplore.ieee.org/abstract/document/9729189/,"neural network architecture, based entirely on self-attention  propose a self-attention-based  deep neural network for 3D  of self-attention models because the attention mechanism is","D Karimi, H Dou, A Gholipour",2022,IEEE Access,0.7484788623332193,0.7751221255538816,0.7618004939435504
A Simplified Query-Only Attention for Encoder-Based Transformer Models,https://www.mdpi.com/2076-3417/14/19/8646,"‚Äôs architecture. Our findings suggest that query-only  -only attention mechanism for  encoder-based transformer models.  in light green, and the fully connected layer module in","H Yeom, K An",2024,Applied Sciences,0.7592465329531014,0.764319693348932,0.7617831131510167
Attention is all you need in speech separation,https://ieeexplore.ieee.org/abstract/document/9413901/,"Transformers are emerging as a natural alternative to standard RNNs, replacing recurrent  computations with a multi-head attention mechanism a fully attention-based mechanism. By","C Subakan, M Ravanelli, S Cornell",2021,ICASSP 2021-2021 ‚Ä¶,0.7654662963220029,0.757811348881219,0.761638822601611
ST-YOLOA: a Swin-transformer-based YOLO model with an attention mechanism for SAR ship detection under complex background,https://www.frontiersin.org/articles/10.3389/fnbot.2023.1170163/full,"First, the Swin Transformer network architecture and coordinate attention ( after the Patch  Merging layer. CA  the SE attention mechanism in the Bottleneck module to selectively","K Zhao, R Lu, S Wang, X Yang, Q Li",2023,Frontiers in ‚Ä¶,0.7558272495725294,0.7672830265655592,0.7615551380690444
Efficient brain tumor segmentation using Swin transformer and enhanced local self-attention,https://link.springer.com/article/10.1007/s11548-023-03024-8,presented model that uses the ELSA transformer module in  lower accuracy with the attention  mechanism may be due to  the proposed architecture with ELSA transformer blocks into the,"F Ghazouani, P Vera, S Ruan",2024,International Journal of Computer Assisted ‚Ä¶,0.7554734817146804,0.7675558764341797,0.76151467907443
An effective CNN and Transformer complementary network for medical image segmentation,https://www.sciencedirect.com/science/article/pii/S0031320322007075,"We propose an effective Feature Complementary Module (FCM words, our CAB is factually  a mixed attention mechanism.  , which is a pure transformer architecture. The variant has an","F Yuan, Z Zhang, Z Fang",2023,Pattern Recognition,0.7453231060815214,0.7772996716827199,0.7613113888821206
Boxer: Box-attention for 2d and 3d transformers,http://openaccess.thecvf.com/content/CVPR2022/html/Nguyen_BoxeR_Box-Attention_for_2D_and_3D_Transformers_CVPR_2022_paper.html,"a simple attention mechanism, we call Box-Attention. It  inductive bias in the network  architecture delivers a strong  inductive bias in the transformer‚Äôs attention module leads to a better","DK Nguyen, J Ju, O Booij",2022,Proceedings of the ‚Ä¶,0.7603931530881003,0.7621029086357196,0.76124803086191
Contextual attention network: Transformer meets u-net,https://link.springer.com/chapter/10.1007/978-3-031-21014-3_39,from the CNN module. Our design proposes a contextual attention mechanism for feature   can provide an additional input signal for a reliable and robust segmentation architecture. It,"R Azad, M Heidari, Y Wu, D Merhof",2022,International Workshop on Machine ‚Ä¶,0.7557280634664425,0.7659875790391852,0.7608578212528139
Uformer: A general u-shaped transformer for image restoration,http://openaccess.thecvf.com/content/CVPR2022/html/Wang_Uformer_A_General_U-Shaped_Transformer_for_Image_Restoration_CVPR_2022_paper.html,"and efficient Transformer-based architecture for image  into the attention module, so the  attention calculation can be  As shown in Figure 3, we first apply a linear projection layer to each","Z Wang, X Cun, J Bao, W Zhou",2022,Proceedings of the ‚Ä¶,0.7646508852298586,0.7564985938682139,0.7605747395490363
Causal attention for vision-language tasks,http://openaccess.thecvf.com/content/CVPR2021/html/Yang_Causal_Attention_for_Vision-Language_Tasks_CVPR_2021_paper.html,"attention mechanism: Causal Attention (CATT), to remove the ever-elusive confounding effect  in existing attention-based  CATT, BUTD and Transformer based VQA models can attend to","X Yang, H Zhang, G Qi, J Cai",2021,Proceedings of the IEEE ‚Ä¶,0.7470323515605887,0.7740020059399048,0.7605171787502467
YOLOV5-CBAM-C3TR: an optimized model based on transformer module and attention mechanism for apple leaf disease detection,https://www.frontiersin.org/articles/10.3389/fpls.2023.1323301/full,"the classical transformer encoder architecture. Illustrated in  , Multi-head attention, and  feedforward neural network (FFN).  at the last layer of backbone network, the optimized YOLOV5-","M Lv, WH Su",2024,Frontiers in Plant Science,0.7498018007473198,0.7710326977967579,0.7604172492720389
Spatial temporal transformer network for skeleton-based action recognition,https://link.springer.com/chapter/10.1007/978-3-030-68796-0_50,"We design a Spatial Self-Attention (SSA) module to  Transformer (ST-TR), an architecture  using the Transformer  T-TR layer, a standard graph convolution sub-module [16] is","C Plizzari, M Cannici, M Matteucci",2021,"‚Ä¶ : virtual event, January 10‚Äì15, 2021 ‚Ä¶",0.7587176266832376,0.7617573569869409,0.7602374918350893
Re-attention transformer for weakly supervised object localization,https://arxiv.org/abs/2208.01838,a reattention mechanism termed token refinement transformer ( tokens from each transformer  layer to compensate for the  ablations about the re-attention module. Both qualitative and,"H Su, Y Ye, Z Chen, M Song, L Cheng",2022,arXiv preprint arXiv:2208.01838,0.7503389389914232,0.7700479461520966,0.7601934425717599
MSTCRB: Predicting circRNA-RBP interaction by extracting multi-scale features based on transformer and attention mechanism,https://www.sciencedirect.com/science/article/pii/S0141813024056101,", the coding layer can be removed from transformer framework.  , transformer module and  attention mechanism module are  extraction module, an optimized transformer architecture is","Y Zhou, H Cui, D Liu, W Wang",2024,International Journal of Biological ‚Ä¶,0.7563941692082601,0.7638070308607847,0.7601006000345224
Clinical knowledge-based ECG abnormalities detection using dual-view CNN-Transformer and external attention mechanism,https://www.sciencedirect.com/science/article/pii/S0010482524008369,Table 1 lists the details of the module architecture designed  Each encoder layer is composed  of a Multi-Head Attention  external attention-based dual-view CNN-Transformer module to,"H Li, J Han, H Zhang, X Zhang, Y Si, Y Zhang",2024,Computers in Biology ‚Ä¶,0.7519805259868774,0.7672860669001416,0.7596332964435095
Choose a transformer: Fourier or galerkin,https://proceedings.neurips.cc/paper/2021/hash/d0921d442ee91b896ad95059d13df618-Abstract.html,"simple attention-based operator learner, Galerkin Transformer,  66], we have modified the  attention mechanism minimally yet in a  If we apply the regular layer normalization rule that",S Cao,2021,Advances in neural information processing systems,0.75691318385121,0.7612311831594023,0.7590721835053061
Swin-transformer-enabled YOLOv5 with attention mechanism for small object detection on satellite images,https://www.mdpi.com/2072-4292/14/12/2861,"a new branch in the shallower network layer for detecting small  This architecture has the  flexibility to model at various scales  transformer prediction head, but also another C3 module in","H Gong, T Mu, Q Li, H Dai, C Li, Z He, W Wang, F Han",2022,Remote Sensing,0.7548637700590807,0.7630467355342319,0.7589552527966563
Serialized multi-layer multi-head attention for neural speaker embedding,https://arxiv.org/abs/2107.06493,"Inspired by the Transformer network, our proposed method utilizes the hierarchical  proposed  serialized attention mechanism, we use d = 256 and dk = 128 in self-attention module, and","H Zhu, KA Lee, H Li",2021,arXiv preprint arXiv:2107.06493,0.7493159944828318,0.7682879796886002,0.758801987085716
CAT-Net: A cross-slice attention transformer model for prostate zonal segmentation in MRI,https://ieeexplore.ieee.org/abstract/document/9910184/,"attention mechanism, which we use in a Transformer module  that can be incorporated within  any network architecture with  attention between slices at the bottom layer of a U-Net with a","ALY Hung, H Zheng, Q Miao, SS Raman",2022,IEEE transactions on ‚Ä¶,0.7481071313777182,0.7692398888575178,0.7586735101176181
A robust attention-enhanced network with transformer for visual tracking,https://link.springer.com/article/10.1007/s11042-023-15168-5,"module and the global feature information fusion module is  The network architecture of our  tracker is very concise, which  Transformer and introduce the attention mechanism into our","F Gu, J Lu, C Cai",2023,Multimedia Tools and Applications,0.752359210552155,0.764909023023625,0.7586341167878901
A PV cell defect detector combined with transformer and attention mechanism,https://www.nature.com/articles/s41598-024-72019-5,"the YOLO architecture, integrating an attention mechanism and the Transformer module. We   Positioning the CCT in the backbone's final layer minimally increases the model's overall","D Lang, Z Lv",2024,Scientific Reports,0.7504274711495954,0.7654136314902561,0.7579205513199258
DSS-TRM: Deep spatial‚Äìspectral transformer for hyperspectral image classification,https://www.tandfonline.com/doi/abs/10.1080/22797254.2021.2023910,"of deep convolution networks, attention mechanism is also  convolutional neural networks  and attention based methods.  A simplified 2D-3D CNN architecture for hyperspectral image","B Liu, A Yu, K Gao, X Tan, Y Sun",2022,European Journal of ‚Ä¶,0.7476334378032016,0.7681671048744388,0.7579002713388202
A sparse-based transformer network with associated spatiotemporal feature for micro-expression recognition,https://ieeexplore.ieee.org/abstract/document/9906452/,"architecture of our proposed method is presented. Specially, we will illustrate the sparse  multi-head self-attention module  [21] network except for the final average pooling layer as the","J Zhu, Y Zong, H Chang, Y Xiao",2022,IEEE Signal Processing ‚Ä¶,0.7491359498664318,0.7659658310486694,0.7575508904575506
UTNet: a hybrid transformer architecture for medical image segmentation,https://link.springer.com/chapter/10.1007/978-3-030-87199-4_6,"Our hybrid layer design allows the initialization of Transformer into  the self-attention  module on top of the feature maps from the CNN backbone, we apply the Transformer module to","Y Gao, M Zhou, DN Metaxas",2021,"‚Ä¶ , France, September 27‚ÄìOctober 1, 2021 ‚Ä¶",0.7546501145122324,0.7602877565919902,0.7574689355521114
VSNet: classification of pulmonary nodules in 3D using vision transformer and sequence spatial attention mechanism,https://link.springer.com/article/10.1007/s11042-024-19475-3,"Differently, we introduce the SSAM module to improve the model‚Äô We have presented an  overview of VSNet architecture in Fig.  last Transformer layer, we utilize a de-convolution layer to","D Tang, T Xiao, F Yang, C Zhang, Z Wang",2024,Multimedia Tools and ‚Ä¶,0.7494982555304349,0.7652001296002002,0.7573491925653175
Underwater image enhancement via adaptive group attention-based multiscale cascade transformer,https://ieeexplore.ieee.org/abstract/document/9825662/,"Swin Transformer block and the channel attention mechanism network, we compose the  encoder with Patch Merging layer  , ie, with the Swin Transformer network architecture alone, the","Z Huang, J Li, Z Hua, L Fan",2022,IEEE Transactions on ‚Ä¶,0.7592585394411825,0.7545743986380437,0.7569164690396131
Prediction of BLEVE-induced response of road tunnel using Transformer network with modified self-attention (SAMT),https://www.sciencedirect.com/science/article/pii/S0141029624009775,"model that employs a Transformer-based architecture with a  Transformer layer, which has  the same architecture as the first  tokens output from the module of Transformer layers. The","R Cheng, W Chen, H Hao, Q Li",2024,Engineering Structures,0.7437021077426944,0.7699289922814698,0.7568155500120821
Multi-encoder-decoder transformer for code-switching speech recognition,https://arxiv.org/abs/2006.10414,multi-head attention mechanism in the decoder module. Each  We propose a modified  Transformer architecture that takes the  The MED Transformer in our experiment contains 12-layer,"X Zhou, E Yƒ±lmaz, Y Long, Y Li, H Li",2020,arXiv preprint arXiv:2006.10414,0.7595726107534966,0.7535182393268207,0.7565454250401586
Query2label: A simple transformer way to multi-label classification,https://arxiv.org/abs/2107.10834,"Transformer decoder architecture is used in classification.  -in cross-attention mechanism in  Transformer decoders, our  and remove the selfattention module in Transformer decoders for","S Liu, L Zhang, X Yang, H Su, J Zhu",2021,arXiv preprint arXiv:2107.10834,0.7517818896618491,0.761130931818974,0.7564564107404115
ACTNet: Attention based CNN and Transformer network for respiratory rate estimation,https://www.sciencedirect.com/science/article/pii/S174680942400555X,"spatial attention, so we use a local attention mechanism in  (EDC) module and transformer  encoder architecture. Finally, a  in the Transformer branch, and the linear projection layer is a","H Chen, X Zhang, Z Guo, N Ying, M Yang",2024,‚Ä¶ Signal Processing and ‚Ä¶,0.7469538379445438,0.7655615652730436,0.7562577016087937
Memory-efficient transformer-based network model for traveling salesman problem,https://www.sciencedirect.com/science/article/pii/S0893608023000771,"to model the network architecture and train the network model. In  Multi-Head Attention  module of the Decoder in Transformer,  scaled dot-product attention mechanism to address the","H Yang, M Zhao, L Yuan, Y Yu, Z Li, M Gu",2023,Neural Networks,0.7495029965655198,0.7620467280263246,0.7557748622959222
Automatic identifier of socket for electrical vehicles using SWIN-transformer and SimAM attention mechanism-based EVS YOLO,https://ieeexplore.ieee.org/abstract/document/10268929/,"attention map produced by a two-layer perceptron. CBAM [29]  Swin module in the backbone  of the YOLOv5S architecture.  transformer module into the backbone part of the network,","VC Mahaadevan, R Narayanamoorthi, R Gono",2023,IEEE ‚Ä¶,0.7498352047929857,0.7615639401130992,0.7556995724530424
Correspondence attention transformer: A context-sensitive network for two-view correspondence learning,https://ieeexplore.ieee.org/abstract/document/9741369/,"attention mechanism in our correspondence attention block,  architecture of our  correspondence attention transformer is  propagation of the covariance attention module, we need","J Ma, Y Wang, A Fan, G Xiao",2022,IEEE Transactions on ‚Ä¶,0.7498752109159572,0.7614730109795851,0.7556741109477711
Transformer tracking,http://openaccess.thecvf.com/content/CVPR2021/html/Chen_Transformer_Tracking_CVPR_2021_paper.html,"by Transformer, this work presents a novel attention-based  encoder-decoder architecture  in the original Transformer as it  idea of Transformer and exploit the attention mechanism to","X Chen, B Yan, J Zhu, D Wang",2021,Proceedings of the ‚Ä¶,0.7524391826088057,0.7575656407402088,0.7550024116745073
Breast Cancer Image Classification Using External Attention Multilayer Perceptron-Based Transformer,https://ieeexplore.ieee.org/abstract/document/10561857/,attention mechanism called External Attention Multi-Layer  crucial component of the  Transformer architecture which divides the  an external attention-based transformer method for,"S Barua, MS Islam",2024,2024 3rd International Conference on ‚Ä¶,0.7575843359270988,0.7519871052533269,0.7547857205902129
Co-scale conv-attentional image transformers,http://openaccess.thecvf.com/content/ICCV2021/html/Xu_Co-Scale_Conv-Attentional_Image_Transformers_ICCV_2021_paper.html,"across different scales in our co-scale module provides  Here, we develop our factorized  attention mechanism following  CoaT architecture, namely serial and parallel blocks, in order to","W Xu, Y Xu, T Chang, Z Tu",2021,Proceedings of the IEEE/CVF ‚Ä¶,0.7503112146363612,0.758675174921056,0.7544931947787086
Incorporating transformers and attention networks for stock movement prediction,https://onlinelibrary.wiley.com/doi/abs/10.1155/2022/7739087,"Among them, the transformer model and attention mechanism are  transformer encoder  attention (TEA) network architecture,  the role of the corresponding module in the framework in a","Y Li, S Lv, X Liu, Q Zhang",2022,Complexity,0.7541735951317631,0.7535969186002833,0.7538852568660233
Reference-based image super-resolution with deformable attention transformer,https://link.springer.com/chapter/10.1007/978-3-031-19797-0_19,"-based deformable attention module for correspondence  Different from existing attention  mechanism [39], our attention is  With the help of our architecture, the proposed RDA module is","J Cao, J Liang, K Zhang, Y Li, Y Zhang, W Wang",2022,European conference on ‚Ä¶,0.7581863610303489,0.7484549376080183,0.7533206493191835
The lipschitz constant of self-attention,https://proceedings.mlr.press/v139/kim21i.html,"self-attention and use it in a Transformer-based architecture for  -layer Transformer (L2), WQ  = WK model and (DP) model used  Having a provably Lipschitz self-attention module at our","H Kim, G Papamakarios, A Mnih",2021,‚Ä¶ Conference on Machine ‚Ä¶,0.7386126189025679,0.7677517317383095,0.7531821753204386
Video swin transformer,http://openaccess.thecvf.com/content/CVPR2022/html/Liu_Video_Swin_Transformer_CVPR_2022_paper.html,in the standard Transformer layer with the 3D shifted window based multihead self-attention  module ( We present a pure-transformer architecture for video recognition that is based on,"Z Liu, J Ning, Y Cao, Y Wei, Z Zhang",2022,Proceedings of the ‚Ä¶,0.7543948282809338,0.7513926834237586,0.7528937558523463
RPConvformer: A novel Transformer-based deep neural networks for traffic flow prediction,https://www.sciencedirect.com/science/article/pii/S095741742300088X,"Therefore, we propose a multi-head attention mechanism  is passed to the multi-head  attention mechanism layer. Next,  rectangle is a multi-head attention mechanism module, and the","Y Wen, P Xu, Z Li, W Xu, X Wang",2023,Expert Systems with Applications,0.7462744743473907,0.7580253602962329,0.7521499173218118
Recent progress in transformer-based medical image analysis,https://www.sciencedirect.com/science/article/pii/S0010482523007333,"the core component of the transformer, the attention mechanism, and the detailed structures  of the transformer. After that, we depict the recent progress of the transformer in the field of","Z Liu, Q Lv, Z Yang, Y Li, CH Lee, L Shen",2023,Computers in Biology and ‚Ä¶,0.755578788697624,0.7485686499422219,0.752073719319923
Medical image segmentation via cascaded attention decoding,https://openaccess.thecvf.com/content/WACV2023/html/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.html,"Transformers rely on an attention-based network architecture;  Finally, we send the output  from each CAM layer to a  It is evident from Figure 2 that the attention mechanism used in our","MM Rahman, R Marculescu",2023,Proceedings of the IEEE/CVF ‚Ä¶,0.7445655801538051,0.7586375710118889,0.751601575582847
Ds-transunet: Dual swin transformer u-net for medical image segmentation,https://ieeexplore.ieee.org/abstract/document/9785614/,a well-established transformer interactive fusion (TIF) module.  Res-UNet [20] adds a weighted  attention mechanism and  UNet-like architecture which applies swin transformer block to,"A Lin, B Chen, J Xu, Z Zhang, G Lu",2022,IEEE Transactions on ‚Ä¶,0.7511181687670156,0.7514602299571471,0.7512891993620814
Sparse self-attention transformer for image inpainting,https://www.sciencedirect.com/science/article/pii/S0031320323005952,"In Section 3, we present the network architecture of Spa- Spa-attention mechanism, which  is incorporated into the  In the Spa-attention module of the k th transformer block, we first put","W Huang, Y Deng, S Hui, Y Wu, S Zhou, J Wang",2024,Pattern Recognition,0.7508050588947611,0.7514342968966273,0.7511196778956942
Research and implementation of Chinese couplet generation system with attention-based transformer mechanism,https://ieeexplore.ieee.org/abstract/document/9411906/,of the last layer in the Decoder back to the first layer of the  network is 1024. The number  of headers in the multihead  the complete attention mechanism-based Transformer model to,"Y Wang, J Zhang, B Zhang, Q Jin",2021,IEEE Transactions on ‚Ä¶,0.7468741940811161,0.7551969562490642,0.7510355751650901
Language modeling with deep transformers,https://arxiv.org/abs/1905.04226,subword-level models to attention based encoder-decoder models  the decoder component  of the Transformer architecture [1].  We observe that the first layer of the model with positional,"K Irie, A Zeyer, R Schl√ºter, H Ney",2019,arXiv preprint arXiv:1905.04226,0.7486578830235632,0.750057605066082,0.7493577440448226
Scale-aware modulation meet transformer,http://openaccess.thecvf.com/content/ICCV2023/html/Lin_Scale-Aware_Modulation_Meet_Transformer_ICCV_2023_paper.html,"introduce the Multi-Head Mixed Convolution (MHMC) module,  -Transformer architecture  called the Evolutionary Hybrid  -head and multi-head mixed convolution in the last layer during","W Lin, Z Wu, J Chen, J Huang",2023,Proceedings of the IEEE ‚Ä¶,0.7568116031871958,0.741416292469005,0.7491139478281004
LncLocFormer: a Transformer-based deep learning model for multi-label lncRNA subcellular localization prediction by using localization-specific attention mechanism,https://academic.oup.com/bioinformatics/article-abstract/39/12/btad752/7477673,"We know that Recurrent Neural Network (RNN) is a  attention scores from the previous  self-attention layer. Instead of using a single attention in the traditional Transformer architecture,","M Zeng, Y Wu, Y Li, R Yin, C Lu, J Duan, M Li",2023,Bioinformatics,0.7406840137667935,0.7568572751494859,0.7487706444581397
DMFormer: Closing the gap Between CNN and Vision Transformers,https://ieeexplore.ieee.org/abstract/document/10097256/,"a Dynamic Multi-level Attention mechanism (DMA), which  DMA, we extend the architecture  of Swin Transformer [3] and  stem module, which consists of a 7√ó7 convolution layer with","Z Wei, H Pan, L Li, M Lu, X Niu",2023,ICASSP 2023-2023 ‚Ä¶,0.7465486115428973,0.750186228560992,0.7483674200519447
Fully cross-attention transformer for guided depth super-resolution,https://www.mdpi.com/1424-8220/23/5/2723,"a transformer-based architecture with a novel guidance  using a CAGM module, which  leverages transformers to fuse and  use a cross-attention mechanism instead of self-attention. We","I Ariav, I Cohen",2023,Sensors,0.7379576537205469,0.7586112216345372,0.748284437677542
Multi-compound transformer for accurate biomedical image segmentation,https://link.springer.com/chapter/10.1007/978-3-030-87193-2_31,"tokens to the Transformer-Self-Attention module to construct  approach, thoroughly leveraging  the attention mechanism‚Äôs  K_c}\)of the last layer of the TCA module is further passed to a","Y Ji, R Zhang, H Wang, Z Li, L Wu, S Zhang",2021,‚Ä¶ Image Computing and ‚Ä¶,0.7381226274041859,0.7578384280821533,0.7479805277431696
Attention based transformer for student answers assessment,https://par.nsf.gov/biblio/10188357,"proposed model uses a multiYhead attention mechanism that  based model architecture is  different from our proposed model  layer of the transformer. In all experiments, we trained our",N Ait Khayi,2020,Proceedings of the Thirty-Third International FLAIRS ‚Ä¶,0.7469764792986612,0.7488321889486396,0.7479043341236504
Can vision transformers perform convolution?,https://arxiv.org/abs/2111.01353,"that attention-based networks, such as Vision Transformer ( , where the multi-head attention  mechanism and the relative  have some constraints on the ViT architecture. In particular, we","S Li, X Chen, D He, CJ Hsieh",2021,arXiv preprint arXiv:2111.01353,0.7308923895130618,0.7634117069336008,0.7471520482233314
Interpretable deep learning model for building energy consumption prediction based on attention mechanism,https://www.sciencedirect.com/science/article/pii/S0378778821006630,"Attention based on hidden layer states and feature-based  prediction model based on the  transformer model. The specific  help of the encoder and decoder architecture, the prediction of","Y Gao, Y Ruan",2021,Energy and Buildings,0.7421589230323504,0.751738484733979,0.7469487038831647
Attention weights in transformer NMT fail aligning words between sequences but largely explain model predictions,https://arxiv.org/abs/2109.05853,"Transformer architecture in the Neural Machine Translation (NMT) setting. Focusing on the  encoder-decoder attention mechanism, we prove that attention  -decoder attention module is","J Ferrando, MR Costa-juss√†",2021,arXiv preprint arXiv:2109.05853,0.7409046899993791,0.7529518079626909,0.7469282489810349
End-to-end dense video captioning with masked transformer,http://openaccess.thecvf.com/content_cvpr_2018/html/Zhou_End-to-End_Dense_Video_CVPR_2018_paper.html,networks and selfattention  an attention mechanism within a module and is a potential way  to learn this long-range dependence. In selfattention the higher layer in the same module is,"L Zhou, Y Zhou, JJ Corso",2018,Proceedings of the ‚Ä¶,0.7318388875623774,0.7619037387860326,0.746871313174205
RTFormer: Efficient design for real-time semantic segmentation with transformer,https://proceedings.neurips.cc/paper_files/paper/2022/hash/30e10e671c5e43edb67eb257abb6c3ea-Abstract-Conference.html,"attention [15], we developed a GPU-Friendly attention module  attention mechanism while  achieving the real-time speed.  And for the design of multi-resolution architecture, we can","J Wang, C Gou, Q Wu, H Feng, J Han",2022,Advances in Neural ‚Ä¶,0.7401021414787559,0.7525273466200113,0.7463147440493836
Comparative study of Transformer and LSTM Network with attention mechanism on Image Captioning,https://link.springer.com/chapter/10.1007/978-981-99-3761-5_47,"is comparable to that of RNNs, but its repeating module  hidden state and passing it through  a fully connected layer. The  captions using a base transformer architecture and achieved a","P Dandwate, C Shahane, V Jagtap",2023,‚Ä¶ Conference on Information ‚Ä¶,0.7240962604611695,0.7672088953302632,0.7456525778957164
A transformer-based framework for scene text recognition,https://ieeexplore.ieee.org/abstract/document/9894408/,"use the 83 attention mechanism in its prediction module for STR  We propose a modified  Transformer-based architecture to  the encoder‚Äôs multi-head self- 517 attention mechanism, we","P Selvam, JAS Koilraj, CAT Romero, M Alharbi",2022,IEEE ‚Ä¶,0.7444805600955224,0.7436983681720475,0.744089464133785
Adapted transformer network for news recommendation,https://www.sciencedirect.com/science/article/pii/S0925231221015356,"We elaborate the model architecture with adapted transformer interaction  Besides the  adapted transformer interaction module, we also propose two additional attention mechanism to","J Huang, Z Han, H Xu, H Liu",2022,Neurocomputing,0.7416649632424346,0.7458887503567608,0.7437768567995977
SwiniPASSR: Swin transformer based parallax attention network for stereo image super-resolution,http://openaccess.thecvf.com/content/CVPR2022W/NTIRE/html/Jin_SwiniPASSR_Swin_Transformer_Based_Parallax_Attention_Network_for_Stereo_Image_CVPRW_2022_paper.html,": we firstly elaborate the network architecture and the impact of the conversion layer, then  we  To construct parallax attention mechanism (PAM), we introduce biPAM module and its","K Jin, Z Wei, A Yang, S Guo, M Gao",2022,Proceedings of the ‚Ä¶,0.7444018453409615,0.7420261911204399,0.7432140182307008
‚Ä¶ -YOLOv5: An automated damage detection model based on DenseNet and Swin-Transformer prediction head-enabled YOLOv5 with attention mechanism,https://www.sciencedirect.com/science/article/pii/S1474034623001350,"Along a similar line, deep neural network (DNN) architecture has  5-(a), the network structure  of the CBAM module consists of  attention map from multi-layer perceptron (MLP). The CAM","AM Roy, J Bhaduri",2023,Advanced Engineering Informatics,0.728621199857445,0.7486499476778365,0.7386355737676408
Time series forecasting based on convolution transformer,https://search.ieice.org/bin/summary.php?id=e106-d_5_976,Each attention mechanism module is followed by a convolution pooling layer to adjust the   and effect of the proposed network model architecture in time series forecasting. MSE is,"N Wang, X Zhao",2023,IEICE TRANSACTIONS on Information and ‚Ä¶,0.7361055580989396,0.7399010473090525,0.7380033027039961
Rethinking graph transformers with spectral attention,https://proceedings.neurips.cc/paper_files/paper/2021/hash/b4fd1d2cb085390fbbadae65e07876a7-Abstract.html,", and outperforms any attention-based model by a wide margin passing model, and we  demonstrate that our SAN architecture  Since we use a similar attention mechanism, our code was","D Kreuzer, D Beaini, W Hamilton",2021,Advances in ‚Ä¶,0.7347323728914207,0.7363016803914694,0.735517026641445
Uctransnet: rethinking the skip connections in u-net from a channel-wise perspective with transformer,https://ojs.aaai.org/index.php/AAAI/article/view/20144,"decoder architecture. It is still challenging for U-Net with a simple skip connection scheme  to  CTrans module in U-Net), from the channel perspective with attention mechanism. Specif","H Wang, P Cao, J Wang, OR Zaiane",2022,Proceedings of the AAAI ‚Ä¶,0.7248978704012918,0.7388947415416529,0.7318963059714724
Improved Pest-YOLO: Real-time pest detection based on efficient channel attention mechanism and transformer encoder,https://www.sciencedirect.com/science/article/pii/S1574954123003692,"(CNN) architecture to enhance its capability to capture global  the ECA module into the  ResNet-50-D network. This addition  Instead, we introduce a simple linear layer to transform the","Z Tang, J Lu, Z Chen, F Qi, L Zhang",2023,Ecological Informatics,0.7291946208453127,0.7293970591896319,0.7292958400174723
Set transformer,https://www.robots.ox.ac.uk/~mobile/Papers/ICLR2019_lee.pdf,"attention-based neural network module, the Set Transformer,  Set Transformers, our novel  neural network architecture for  the multihead attention mechanism used in Transformer. We","J Lee, Y Lee, J Kim, AR Kosiorek, S Choi",2019,‚Ä¶ on Machine Learning,0.7309593769971641,0.7223741717685366,0.7266667743828503
ResT-ReID: Transformer block-based residual learning for person re-identification,https://www.sciencedirect.com/science/article/pii/S016786552200085X,"attention mechanism into GCN by embedding an attention  for Res-Transformer) module  and SIE-AGCN module can  of evaluation protocols over baseline architecture. Especially, we","Y Chen, S Xia, J Zhao, Y Zhou, Q Niu, R Yao",2022,Pattern Recognition ‚Ä¶,0.7127765315590467,0.7334144732919856,0.7230955024255161
Pay attention to mlps,https://proceedings.neurips.cc/paper/2021/hash/4cc05b35c2f937c5bd9e7d41d3686fff-Abstract.html,"For BERT, our model achieves parity with Transformers on  On one hand, the attention  mechanism [18] introduces the  A typical tiny attention module in our experiments has only a","H Liu, Z Dai, D So, QV Le",2021,Advances in neural information ‚Ä¶,0.7208070173988197,0.724641830917819,0.7227244241583193
